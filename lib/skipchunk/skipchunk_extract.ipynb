{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import spacy\n",
    "import operator\n",
    "from nltk.corpus import wordnet as wn\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_NNJJ_ = {'JJ','JJR','JJS','NN','NNP','NNS','ADJ','NOUN'} #Nouns and Adjectives\n",
    "_VBRB_ = {'RB','RBR','RBS','RP','VB','VBD','VBG','VBN','VBP','VBZ','ADV','VERB'} #Verbs and Adverbs\n",
    "_PUNC_ = {'.',',','?','!',';',':','(',')','[',']','{','}','\"','\\''} #Punctuation\n",
    "_EXCL_ = {'SP','-RRB-','HYPH'} #Noise to skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(filename):\n",
    "    txt = open('../../' + filename,\"r\").read()\n",
    "    doc = nlp(txt)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatize(token):\n",
    "    lemma = token.lower_\n",
    "    if token.tag_ in _NNJJ_:\n",
    "        lemma = token.lemma_\n",
    "    elif token.tag_ in _VBRB_:\n",
    "        lemma = token.lemma_\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adj_to_noun(lem):\n",
    "    for i in wn.synsets(lem, wn.ADJ):\n",
    "        for j in i.lemmas():\n",
    "            drf = j.derivationally_related_forms()\n",
    "            drf.sort(key = lambda x: len(x.name()))\n",
    "            for k in drf:\n",
    "                if k.name()[:2] == lem[:2]:\n",
    "                    #Found it!\n",
    "                    return k.name()\n",
    "\n",
    "def noun_to_adj(lem):\n",
    "    for i in wn.synsets(lem, wn.NOUN):\n",
    "        for j in i.lemmas():\n",
    "            for k in j.derivationally_related_forms():\n",
    "                if k.name()[:2] == lem[:2]:\n",
    "                    #Found it!\n",
    "                    return k.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def annotate(doc):\n",
    "    groups = []\n",
    "    for sent in doc.sents:\n",
    "        terms = []\n",
    "        for tok in sent:\n",
    "            if tok.tag_ not in _EXCL_:\n",
    "                lemma = lemmatize(tok)\n",
    "                drf = None\n",
    "                #Derive related form:\n",
    "                if (tok.tag_ == 'JJ'):\n",
    "                    drf = adj_to_noun(lemma)\n",
    "\n",
    "                terms.append([tok.norm_,lemma,tok.tag_,drf])\n",
    "                \n",
    "        groups.append([sent,terms])\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(stack,origs):\n",
    "    frm = []\n",
    "    stack1 = []\n",
    "    origs1 = []\n",
    "    \n",
    "    for tok in stack:\n",
    "        val = tok[0]\n",
    "        pos = tok[1]\n",
    "        if len(tok)>2 and tok[2]:\n",
    "            val = tok[2]\n",
    "        if pos in _NNJJ_ or pos in _VBRB_:\n",
    "            frm.append(val)\n",
    "        if val not in _PUNC_:\n",
    "            stack1.append(val)\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    k = 0\n",
    "    f = False\n",
    "    for tok in origs:\n",
    "        val = tok[0]\n",
    "        pos = tok[1]\n",
    "        j += 1\n",
    "        if len(tok)>2 and tok[2]:\n",
    "            val = tok[2]\n",
    "        if val not in _PUNC_:\n",
    "            origs1.append(val)\n",
    "        if pos in _NNJJ_ or pos in _VBRB_:\n",
    "            i = j\n",
    "            if not f:\n",
    "                k = j-1\n",
    "            f = True\n",
    "        \n",
    "            \n",
    "    origs1 = origs1[k:i]\n",
    "        \n",
    "    key = '_'.join(sorted(frm)).lower()\n",
    "    txt = '_'.join(stack1).lower()\n",
    "    org = ' '.join(origs1).lower()\n",
    "    count = len(stack1)\n",
    "    return key,txt,org,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def skipchunk(sentences,maxslop=4,maxlength=4,concepts=dict(),predicates=dict(),triples=[]):\n",
    "    \n",
    "    stack = []\n",
    "    origs = []\n",
    "    \n",
    "    def add(obj):\n",
    "        nonlocal stack\n",
    "        nonlocal origs\n",
    "        key,txt,org,count = normalize(stack,origs)\n",
    "        if count>1:\n",
    "            if key not in obj:\n",
    "                obj[key] = []\n",
    "            obj[key].append([key,txt,org])\n",
    "        stack=[]\n",
    "        origs=[]\n",
    "        return key\n",
    "    \n",
    "    def addtriple(sbj,prd,obj):\n",
    "        triples.append({'subject':sbj,'predicate':prd,'object':obj})\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        tokens = sentence[1]\n",
    "\n",
    "        stack = []\n",
    "        origs = []\n",
    "        \n",
    "        isprd = False\n",
    "        iscon = False\n",
    "\n",
    "        currcon = None\n",
    "        currprd = None\n",
    "        lastcon = None\n",
    "        lastprd = None\n",
    "        \n",
    "        last = 0\n",
    "        slop = 0\n",
    "                \n",
    "        for tok in tokens:\n",
    "            wrd = tok[0]\n",
    "            lem = tok[1]\n",
    "            pos = tok[2]\n",
    "            drf = tok[3]\n",
    "\n",
    "            if pos in _NNJJ_:\n",
    "                if isprd:\n",
    "                    currprd = add(predicates)\n",
    "                    \n",
    "                last  = 0\n",
    "                isprd = False\n",
    "                iscon = True\n",
    "                stack.append([lem,pos,drf])\n",
    "                origs.append([wrd,pos,drf])\n",
    "\n",
    "                if len(stack)>=maxlength:\n",
    "                    currcon = add(concepts)\n",
    "\n",
    "            elif pos in _VBRB_:\n",
    "                if iscon:\n",
    "                    lastcon = currcon\n",
    "                    currcon = add(concepts)\n",
    "                    if lastcon and currcon and currprd:\n",
    "                        addtriple(lastcon,currprd,currcon)\n",
    "                        currcon = None\n",
    "                        currprd = None\n",
    "                        lastcon = None\n",
    "                        lastprd = None\n",
    "                    \n",
    "                last  = 0\n",
    "                isprd = True\n",
    "                iscon = False\n",
    "                stack.append([lem,pos])\n",
    "                origs.append([wrd,pos])\n",
    "\n",
    "            elif iscon:\n",
    "                slop += 1\n",
    "                last += 1\n",
    "\n",
    "                origs.append([wrd,pos])\n",
    "\n",
    "                if wrd in _PUNC_ or slop>maxslop:\n",
    "                    lastcon = currcon\n",
    "                    currcon = add(concepts)\n",
    "                    if lastcon and currcon and currprd:\n",
    "                        addtriple(lastcon,currprd,currcon)\n",
    "                        currcon = None\n",
    "                        currprd = None\n",
    "                        lastcon = None\n",
    "                        lastprd = None\n",
    "                    \n",
    "                    iscon = False\n",
    "\n",
    "            elif isprd:\n",
    "                slop += 1\n",
    "                last += 1\n",
    "\n",
    "                origs.append([wrd,pos])\n",
    "\n",
    "                if wrd in _PUNC_ or slop>maxslop:\n",
    "                    currprd = add(predicates)\n",
    "                    isprd = False\n",
    "\n",
    "    return concepts,predicates,triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printgroup(data):\n",
    "    for item in data:\n",
    "        if len(data[item])>1:\n",
    "            print('--------------------------------------------')\n",
    "            print(item)\n",
    "            group = map(lambda x:x[2],data[item])\n",
    "            coll = collections.Counter(group)\n",
    "            for c in coll.most_common():\n",
    "                print('\\t',c[1],c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sortgroup(data):\n",
    "    items = []\n",
    "    for item in data:\n",
    "        if len(data[item])>1:\n",
    "            group = map(lambda x:x[2],data[item])\n",
    "            coll = collections.Counter(group)\n",
    "            total = 0\n",
    "            pref = None\n",
    "            for c in coll.most_common():\n",
    "                if not pref:\n",
    "                    pref = c[0]\n",
    "                total += c[1]\n",
    "            items.append([total,item,pref])\n",
    "    return sorted(items, key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "compscifiles = [\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/10894.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/12049.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/13259.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/16393.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/18209.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/19970.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/20782.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/23267.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/23507.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/23596.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/25473.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/287.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/37632.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/39172.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/39955.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/40879.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/43032.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/7183.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/7502.txt',\n",
    "    'content/keyword-extraction-datasets/wiki20/documents/9307.txt'   \n",
    "]\n",
    "\n",
    "greatexpectations = [\n",
    "    'content/great_expectations.txt'\n",
    "]\n",
    "\n",
    "concepts = dict()\n",
    "predicates = dict()\n",
    "triples = []\n",
    "for file in compscifiles:\n",
    "#for file in greatexpectations:\n",
    "    doc = parse(file)\n",
    "    sentences = annotate(doc)\n",
    "    concepts,predicates,triples = skipchunk(sentences,concepts=concepts,predicates=predicates,triples=triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "regression_selection_technique_test\n",
      "\t 6 regression test selection techniques\n",
      "\t 2 regression test selection technique\n",
      "--------------------------------------------\n",
      "knowledge_priority\n",
      "\t 3 priority knowledge\n",
      "--------------------------------------------\n",
      "newness_regression_technique_test\n",
      "\t 2 newness technique for regression test\n",
      "--------------------------------------------\n",
      "select_test\n",
      "\t 2 select tests\n",
      "--------------------------------------------\n",
      "certain_condition\n",
      "\t 2 certain conditions\n",
      "--------------------------------------------\n",
      "set_test\n",
      "\t 5 test sets\n",
      "\t 3 set of tests\n",
      "\t 1 test set\n",
      "\t 1 test from the set\n",
      "--------------------------------------------\n",
      "algorithm_select\n",
      "\t 2 algorithms select\n",
      "--------------------------------------------\n",
      "original_suite_test\n",
      "\t 3 original test suite\n",
      "--------------------------------------------\n",
      "algorithm_selection\n",
      "\t 2 selection algorithms\n",
      "--------------------------------------------\n",
      "many_otherness_regression_test\n",
      "\t 2 many otherness regression test\n",
      "--------------------------------------------\n",
      "modification_program_type\n",
      "\t 2 types of program modifications\n",
      "--------------------------------------------\n",
      "regression_testing\n",
      "\t 31 regression testing\n",
      "--------------------------------------------\n",
      "cost_overall\n",
      "\t 5 overall cost\n",
      "--------------------------------------------\n",
      "development_testing\n",
      "\t 2 development testing\n",
      "--------------------------------------------\n",
      "such_test\n",
      "\t 3 such tests\n",
      "\t 1 tests such\n",
      "--------------------------------------------\n",
      "retest_select_technique\n",
      "\t 4 select retest techniques\n",
      "\t 3 select retest technique\n",
      "--------------------------------------------\n",
      "modified_program\n",
      "\t 2 modified program\n",
      "--------------------------------------------\n",
      "clemson_university\n",
      "\t 2 clemson university\n",
      "--------------------------------------------\n",
      "ohio_state_university\n",
      "\t 4 ohio state university\n",
      "--------------------------------------------\n",
      "component_program\n",
      "\t 2 program components\n",
      "--------------------------------------------\n",
      "coverage_criterion\n",
      "\t 2 coverage criteria\n",
      "--------------------------------------------\n",
      "suite_test\n",
      "\t 11 test suites\n",
      "\t 11 test suite\n",
      "--------------------------------------------\n",
      "selection_test\n",
      "\t 5 test selection\n",
      "\t 1 selection of these tests\n",
      "--------------------------------------------\n",
      "environment_programming\n",
      "\t 2 programming environment\n",
      "--------------------------------------------\n",
      "currency_practice\n",
      "\t 2 currency practice\n",
      "--------------------------------------------\n",
      "additional_test\n",
      "\t 2 additional tests\n",
      "--------------------------------------------\n",
      "problem_regression_selection_test\n",
      "\t 2 regression test selection problem\n",
      "\t 1 problem of regression test selection\n",
      "--------------------------------------------\n",
      "selection_technique_test\n",
      "\t 3 test selection techniques\n",
      "--------------------------------------------\n",
      "many_technique\n",
      "\t 2 many techniques\n",
      "--------------------------------------------\n",
      "algorithms_otherness_safeness\n",
      "\t 2 otherness safeness algorithms\n",
      "--------------------------------------------\n",
      "few_test\n",
      "\t 2 fewer tests\n",
      "--------------------------------------------\n",
      "process_regression_testing\n",
      "\t 1 regression testing process\n",
      "\t 1 regression testing processes\n",
      "--------------------------------------------\n",
      "interprocedural_intraprocedural_regression_test\n",
      "\t 1 interprocedural and intraprocedural regression test\n",
      "\t 1 intraprocedural and interprocedural regression test\n",
      "--------------------------------------------\n",
      "modification_program\n",
      "\t 2 program modifications\n",
      "--------------------------------------------\n",
      "language_procedure\n",
      "\t 2 procedure languages\n",
      "--------------------------------------------\n",
      "next_section\n",
      "\t 3 next section\n",
      "\t 1 next two sections\n",
      "--------------------------------------------\n",
      "output_p\n",
      "\t 1 output of p\n",
      "\t 1 outputs p\n",
      "--------------------------------------------\n",
      "output_specified\n",
      "\t 2 specified output\n",
      "--------------------------------------------\n",
      "t_test\n",
      "\t 7 test t\n",
      "\t 5 tests in t\n",
      "\t 1 t tests\n",
      "--------------------------------------------\n",
      "cfg_p_procedure\n",
      "\t 1 cfg for procedure p\n",
      "\t 1 cfg for a procedure p\n",
      "--------------------------------------------\n",
      "conditionality_statement\n",
      "\t 2 conditionality statements\n",
      "\t 1 conditionality statement\n",
      "--------------------------------------------\n",
      "node_statement\n",
      "\t 2 statement nodes\n",
      "--------------------------------------------\n",
      "node_predicate\n",
      "\t 4 predicate nodes\n",
      "--------------------------------------------\n",
      "edge_label\n",
      "\t 1 edge label\n",
      "\t 1 edge labels\n",
      "--------------------------------------------\n",
      "exit_node\n",
      "\t 4 exit node\n",
      "--------------------------------------------\n",
      "case_statement\n",
      "\t 2 case statements\n",
      "--------------------------------------------\n",
      "cfg_node\n",
      "\t 3 cfg node\n",
      "\t 1 cfg nodes\n",
      "--------------------------------------------\n",
      "method_otherness\n",
      "\t 2 otherness methods\n",
      "\t 1 otherness two methods\n",
      "--------------------------------------------\n",
      "instrumented_version\n",
      "\t 2 instrumented version\n",
      "--------------------------------------------\n",
      "cfg_g\n",
      "\t 1 cfg g\n",
      "\t 1 cfgs g\n",
      "--------------------------------------------\n",
      "edge_p_t_trace\n",
      "\t 2 edge trace for t on p\n",
      "--------------------------------------------\n",
      "bit_vector\n",
      "\t 2 bit vector\n",
      "--------------------------------------------\n",
      "information_test\n",
      "\t 2 test information\n",
      "--------------------------------------------\n",
      "paper_remainder\n",
      "\t 3 remainder of this paper\n",
      "--------------------------------------------\n",
      "variety_wideness\n",
      "\t 4 wideness variety\n",
      "--------------------------------------------\n",
      "cost_regression_testing\n",
      "\t 3 cost of regression testing\n",
      "--------------------------------------------\n",
      "p_t\n",
      "\t 2 p with t\n",
      "--------------------------------------------\n",
      "problem_several\n",
      "\t 3 several problems\n",
      "--------------------------------------------\n",
      "subset_t\n",
      "\t 1 subset t\n",
      "\t 1 subset of t\n",
      "--------------------------------------------\n",
      "result_test\n",
      "\t 2 test results\n",
      "\t 1 result of this test\n",
      "\t 1 results of the tests\n",
      "--------------------------------------------\n",
      "phase_preliminary\n",
      "\t 3 preliminary phase\n",
      "\t 1 preliminary phases\n",
      "--------------------------------------------\n",
      "critic_phase\n",
      "\t 2 critic phase\n",
      "--------------------------------------------\n",
      "phase_preliminary_regression_testing\n",
      "\t 1 preliminary phase of regression testing\n",
      "\t 1 preliminary regression testing phase\n",
      "--------------------------------------------\n",
      "cost_critic_phase\n",
      "\t 1 critic phase cost\n",
      "\t 1 critic phase costs\n",
      "--------------------------------------------\n",
      "algorithm_regression_selection_test\n",
      "\t 1 regression test selection algorithms\n",
      "\t 1 regression test selection algorithm\n",
      "--------------------------------------------\n",
      "nonobsolete_test\n",
      "\t 2 nonobsolete tests\n",
      "--------------------------------------------\n",
      "otherness_word\n",
      "\t 10 otherness words\n",
      "--------------------------------------------\n",
      "p_p\n",
      "\t 5 p and p\n",
      "--------------------------------------------\n",
      "et_execution_trace\n",
      "\t 2 execution trace et\n",
      "\t 1 execution traces et\n",
      "--------------------------------------------\n",
      "modification_traversing\n",
      "\t 14 modification traversing\n",
      "--------------------------------------------\n",
      "differ_execution_trace\n",
      "\t 2 differ execution traces\n",
      "--------------------------------------------\n",
      "algorithm_interprocedural_selection_test\n",
      "\t 3 interprocedural test selection algorithm\n",
      "\t 1 algorithm for interprocedural test selection\n",
      "--------------------------------------------\n",
      "intraprocedural_selection_test\n",
      "\t 2 intraprocedural test selection\n",
      "--------------------------------------------\n",
      "execution_trace\n",
      "\t 2 execution trace\n",
      "\t 2 execution traces\n",
      "--------------------------------------------\n",
      "trace_traversal\n",
      "\t 5 traversal traces\n",
      "\t 1 traversal trace\n",
      "--------------------------------------------\n",
      "prefix_trace_traversal\n",
      "\t 3 traversal trace prefixes\n",
      "\t 1 traversal trace prefix\n",
      "--------------------------------------------\n",
      "increment_process\n",
      "\t 2 increment process\n",
      "--------------------------------------------\n",
      "currency_state\n",
      "\t 4 currency state\n",
      "\t 1 currency states\n",
      "--------------------------------------------\n",
      "comparison_pairwise\n",
      "\t 3 pairwise comparison\n",
      "--------------------------------------------\n",
      "first_pair\n",
      "\t 3 first pair\n",
      "--------------------------------------------\n",
      "n_node\n",
      "\t 6 nodes n\n",
      "--------------------------------------------\n",
      "entry_node\n",
      "\t 6 entry nodes\n",
      "--------------------------------------------\n",
      "such_trace\n",
      "\t 1 such traces\n",
      "\t 1 traces such\n",
      "--------------------------------------------\n",
      "p_procedure\n",
      "\t 4 procedure p\n",
      "\t 1 procedures p\n",
      "\t 1 procedures in p\n",
      "\t 1 p procedures\n",
      "--------------------------------------------\n",
      "p_version\n",
      "\t 2 version p\n",
      "--------------------------------------------\n",
      "n_n_node_pair\n",
      "\t 1 pairs of nodes n and n\n",
      "\t 1 pair of nodes n and n\n",
      "--------------------------------------------\n",
      "graph_traversal\n",
      "\t 1 graph traversals\n",
      "\t 1 graph traversal\n",
      "--------------------------------------------\n",
      "s_statement\n",
      "\t 2 statements s\n",
      "--------------------------------------------\n",
      "character_constant\n",
      "\t 2 character constants\n",
      "--------------------------------------------\n",
      "avg_procedure\n",
      "\t 2 procedure avg\n",
      "--------------------------------------------\n",
      "avg_avg2\n",
      "\t 2 avg and avg2\n",
      "--------------------------------------------\n",
      "suite_t_test\n",
      "\t 2 test suite t\n",
      "--------------------------------------------\n",
      "equivalent_return_trueness\n",
      "\t 2 equivalent returns trueness\n",
      "--------------------------------------------\n",
      "call_recursive\n",
      "\t 3 recursive calls\n",
      "\t 3 recursive call\n",
      "--------------------------------------------\n",
      "node_successor\n",
      "\t 1 successors of these nodes\n",
      "\t 1 successors of the nodes\n",
      "--------------------------------------------\n",
      "change_only\n",
      "\t 2 only change\n",
      "--------------------------------------------\n",
      "case_latter\n",
      "\t 2 latter case\n",
      "--------------------------------------------\n",
      "c_function\n",
      "\t 1 c function\n",
      "\t 1 c functions\n",
      "--------------------------------------------\n",
      "t2_test\n",
      "\t 2 test t2\n",
      "--------------------------------------------\n",
      "algorithm_efficiency\n",
      "\t 2 efficiency algorithm\n",
      "\t 1 efficiency of this algorithm\n",
      "\t 1 efficiency algorithms\n",
      "--------------------------------------------\n",
      "factor_otherness\n",
      "\t 1 otherness factors\n",
      "\t 1 otherness factor\n",
      "--------------------------------------------\n",
      "regression_selection_test\n",
      "\t 2 regression test selection\n",
      "--------------------------------------------\n",
      "controlled_regression_testing\n",
      "\t 2 controlled regression testing\n",
      "--------------------------------------------\n",
      "prematureness_section\n",
      "\t 2 prematureness section\n",
      "--------------------------------------------\n",
      "condition_node\n",
      "\t 10 node condition\n",
      "--------------------------------------------\n",
      "empiricism_study\n",
      "\t 8 empiricism studies\n",
      "\t 3 empiricism study\n",
      "--------------------------------------------\n",
      "equivalent_procedure\n",
      "\t 2 equivalent procedure\n",
      "--------------------------------------------\n",
      "practice_purpose\n",
      "\t 2 practice purposes\n",
      "--------------------------------------------\n",
      "pair_procedure\n",
      "\t 1 pair of procedures\n",
      "\t 1 procedure pair\n",
      "--------------------------------------------\n",
      "several_way\n",
      "\t 2 several ways\n",
      "--------------------------------------------\n",
      "algorithm_basic\n",
      "\t 1 basic algorithm\n",
      "\t 1 basic algorithms\n",
      "--------------------------------------------\n",
      "code_executability\n",
      "\t 2 executability code\n",
      "--------------------------------------------\n",
      "only_test\n",
      "\t 2 only tests\n",
      "--------------------------------------------\n",
      "executability_portion\n",
      "\t 2 executability portion\n",
      "--------------------------------------------\n",
      "algorithm_selection_test\n",
      "\t 3 test selection algorithms\n",
      "--------------------------------------------\n",
      "location_memory\n",
      "\t 2 memory locations\n",
      "\t 1 memory location\n",
      "--------------------------------------------\n",
      "edge_newness\n",
      "\t 1 newness edges\n",
      "\t 1 newness edge\n",
      "--------------------------------------------\n",
      "number_test\n",
      "\t 3 number of tests\n",
      "\t 1 numbers of tests\n",
      "--------------------------------------------\n",
      "procedure_singleness\n",
      "\t 1 singleness procedure\n",
      "\t 1 singleness procedures\n",
      "--------------------------------------------\n",
      "functionality_specification\n",
      "\t 2 functionality and specification\n",
      "--------------------------------------------\n",
      "name_procedure\n",
      "\t 3 procedure names\n",
      "\t 1 name of each procedure\n",
      "--------------------------------------------\n",
      "approach_simpleness\n",
      "\t 2 simpleness approach\n",
      "--------------------------------------------\n",
      "p_present\n",
      "\t 2 present in p\n",
      "--------------------------------------------\n",
      "program_sys\n",
      "\t 2 program sys\n",
      "--------------------------------------------\n",
      "case_need\n",
      "\t 2 need in this case\n",
      "--------------------------------------------\n",
      "algorithm_naiveness\n",
      "\t 3 naiveness algorithm\n",
      "--------------------------------------------\n",
      "entry_procedure\n",
      "\t 3 entry procedures\n",
      "--------------------------------------------\n",
      "call_node\n",
      "\t 2 call nodes\n",
      "--------------------------------------------\n",
      "flag_status\n",
      "\t 6 status flag\n",
      "--------------------------------------------\n",
      "e_p\n",
      "\t 2 p e\n",
      "--------------------------------------------\n",
      "c_call\n",
      "\t 1 c for calls\n",
      "\t 1 calls to c\n",
      "--------------------------------------------\n",
      "bad_case\n",
      "\t 4 worst case\n",
      "--------------------------------------------\n",
      "execution_time\n",
      "\t 14 execution time\n",
      "\t 1 execution times\n",
      "--------------------------------------------\n",
      "safeness_selection_test\n",
      "\t 2 safeness test selection\n",
      "--------------------------------------------\n",
      "case_multiply\n",
      "\t 2 cases where the multiply\n",
      "--------------------------------------------\n",
      "otherness_safeness_technique\n",
      "\t 2 otherness safeness techniques\n",
      "--------------------------------------------\n",
      "history_information_test\n",
      "\t 3 test history information\n",
      "--------------------------------------------\n",
      "language_such\n",
      "\t 4 such languages\n",
      "\t 1 languages such\n",
      "--------------------------------------------\n",
      "experimental_subject_suitability\n",
      "\t 2 suitability experimental subjects\n",
      "--------------------------------------------\n",
      "multiple_version\n",
      "\t 4 multiple versions\n",
      "--------------------------------------------\n",
      "task_trivia\n",
      "\t 2 trivia task\n",
      "--------------------------------------------\n",
      "free_software\n",
      "\t 2 free software\n",
      "--------------------------------------------\n",
      "code_source\n",
      "\t 3 source code\n",
      "--------------------------------------------\n",
      "experimental_result\n",
      "\t 6 experimental results\n",
      "--------------------------------------------\n",
      "cross_fairness_section\n",
      "\t 2 fairness cross section\n",
      "--------------------------------------------\n",
      "engineer_software\n",
      "\t 1 software engineers\n",
      "\t 1 software engineer\n",
      "--------------------------------------------\n",
      "study_such\n",
      "\t 1 such studies\n",
      "\t 1 such study\n",
      "--------------------------------------------\n",
      "interprocedural_selection_test\n",
      "\t 2 interprocedural test selection\n",
      "--------------------------------------------\n",
      "adequacy_criterion_test\n",
      "\t 2 test adequacy criteria\n",
      "--------------------------------------------\n",
      "program_version\n",
      "\t 2 program version\n",
      "\t 1 versions of these programs\n",
      "--------------------------------------------\n",
      "program_siemens\n",
      "\t 1 siemens programs\n",
      "\t 1 siemens program\n",
      "--------------------------------------------\n",
      "siemens_study\n",
      "\t 4 siemens study\n",
      "--------------------------------------------\n",
      "base_fault_program_version\n",
      "\t 2 fault versions of base programs\n",
      "--------------------------------------------\n",
      "base_program\n",
      "\t 5 base program\n",
      "\t 3 base programs\n",
      "--------------------------------------------\n",
      "researcher_siemens\n",
      "\t 3 siemens researchers\n",
      "--------------------------------------------\n",
      "pool_test\n",
      "\t 1 test pool\n",
      "\t 1 test pools\n",
      "--------------------------------------------\n",
      "siemens_subject\n",
      "\t 2 siemens subjects\n",
      "--------------------------------------------\n",
      "empiricism_result\n",
      "\t 5 empiricism results\n",
      "--------------------------------------------\n",
      "base_version\n",
      "\t 4 base version\n",
      "--------------------------------------------\n",
      "base_procedure\n",
      "\t 2 base procedure\n",
      "--------------------------------------------\n",
      "figure_result\n",
      "\t 2 results figure\n",
      "--------------------------------------------\n",
      "selection_test_tool\n",
      "\t 2 test selection tool\n",
      "--------------------------------------------\n",
      "percentage_test\n",
      "\t 3 percentage of tests\n",
      "--------------------------------------------\n",
      "column_dark\n",
      "\t 2 darkest column\n",
      "--------------------------------------------\n",
      "column_light\n",
      "\t 2 lightest column\n",
      "--------------------------------------------\n",
      "overall_regression_testing_time\n",
      "\t 2 overall regression testing time\n",
      "--------------------------------------------\n",
      "effort_totality\n",
      "\t 4 totality effort\n",
      "--------------------------------------------\n",
      "large_program\n",
      "\t 2 larger programs\n",
      "--------------------------------------------\n",
      "second_study\n",
      "\t 3 second study\n",
      "--------------------------------------------\n",
      "executable_player\n",
      "\t 2 player executable\n",
      "--------------------------------------------\n",
      "manager_transaction\n",
      "\t 2 transaction manager\n",
      "--------------------------------------------\n",
      "large_software_system\n",
      "\t 2 large software systems\n",
      "--------------------------------------------\n",
      "functionality_test\n",
      "\t 3 functionality tests\n",
      "--------------------------------------------\n",
      "player_program\n",
      "\t 3 player program\n",
      "--------------------------------------------\n",
      "software_system\n",
      "\t 4 software systems\n",
      "\t 2 software system\n",
      "\t 1 system software\n",
      "--------------------------------------------\n",
      "hour_minute\n",
      "\t 1 hours and 39 minutes\n",
      "\t 1 minutes and 2 hours\n",
      "--------------------------------------------\n",
      "replace_version\n",
      "\t 1 versions of replace\n",
      "\t 1 version 26 of replace\n",
      "\t 1 version 19 of replace\n",
      "--------------------------------------------\n",
      "deviation_standard\n",
      "\t 4 standard deviation\n",
      "--------------------------------------------\n",
      "minimization_selection_technique_test\n",
      "\t 2 minimization test selection technique\n",
      "--------------------------------------------\n",
      "effectiveness_relativity\n",
      "\t 2 relativity effectiveness\n",
      "--------------------------------------------\n",
      "case_such\n",
      "\t 1 cases such\n",
      "\t 1 such cases\n",
      "--------------------------------------------\n",
      "goodness_reason\n",
      "\t 2 goodness reasons\n",
      "\t 1 goodness reason\n",
      "--------------------------------------------\n",
      "program_simpleness\n",
      "\t 1 simpleness programs\n",
      "\t 1 simpleness program\n",
      "--------------------------------------------\n",
      "artifact_manufactured\n",
      "\t 2 manufactured artifacts\n",
      "--------------------------------------------\n",
      "analysis_time\n",
      "\t 1 analysis times\n",
      "\t 1 analysis time\n",
      "--------------------------------------------\n",
      "product_software\n",
      "\t 2 software product\n",
      "--------------------------------------------\n",
      "developer_software_user\n",
      "\t 2 developers and users of software\n",
      "--------------------------------------------\n",
      "empiricism_work\n",
      "\t 4 empiricism work\n",
      "--------------------------------------------\n",
      "otherness_regression_selection_test\n",
      "\t 2 otherness regression test selection\n",
      "--------------------------------------------\n",
      "newness_test\n",
      "\t 2 newness tests\n",
      "--------------------------------------------\n",
      "futurity_work\n",
      "\t 3 futurity work\n",
      "--------------------------------------------\n",
      "design_suite_test\n",
      "\t 2 test suite design\n",
      "--------------------------------------------\n",
      "london_s.\n",
      "\t 2 s. london\n",
      "--------------------------------------------\n",
      "conference_maintenance_proceeding_software\n",
      "\t 20 proceedings of the conference on software maintenance\n",
      "--------------------------------------------\n",
      "addison_wesley\n",
      "\t 6 addison wesley\n",
      "--------------------------------------------\n",
      "ostrand_t.\n",
      "\t 2 t. ostrand\n",
      "--------------------------------------------\n",
      "horwitz_s.\n",
      "\t 3 s. horwitz\n",
      "--------------------------------------------\n",
      "languages_principle_programming\n",
      "\t 2 principles of programming languages\n",
      "--------------------------------------------\n",
      "b._beizer\n",
      "\t 2 b. beizer\n",
      "--------------------------------------------\n",
      "software_testing\n",
      "\t 3 software testing\n",
      "--------------------------------------------\n",
      "new_york\n",
      "\t 8 new york\n",
      "--------------------------------------------\n",
      "john_sons_wiley\n",
      "\t 1 john wiley and sons\n",
      "\t 1 john wiley & sons\n",
      "--------------------------------------------\n",
      "binkley_d.\n",
      "\t 2 d. binkley\n",
      "--------------------------------------------\n",
      "d._hoffman\n",
      "\t 3 d. hoffman\n",
      "--------------------------------------------\n",
      "16th_conference_international_proceeding\n",
      "\t 2 proceedings of the 16th international conference\n",
      "--------------------------------------------\n",
      "engineering_software\n",
      "\t 12 software engineering\n",
      "--------------------------------------------\n",
      "fischer_k.f.\n",
      "\t 2 k.f. fischer\n",
      "--------------------------------------------\n",
      "gupta_r.\n",
      "\t 2 r. gupta\n",
      "--------------------------------------------\n",
      "harrold_m.j.\n",
      "\t 8 m.j. harrold\n",
      "--------------------------------------------\n",
      "m.l._soffa\n",
      "\t 5 m.l. soffa\n",
      "--------------------------------------------\n",
      "g._rothermel\n",
      "\t 4 g. rothermel\n",
      "--------------------------------------------\n",
      "datum_increment\n",
      "\t 2 increment data\n",
      "--------------------------------------------\n",
      "hartmann_j.\n",
      "\t 3 j. hartmann\n",
      "--------------------------------------------\n",
      "d.j._robson\n",
      "\t 2 d.j. robson\n",
      "--------------------------------------------\n",
      "maintenance_software\n",
      "\t 11 software maintenance\n",
      "--------------------------------------------\n",
      "ieee_software\n",
      "\t 4 ieee software\n",
      "--------------------------------------------\n",
      "reps_t.\n",
      "\t 2 t. reps\n",
      "--------------------------------------------\n",
      "journal_software\n",
      "\t 2 journal of systems and software\n",
      "--------------------------------------------\n",
      "h.k.n._leung\n",
      "\t 2 h.k.n. leung\n",
      "--------------------------------------------\n",
      "h.k.n._l.j._leung_white\n",
      "\t 1 h.k.n. leung and l.j. white\n",
      "\t 1 l.j. white and h.k.n. leung\n",
      "--------------------------------------------\n",
      "l.j._white\n",
      "\t 2 l.j. white\n",
      "--------------------------------------------\n",
      "cost_model\n",
      "\t 2 cost model\n",
      "--------------------------------------------\n",
      "conference_proceeding\n",
      "\t 2 conference proceedings\n",
      "--------------------------------------------\n",
      "acm_communication\n",
      "\t 3 communications of the acm\n",
      "--------------------------------------------\n",
      "conference_proceedings\n",
      "\t 3 conference proceedings\n",
      "--------------------------------------------\n",
      "empiricism_technique\n",
      "\t 2 empiricism techniques\n",
      "\t 1 empiricism technique\n",
      "--------------------------------------------\n",
      "edition_second\n",
      "\t 2 second edition\n",
      "--------------------------------------------\n",
      "w._yang\n",
      "\t 2 w. yang\n",
      "--------------------------------------------\n",
      "acm_engineering_software_transaction\n",
      "\t 2 acm transactions on software engineering\n",
      "--------------------------------------------\n",
      "reality_time\n",
      "\t 2 reality time\n",
      "--------------------------------------------\n",
      "occam_razor\n",
      "\t 2 occam 's razor\n",
      "--------------------------------------------\n",
      "computer_modernity\n",
      "\t 1 modernity computers\n",
      "\t 1 modernity computer\n",
      "--------------------------------------------\n",
      "language_occam_programming\n",
      "\t 1 programming language occam\n",
      "\t 1 occam programming language\n",
      "--------------------------------------------\n",
      "language_programming\n",
      "\t 4 programming languages\n",
      "\t 3 programming language\n",
      "--------------------------------------------\n",
      "lex_yacc\n",
      "\t 2 lex and yacc\n",
      "--------------------------------------------\n",
      "c_code\n",
      "\t 10 c code\n",
      "--------------------------------------------\n",
      "end_front\n",
      "\t 2 front end\n",
      "--------------------------------------------\n",
      "application_code\n",
      "\t 2 application code\n",
      "--------------------------------------------\n",
      "c_compiler\n",
      "\t 5 c compiler\n",
      "\t 1 c compilers\n",
      "--------------------------------------------\n",
      "module_object\n",
      "\t 2 object module\n",
      "\t 1 object modules\n",
      "--------------------------------------------\n",
      "language_specification\n",
      "\t 2 specification language\n",
      "--------------------------------------------\n",
      "automaton_virtual\n",
      "\t 3 virtual automaton\n",
      "--------------------------------------------\n",
      "infinity_lookahead\n",
      "\t 2 infinity lookahead\n",
      "--------------------------------------------\n",
      "basic_construct\n",
      "\t 1 basic constructs\n",
      "\t 1 basic construct\n",
      "--------------------------------------------\n",
      "precc_specification\n",
      "\t 7 precc specification\n",
      "\t 3 precc specifications\n",
      "--------------------------------------------\n",
      "extra_flexibility\n",
      "\t 2 extra flexibility\n",
      "--------------------------------------------\n",
      "flexibility_greatness\n",
      "\t 2 greatness flexibility\n",
      "--------------------------------------------\n",
      "call_function\n",
      "\t 3 function calls\n",
      "\t 1 function call\n",
      "--------------------------------------------\n",
      "c_call_stack\n",
      "\t 2 c call stack\n",
      "--------------------------------------------\n",
      "c_stack\n",
      "\t 2 c stack\n",
      "--------------------------------------------\n",
      "concreteness_syntax\n",
      "\t 7 concreteness syntax\n",
      "--------------------------------------------\n",
      "analyser_lexis\n",
      "\t 2 lexis analyser\n",
      "--------------------------------------------\n",
      "many_point\n",
      "\t 2 many points\n",
      "--------------------------------------------\n",
      "block_structure\n",
      "\t 2 block structure\n",
      "--------------------------------------------\n",
      "highness_language_level\n",
      "\t 2 highness level language\n",
      "\t 1 highness level languages\n",
      "--------------------------------------------\n",
      "such_tool\n",
      "\t 2 such tools\n",
      "--------------------------------------------\n",
      "input_language\n",
      "\t 2 input language\n",
      "--------------------------------------------\n",
      "parse_specification\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 2 parse specification\n",
      "--------------------------------------------\n",
      "correctness_parser\n",
      "\t 1 correctness parsers\n",
      "\t 1 parser correctness\n",
      "--------------------------------------------\n",
      "parser_precc\n",
      "\t 2 precc parser\n",
      "--------------------------------------------\n",
      "concreteness_specification\n",
      "\t 2 concreteness specification\n",
      "--------------------------------------------\n",
      "sameness_way\n",
      "\t 3 sameness way\n",
      "--------------------------------------------\n",
      "default_lexer\n",
      "\t 2 default lexer\n",
      "--------------------------------------------\n",
      "precc_script\n",
      "\t 1 precc script\n",
      "\t 1 precc scripts\n",
      "--------------------------------------------\n",
      "more_time\n",
      "\t 2 more times\n",
      "\t 1 more time\n",
      "--------------------------------------------\n",
      "declare_semantic\n",
      "\t 2 declare semantics\n",
      "--------------------------------------------\n",
      "effect_side\n",
      "\t 4 side effects\n",
      "\t 2 side effect\n",
      "--------------------------------------------\n",
      "production_rule\n",
      "\t 2 production rules\n",
      "--------------------------------------------\n",
      "emptiness_string\n",
      "\t 2 emptiness string\n",
      "--------------------------------------------\n",
      "c_macros\n",
      "\t 2 c macros\n",
      "--------------------------------------------\n",
      "expression_islower\n",
      "\t 2 islower expression\n",
      "--------------------------------------------\n",
      "muchness_work\n",
      "\t 1 muchness of the work\n",
      "\t 1 muchness work\n",
      "--------------------------------------------\n",
      "springer_verlag\n",
      "\t 12 springer verlag\n",
      "--------------------------------------------\n",
      "john_wiley\n",
      "\t 2 john wiley\n",
      "--------------------------------------------\n",
      "computing_laboratory_oxford_university\n",
      "\t 2 oxford university computing laboratory\n",
      "--------------------------------------------\n",
      "l.m._wegner\n",
      "\t 2 l.m. wegner\n",
      "--------------------------------------------\n",
      "computer_science\n",
      "\t 8 computer science\n",
      "--------------------------------------------\n",
      "international_sri\n",
      "\t 3 sri international\n",
      "--------------------------------------------\n",
      "information_processing\n",
      "\t 2 information processing\n",
      "--------------------------------------------\n",
      "d._weber_wulff\n",
      "\t 2 d. weber wulff\n",
      "--------------------------------------------\n",
      "information_more\n",
      "\t 3 more information\n",
      "--------------------------------------------\n",
      "flesh_language\n",
      "\t 4 flesh language\n",
      "--------------------------------------------\n",
      "system_uga\n",
      "\t 2 uga system\n",
      "--------------------------------------------\n",
      "overall_structure\n",
      "\t 3 overall structure\n",
      "--------------------------------------------\n",
      "detail_less\n",
      "\t 2 less detail\n",
      "--------------------------------------------\n",
      "perspective_wall\n",
      "\t 3 perspective wall\n",
      "--------------------------------------------\n",
      "panel_side\n",
      "\t 2 side panels\n",
      "--------------------------------------------\n",
      "class_particularity\n",
      "\t 2 particularity class\n",
      "--------------------------------------------\n",
      "data_set\n",
      "\t 3 data sets\n",
      "\t 1 data set\n",
      "--------------------------------------------\n",
      "perspective_view\n",
      "\t 2 perspective view\n",
      "--------------------------------------------\n",
      "hand_otherness\n",
      "\t 25 otherness hand\n",
      "--------------------------------------------\n",
      "cone_tree\n",
      "\t 7 cone tree\n",
      "\t 5 cone trees\n",
      "--------------------------------------------\n",
      "relation_space\n",
      "\t 5 space relations\n",
      "--------------------------------------------\n",
      "dimensionality_screen\n",
      "\t 1 dimensionality screens\n",
      "\t 1 dimensionality screen\n",
      "--------------------------------------------\n",
      "data_large_set\n",
      "\t 1 large data sets\n",
      "\t 1 large data set\n",
      "--------------------------------------------\n",
      "color_such\n",
      "\t 2 such as color\n",
      "--------------------------------------------\n",
      "behavior_object\n",
      "\t 3 object behavior\n",
      "\t 1 object behaviors\n",
      "--------------------------------------------\n",
      "object_tradition\n",
      "\t 2 tradition object\n",
      "--------------------------------------------\n",
      "complexity_object\n",
      "\t 1 complexity objects\n",
      "\t 1 complexity object\n",
      "--------------------------------------------\n",
      "csg_hierarchy\n",
      "\t 2 csg hierarchy\n",
      "--------------------------------------------\n",
      "tool_visualization\n",
      "\t 2 visualization tool\n",
      "--------------------------------------------\n",
      "information_semantics\n",
      "\t 2 semantics information\n",
      "--------------------------------------------\n",
      "additional_information\n",
      "\t 3 additional information\n",
      "--------------------------------------------\n",
      "file_size\n",
      "\t 1 file size\n",
      "\t 1 file sizes\n",
      "--------------------------------------------\n",
      "excel_tool\n",
      "\t 2 excel tool\n",
      "--------------------------------------------\n",
      "general_trend\n",
      "\t 2 general trends\n",
      "--------------------------------------------\n",
      "general_impression\n",
      "\t 2 general impression\n",
      "--------------------------------------------\n",
      "node_size\n",
      "\t 1 node size\n",
      "\t 1 size of the nodes\n",
      "--------------------------------------------\n",
      "large_object\n",
      "\t 1 large objects\n",
      "\t 1 large object\n",
      "--------------------------------------------\n",
      "question_such\n",
      "\t 3 such questions\n",
      "\t 1 questions such\n",
      "--------------------------------------------\n",
      "interface_user\n",
      "\t 4 user interface\n",
      "\t 2 user interfaces\n",
      "--------------------------------------------\n",
      "complexity_visual\n",
      "\t 2 visual complexity\n",
      "--------------------------------------------\n",
      "figure_tree\n",
      "\t 2 tree figure\n",
      "--------------------------------------------\n",
      "dimensionality_object\n",
      "\t 2 dimensionality object\n",
      "--------------------------------------------\n",
      "high_level\n",
      "\t 1 higher level\n",
      "\t 1 higher levels\n",
      "--------------------------------------------\n",
      "node_parent\n",
      "\t 1 parent nodes\n",
      "\t 1 parent node\n",
      "--------------------------------------------\n",
      "case_many\n",
      "\t 3 many cases\n",
      "\t 1 many of these cases\n",
      "--------------------------------------------\n",
      "such_system\n",
      "\t 1 system such\n",
      "\t 1 such system\n",
      "--------------------------------------------\n",
      "datum_hierarchy\n",
      "\t 3 hierarchy data\n",
      "--------------------------------------------\n",
      "futurity_research\n",
      "\t 2 futurity research\n",
      "--------------------------------------------\n",
      "acm_conf_sigchi\n",
      "\t 6 acm sigchi conf\n",
      "--------------------------------------------\n",
      "computing_factors_human\n",
      "\t 6 human factors in computing\n",
      "--------------------------------------------\n",
      "c._robert_zeleznik\n",
      "\t 2 robert c. zeleznik\n",
      "--------------------------------------------\n",
      "computer_department_science\n",
      "\t 4 department of computer science\n",
      "\t 1 computer science department\n",
      "--------------------------------------------\n",
      "brown_university\n",
      "\t 3 brown university\n",
      "--------------------------------------------\n",
      "cache_coherence_scheme_software\n",
      "\t 1 software cache coherence scheme\n",
      "\t 1 software cache coherence schemes\n",
      "--------------------------------------------\n",
      "memory_virtual\n",
      "\t 2 virtual memory\n",
      "--------------------------------------------\n",
      "memory_multiprocessor\n",
      "\t 3 memory multiprocessors\n",
      "--------------------------------------------\n",
      "cache_coherence\n",
      "\t 2 cache coherence\n",
      "--------------------------------------------\n",
      "hardware_multiprocessor_specialness\n",
      "\t 2 specialness multiprocessor hardware\n",
      "--------------------------------------------\n",
      "compiler_support\n",
      "\t 4 compiler support\n",
      "--------------------------------------------\n",
      "consistency_differ_model\n",
      "\t 2 differ consistency models\n",
      "--------------------------------------------\n",
      "consistency_model_vm\n",
      "\t 1 consistency models for the vm\n",
      "\t 1 consistency model for the vm\n",
      "--------------------------------------------\n",
      "consistency_sequence\n",
      "\t 5 sequence consistency\n",
      "--------------------------------------------\n",
      "consistency_laziness_release\n",
      "\t 3 laziness release consistency\n",
      "--------------------------------------------\n",
      "result_simulation\n",
      "\t 2 simulation results\n",
      "--------------------------------------------\n",
      "cache_coherence_scheme\n",
      "\t 4 cache coherence schemes\n",
      "--------------------------------------------\n",
      "scale_smallness\n",
      "\t 2 smallness scale\n",
      "--------------------------------------------\n",
      "cache_cohere\n",
      "\t 2 caches cohere\n",
      "--------------------------------------------\n",
      "shelf_uniprocessor\n",
      "\t 2 shelf uniprocessors\n",
      "--------------------------------------------\n",
      "arbitrariness_interconnection\n",
      "\t 2 arbitrariness interconnections\n",
      "--------------------------------------------\n",
      "bus_transaction\n",
      "\t 1 transactions on this bus\n",
      "\t 1 bus transaction\n",
      "--------------------------------------------\n",
      "action_appropriateness\n",
      "\t 2 appropriateness actions\n",
      "--------------------------------------------\n",
      "boundary_loop\n",
      "\t 2 loop boundaries\n",
      "--------------------------------------------\n",
      "main_memory\n",
      "\t 6 main memory\n",
      "--------------------------------------------\n",
      "similarity_technique\n",
      "\t 3 similarity techniques\n",
      "--------------------------------------------\n",
      "cache_line\n",
      "\t 13 cache lines\n",
      "--------------------------------------------\n",
      "invalidation_unnecessary\n",
      "\t 2 unnecessary invalidations\n",
      "--------------------------------------------\n",
      "few_instruction\n",
      "\t 2 few instructions\n",
      "--------------------------------------------\n",
      "access_memory\n",
      "\t 8 memory accesses\n",
      "\t 3 memory access\n",
      "--------------------------------------------\n",
      "hardware_specialness_support\n",
      "\t 2 specialness hardware support\n",
      "--------------------------------------------\n",
      "memory_module\n",
      "\t 8 memory modules\n",
      "--------------------------------------------\n",
      "parallel_program\n",
      "\t 1 parallel programs\n",
      "\t 1 parallel program\n",
      "--------------------------------------------\n",
      "prematureness_work\n",
      "\t 2 prematureness work\n",
      "--------------------------------------------\n",
      "consistency_memory_model\n",
      "\t 2 memory consistency models\n",
      "--------------------------------------------\n",
      "hardware_support\n",
      "\t 3 hardware support\n",
      "--------------------------------------------\n",
      "implementation_vm\n",
      "\t 2 implementation of the vm\n",
      "--------------------------------------------\n",
      "cached_line\n",
      "\t 2 cached lines\n",
      "--------------------------------------------\n",
      "back_cache_write\n",
      "\t 2 write back caches\n",
      "--------------------------------------------\n",
      "address_space\n",
      "\t 1 address space\n",
      "\t 1 address spaces\n",
      "--------------------------------------------\n",
      "page_table\n",
      "\t 1 page table\n",
      "\t 1 page tables\n",
      "--------------------------------------------\n",
      "bit_protection\n",
      "\t 2 protection bits\n",
      "--------------------------------------------\n",
      "differ_processor\n",
      "\t 4 differ processors\n",
      "\t 1 differ for each processor\n",
      "--------------------------------------------\n",
      "cache_consistency_model\n",
      "\t 1 cache consistency model\n",
      "\t 1 cache consistency models\n",
      "--------------------------------------------\n",
      "initial_state\n",
      "\t 2 initial state\n",
      "--------------------------------------------\n",
      "bit_page_protection_table\n",
      "\t 2 protection bits of all page table\n",
      "\t 1 protection bits in the page table\n",
      "--------------------------------------------\n",
      "i._page\n",
      "\t 5 page i.\n",
      "--------------------------------------------\n",
      "processor_system\n",
      "\t 4 processor system\n",
      "--------------------------------------------\n",
      "entry_page_table\n",
      "\t 1 page table entry\n",
      "\t 1 page table entries\n",
      "--------------------------------------------\n",
      "load_memory\n",
      "\t 1 memory load\n",
      "\t 1 memory loads\n",
      "--------------------------------------------\n",
      "coherence_scheme\n",
      "\t 2 coherence schemes\n",
      "\t 2 coherence scheme\n",
      "--------------------------------------------\n",
      "status_word\n",
      "\t 2 status word\n",
      "\t 1 status words\n",
      "--------------------------------------------\n",
      "number_processor\n",
      "\t 3 number of processors\n",
      "\t 1 processor number\n",
      "\t 1 numbers of processors\n",
      "--------------------------------------------\n",
      "invalidation_laziness_method\n",
      "\t 1 method laziness invalidation\n",
      "\t 1 laziness invalidation method\n",
      "--------------------------------------------\n",
      "invalidation_laziness\n",
      "\t 2 laziness invalidation\n",
      "--------------------------------------------\n",
      "datum_staleness\n",
      "\t 2 staleness data\n",
      "--------------------------------------------\n",
      "location_memory_physicality_sameness\n",
      "\t 2 sameness physicality memory location\n",
      "--------------------------------------------\n",
      "bit_highness_order_unused\n",
      "\t 2 unused highness order bits\n",
      "--------------------------------------------\n",
      "number_version\n",
      "\t 2 version number\n",
      "--------------------------------------------\n",
      "otherness_processor\n",
      "\t 5 otherness processors\n",
      "\t 5 otherness processor\n",
      "--------------------------------------------\n",
      "otherness_variable\n",
      "\t 2 otherness variables\n",
      "--------------------------------------------\n",
      "datum_structure\n",
      "\t 6 data structures\n",
      "\t 1 data structure\n",
      "--------------------------------------------\n",
      "consistency_model_relaxed\n",
      "\t 1 relaxed consistency models\n",
      "\t 1 relaxed consistency model\n",
      "--------------------------------------------\n",
      "fault_page\n",
      "\t 3 page faults\n",
      "\t 1 page fault\n",
      "--------------------------------------------\n",
      "falsity_sharing\n",
      "\t 4 falsity sharing\n",
      "--------------------------------------------\n",
      "t1_time\n",
      "\t 2 time t1\n",
      "--------------------------------------------\n",
      "fault_write\n",
      "\t 2 write fault\n",
      "--------------------------------------------\n",
      "access_synchronization\n",
      "\t 2 synchronization accesses\n",
      "--------------------------------------------\n",
      "access_store\n",
      "\t 2 store access\n",
      "--------------------------------------------\n",
      "access_release\n",
      "\t 2 release access\n",
      "\t 1 release accesses\n",
      "--------------------------------------------\n",
      "otherness_processor_respect\n",
      "\t 2 respect to any otherness processor\n",
      "--------------------------------------------\n",
      "page_shared\n",
      "\t 2 shared pages\n",
      "--------------------------------------------\n",
      "synchronization_variable\n",
      "\t 3 synchronization variables\n",
      "\t 2 synchronization variable\n",
      "--------------------------------------------\n",
      "buffer_write\n",
      "\t 5 write buffer\n",
      "--------------------------------------------\n",
      "access_write\n",
      "\t 2 write access\n",
      "--------------------------------------------\n",
      "implementation_lrc\n",
      "\t 2 implementation of lrc\n",
      "--------------------------------------------\n",
      "increment_weaki\n",
      "\t 2 increment weaki\n",
      "--------------------------------------------\n",
      "cache_entry\n",
      "\t 2 cache entries\n",
      "--------------------------------------------\n",
      "application_program\n",
      "\t 1 application programs\n",
      "\t 1 application program\n",
      "--------------------------------------------\n",
      "number_small\n",
      "\t 1 smallest number\n",
      "\t 1 smaller number\n",
      "--------------------------------------------\n",
      "queue_task\n",
      "\t 2 task queue\n",
      "--------------------------------------------\n",
      "series_step_time\n",
      "\t 2 series of time steps\n",
      "--------------------------------------------\n",
      "barrier_synchronization\n",
      "\t 2 barrier synchronization\n",
      "--------------------------------------------\n",
      "data_structure\n",
      "\t 4 data structure\n",
      "\t 2 data structures\n",
      "--------------------------------------------\n",
      "physicality_space\n",
      "\t 3 physicality space\n",
      "--------------------------------------------\n",
      "molecule_set\n",
      "\t 2 set of molecules\n",
      "--------------------------------------------\n",
      "processor_several\n",
      "\t 2 several processors\n",
      "--------------------------------------------\n",
      "cell_sameness_space\n",
      "\t 1 sameness space cell\n",
      "\t 1 sameness space cells\n",
      "--------------------------------------------\n",
      "sameness_step_time\n",
      "\t 2 sameness time step\n",
      "--------------------------------------------\n",
      "step_time\n",
      "\t 5 time steps\n",
      "\t 4 time step\n",
      "--------------------------------------------\n",
      "matrix_point\n",
      "\t 1 point matrix\n",
      "\t 1 point matrices\n",
      "--------------------------------------------\n",
      "memory_unit\n",
      "\t 2 memory unit\n",
      "--------------------------------------------\n",
      "byte_k\n",
      "\t 2 k bytes\n",
      "\t 1 k byte\n",
      "--------------------------------------------\n",
      "bus_contention\n",
      "\t 2 bus contention\n",
      "--------------------------------------------\n",
      "event_synchronization\n",
      "\t 2 synchronization events\n",
      "\t 1 synchronization event\n",
      "--------------------------------------------\n",
      "p1_processor\n",
      "\t 2 processor p1\n",
      "\t 2 processors p1\n",
      "--------------------------------------------\n",
      "lock_x\n",
      "\t 2 lock x\n",
      "--------------------------------------------\n",
      "fault_handler\n",
      "\t 1 fault handler\n",
      "\t 1 fault handlers\n",
      "--------------------------------------------\n",
      "paper_purpose\n",
      "\t 2 purpose of this paper\n",
      "--------------------------------------------\n",
      "locality_lowness\n",
      "\t 2 lowness locality\n",
      "--------------------------------------------\n",
      "degree_highness\n",
      "\t 1 highness degree\n",
      "\t 1 highness degrees\n",
      "--------------------------------------------\n",
      "case_otherness\n",
      "\t 2 otherness cases\n",
      "--------------------------------------------\n",
      "gain_performance\n",
      "\t 3 performance gains\n",
      "\t 1 performance gain\n",
      "--------------------------------------------\n",
      "execution_time_totality\n",
      "\t 7 totality execution time\n",
      "--------------------------------------------\n",
      "bus_load\n",
      "\t 1 load in on the bus\n",
      "\t 1 bus load\n",
      "--------------------------------------------\n",
      "mul_water\n",
      "\t 2 water and mul\n",
      "--------------------------------------------\n",
      "good_speedup\n",
      "\t 1 better speedups\n",
      "\t 1 best speedups\n",
      "\t 1 best speedup\n",
      "--------------------------------------------\n",
      "large_page\n",
      "\t 3 larger pages\n",
      "--------------------------------------------\n",
      "contention_extremity\n",
      "\t 2 extremity contention\n",
      "--------------------------------------------\n",
      "scheme_snooping\n",
      "\t 2 snooping scheme\n",
      "--------------------------------------------\n",
      "advantage_several\n",
      "\t 3 several advantages\n",
      "--------------------------------------------\n",
      "incoherence_page\n",
      "\t 2 incoherence pages\n",
      "--------------------------------------------\n",
      "acknowledgement_research\n",
      "\t 2 acknowledgements this research\n",
      "--------------------------------------------\n",
      "draft_early\n",
      "\t 1 earlier drafts\n",
      "\t 1 earlier draft\n",
      "--------------------------------------------\n",
      "d._hill_mark\n",
      "\t 2 mark d. hill\n",
      "--------------------------------------------\n",
      "architecture_computer\n",
      "\t 8 computer architecture\n",
      "--------------------------------------------\n",
      "hennessy_john\n",
      "\t 5 john hennessy\n",
      "--------------------------------------------\n",
      "conference_international_parallel_proceeding\n",
      "\t 1 proceedings of the 1985 international conference on parallel\n",
      "\t 1 proceedings of the 1988 international conference on parallel\n",
      "\t 1 proceedings of the 1989 international conference on parallel\n",
      "\t 1 proceedings of the 1986 international conference on parallel\n",
      "--------------------------------------------\n",
      "conference_international_proceeding_supercomputing\n",
      "\t 2 proceedings of the 1992 international conference on supercomputing\n",
      "--------------------------------------------\n",
      "12th_international_proceeding_symposium\n",
      "\t 2 proceedings of the 12th international symposium\n",
      "--------------------------------------------\n",
      "anoop_gupta\n",
      "\t 6 anoop gupta\n",
      "--------------------------------------------\n",
      "architectural_languages_programming_support\n",
      "\t 2 architectural support for programming languages\n",
      "--------------------------------------------\n",
      "james_laudon\n",
      "\t 3 james laudon\n",
      "--------------------------------------------\n",
      "joe_truman\n",
      "\t 2 truman joe\n",
      "--------------------------------------------\n",
      "david_nakahira\n",
      "\t 2 david nakahira\n",
      "--------------------------------------------\n",
      "luis_stevens\n",
      "\t 2 luis stevens\n",
      "--------------------------------------------\n",
      "dash_prototype_stanford\n",
      "\t 2 stanford dash prototype\n",
      "--------------------------------------------\n",
      "logic_overhead_performance\n",
      "\t 2 logic overhead and performance\n",
      "--------------------------------------------\n",
      "report_technique\n",
      "\t 8 technique report\n",
      "--------------------------------------------\n",
      "stanford_university\n",
      "\t 5 stanford university\n",
      "--------------------------------------------\n",
      "3rd_conference_international_proceeding\n",
      "\t 2 proceedings of the 3rd international conference\n",
      "--------------------------------------------\n",
      "logic_programming\n",
      "\t 13 logic programming\n",
      "--------------------------------------------\n",
      "dynamic_object\n",
      "\t 2 object dynamics\n",
      "--------------------------------------------\n",
      "classical_logic\n",
      "\t 8 classical logic\n",
      "--------------------------------------------\n",
      "change_object_state\n",
      "\t 1 object state changes\n",
      "\t 1 object state change\n",
      "--------------------------------------------\n",
      "approach_differ\n",
      "\t 4 differ approach\n",
      "\t 1 differ approaches\n",
      "--------------------------------------------\n",
      "change_state\n",
      "\t 6 state change\n",
      "--------------------------------------------\n",
      "mutability_state\n",
      "\t 2 mutability state\n",
      "--------------------------------------------\n",
      "aspect_stillness\n",
      "\t 2 stillness aspects\n",
      "--------------------------------------------\n",
      "logic_variable\n",
      "\t 2 logic variables\n",
      "\t 1 logic variable\n",
      "--------------------------------------------\n",
      "object_otherness\n",
      "\t 2 otherness object\n",
      "\t 1 otherness objects\n",
      "--------------------------------------------\n",
      "object_state\n",
      "\t 6 object state\n",
      "--------------------------------------------\n",
      "otherness_side\n",
      "\t 3 otherness side\n",
      "--------------------------------------------\n",
      "object_orientation\n",
      "\t 4 object orientation\n",
      "--------------------------------------------\n",
      "react_system\n",
      "\t 2 react systems\n",
      "--------------------------------------------\n",
      "large_number\n",
      "\t 2 large number\n",
      "\t 1 larger number\n",
      "--------------------------------------------\n",
      "newness_state\n",
      "\t 3 newness state\n",
      "--------------------------------------------\n",
      "logicality_semantic\n",
      "\t 3 logicality semantics\n",
      "--------------------------------------------\n",
      "general_language_oolp\n",
      "\t 2 general oolp language\n",
      "--------------------------------------------\n",
      "logic_transaction\n",
      "\t 3 transaction logic\n",
      "--------------------------------------------\n",
      "logicality_object\n",
      "\t 4 logicality objects\n",
      "--------------------------------------------\n",
      "linear_logic\n",
      "\t 16 linear logic\n",
      "--------------------------------------------\n",
      "language_oolp\n",
      "\t 2 oolp language\n",
      "--------------------------------------------\n",
      "logic_program\n",
      "\t 2 logic program\n",
      "--------------------------------------------\n",
      "declare_effort\n",
      "\t 2 declare effort\n",
      "--------------------------------------------\n",
      "conjunction_logicality\n",
      "\t 2 logicality conjunction\n",
      "--------------------------------------------\n",
      "object_reality_world\n",
      "\t 2 reality world objects\n",
      "--------------------------------------------\n",
      "object_prolog\n",
      "\t 2 object prolog\n",
      "--------------------------------------------\n",
      "argument_term\n",
      "\t 1 term argument\n",
      "\t 1 argument terms\n",
      "--------------------------------------------\n",
      "completeness_history\n",
      "\t 1 completeness histories\n",
      "\t 1 completeness history\n",
      "--------------------------------------------\n",
      "database_declare\n",
      "\t 2 declare database\n",
      "--------------------------------------------\n",
      "knowledge_newness\n",
      "\t 2 newness knowledge\n",
      "--------------------------------------------\n",
      "general_logic_theory\n",
      "\t 1 general logic theories\n",
      "\t 1 theory of general logics\n",
      "--------------------------------------------\n",
      "issue_monotonicity\n",
      "\t 3 monotonicity issues\n",
      "--------------------------------------------\n",
      "oldness_theory\n",
      "\t 2 oldness theory\n",
      "--------------------------------------------\n",
      "possibility_world\n",
      "\t 5 possibility worlds\n",
      "--------------------------------------------\n",
      "calculus_event\n",
      "\t 2 event calculus\n",
      "\t 1 calculus of events\n",
      "--------------------------------------------\n",
      "change_minimal\n",
      "\t 4 minimal change\n",
      "--------------------------------------------\n",
      "database_update\n",
      "\t 2 database updates\n",
      "--------------------------------------------\n",
      "r_t\n",
      "\t 6 t r\n",
      "--------------------------------------------\n",
      "base_transition\n",
      "\t 3 transition base\n",
      "--------------------------------------------\n",
      "element_update\n",
      "\t 2 element updates\n",
      "--------------------------------------------\n",
      "model_particularity\n",
      "\t 2 particularity model\n",
      "--------------------------------------------\n",
      "sameness_time\n",
      "\t 2 sameness time\n",
      "--------------------------------------------\n",
      "database_transaction\n",
      "\t 1 database transactions\n",
      "\t 1 transactions on database\n",
      "--------------------------------------------\n",
      "compositional_property\n",
      "\t 2 compositional properties\n",
      "--------------------------------------------\n",
      "choice_determinism\n",
      "\t 2 determinism choice\n",
      "--------------------------------------------\n",
      "efficiency_implementation\n",
      "\t 2 efficiency implementation\n",
      "--------------------------------------------\n",
      "imperativeness_program\n",
      "\t 2 imperativeness programs\n",
      "--------------------------------------------\n",
      "dynamic_logic\n",
      "\t 4 dynamic logic\n",
      "--------------------------------------------\n",
      "formula_oe\n",
      "\t 2 formulae oe\n",
      "--------------------------------------------\n",
      "context_free_grammar\n",
      "\t 1 context free grammar\n",
      "\t 1 context free grammars\n",
      "--------------------------------------------\n",
      "abstract_data_types\n",
      "\t 2 abstract data types\n",
      "--------------------------------------------\n",
      "identifier_object\n",
      "\t 2 object identifiers\n",
      "\t 1 object identifier\n",
      "--------------------------------------------\n",
      "aspect_dynamism\n",
      "\t 2 dynamism aspects\n",
      "--------------------------------------------\n",
      "diploma_thesis\n",
      "\t 2 diploma thesis\n",
      "--------------------------------------------\n",
      "database_theory\n",
      "\t 1 theory of database\n",
      "\t 1 database theory\n",
      "--------------------------------------------\n",
      "prolog_purity\n",
      "\t 2 purity prolog\n",
      "--------------------------------------------\n",
      "logic_mode\n",
      "\t 2 mode logic\n",
      "--------------------------------------------\n",
      "approach_similarity\n",
      "\t 2 similarity approach\n",
      "--------------------------------------------\n",
      "hierarchy_inheritance\n",
      "\t 3 inheritance hierarchy\n",
      "--------------------------------------------\n",
      "proof_search\n",
      "\t 2 proof search\n",
      "--------------------------------------------\n",
      "process_proof\n",
      "\t 3 proof process\n",
      "--------------------------------------------\n",
      "concurrency_pseudo\n",
      "\t 2 pseudo concurrency\n",
      "--------------------------------------------\n",
      "development_simultaneity\n",
      "\t 2 simultaneity development\n",
      "--------------------------------------------\n",
      "message_stream\n",
      "\t 3 message stream\n",
      "\t 1 message streams\n",
      "--------------------------------------------\n",
      "message_term\n",
      "\t 2 message term\n",
      "--------------------------------------------\n",
      "concurrent_prolog\n",
      "\t 3 concurrent prolog\n",
      "--------------------------------------------\n",
      "currency_goal\n",
      "\t 2 currency goal\n",
      "--------------------------------------------\n",
      "clause_corresponding\n",
      "\t 2 corresponding clause\n",
      "--------------------------------------------\n",
      "concurrent_programming_prolog\n",
      "\t 2 programming in concurrent prolog\n",
      "--------------------------------------------\n",
      "conventionality_prolog\n",
      "\t 2 conventionality prolog\n",
      "--------------------------------------------\n",
      "level_lowness\n",
      "\t 2 lowness level\n",
      "--------------------------------------------\n",
      "coincide_language_lp\n",
      "\t 2 coincide lp language\n",
      "--------------------------------------------\n",
      "part_record\n",
      "\t 2 part records\n",
      "--------------------------------------------\n",
      "method_polymorphism\n",
      "\t 1 polymorphism method\n",
      "\t 1 polymorphism methods\n",
      "--------------------------------------------\n",
      "otherness_way\n",
      "\t 1 otherness ways\n",
      "\t 1 otherness way\n",
      "--------------------------------------------\n",
      "literalness_object\n",
      "\t 5 object literalness\n",
      "--------------------------------------------\n",
      "clause_program\n",
      "\t 1 program clause\n",
      "\t 1 program clauses\n",
      "--------------------------------------------\n",
      "literalness_procedure\n",
      "\t 2 procedure literalness\n",
      "--------------------------------------------\n",
      "literal_object\n",
      "\t 5 object literals\n",
      "--------------------------------------------\n",
      "newness_object\n",
      "\t 1 newness object\n",
      "\t 1 newness objects\n",
      "--------------------------------------------\n",
      "class_sameness\n",
      "\t 4 sameness class\n",
      "--------------------------------------------\n",
      "a_object\n",
      "\t 2 object a\n",
      "--------------------------------------------\n",
      "clause_head\n",
      "\t 1 head of the clause\n",
      "\t 1 clause heads\n",
      "\t 1 clause head\n",
      "--------------------------------------------\n",
      "conery_haridi\n",
      "\t 2 conery and haridi\n",
      "--------------------------------------------\n",
      "method_specificity\n",
      "\t 2 specificity method\n",
      "\t 1 specificity methods\n",
      "--------------------------------------------\n",
      "inheritance_mechanism\n",
      "\t 1 inheritance mechanism\n",
      "\t 1 inheritance mechanisms\n",
      "--------------------------------------------\n",
      "problem_similarity\n",
      "\t 2 similarity problem\n",
      "--------------------------------------------\n",
      "object_space\n",
      "\t 3 space objects\n",
      "\t 1 object space\n",
      "--------------------------------------------\n",
      "fineness_granularity\n",
      "\t 2 fineness granularity\n",
      "--------------------------------------------\n",
      "implication_linearity\n",
      "\t 2 linearity implication\n",
      "--------------------------------------------\n",
      "linear_object\n",
      "\t 2 linear objects\n",
      "--------------------------------------------\n",
      "andreoli_pareschi\n",
      "\t 2 andreoli and pareschi\n",
      "--------------------------------------------\n",
      "corresponding_method\n",
      "\t 2 corresponding method\n",
      "--------------------------------------------\n",
      "inference_process\n",
      "\t 2 inference process\n",
      "--------------------------------------------\n",
      "awareness_resource\n",
      "\t 3 resource awareness\n",
      "--------------------------------------------\n",
      "many_way\n",
      "\t 4 many ways\n",
      "--------------------------------------------\n",
      "naturalness_way\n",
      "\t 1 naturalness ways\n",
      "\t 1 naturalness way\n",
      "--------------------------------------------\n",
      "inference_rule\n",
      "\t 2 inference rule\n",
      "--------------------------------------------\n",
      "clause_horn_programming\n",
      "\t 2 horn clause programming\n",
      "--------------------------------------------\n",
      "particularity_style\n",
      "\t 3 particularity style\n",
      "--------------------------------------------\n",
      "coincide_logicality_object_theory\n",
      "\t 2 logicality theory of coincide objects\n",
      "--------------------------------------------\n",
      "language_logic_programming\n",
      "\t 2 logic programming language\n",
      "--------------------------------------------\n",
      "programming_relational\n",
      "\t 2 relational programming\n",
      "--------------------------------------------\n",
      "coincide_programming\n",
      "\t 3 coincide programming\n",
      "--------------------------------------------\n",
      "rewrite_rule\n",
      "\t 2 rewrite rule\n",
      "\t 1 rewrite rules\n",
      "--------------------------------------------\n",
      "class_object\n",
      "\t 1 object class\n",
      "\t 1 classes and objects\n",
      "--------------------------------------------\n",
      "aci_operation\n",
      "\t 3 aci operation\n",
      "--------------------------------------------\n",
      "currency_set\n",
      "\t 5 currency set\n",
      "--------------------------------------------\n",
      "logic_mode_multi_programming\n",
      "\t 2 multi mode logic programming\n",
      "--------------------------------------------\n",
      "object_structure\n",
      "\t 2 object structure\n",
      "--------------------------------------------\n",
      "importance_point\n",
      "\t 2 importance point\n",
      "\t 1 importance points\n",
      "--------------------------------------------\n",
      "abiteboul_s.\n",
      "\t 2 s. abiteboul\n",
      "--------------------------------------------\n",
      "database_principle\n",
      "\t 3 principles of database\n",
      "--------------------------------------------\n",
      "acm_sigact_sigart_sigmod\n",
      "\t 2 acm sigact sigmod sigart\n",
      "--------------------------------------------\n",
      "andreoli_j_m._r.\n",
      "\t 1 j m. andreoli and r.\n",
      "\t 1 j .- m. andreoli and r.\n",
      "--------------------------------------------\n",
      "linearity_object\n",
      "\t 2 linearity objects\n",
      "--------------------------------------------\n",
      "logicality_process\n",
      "\t 2 logicality processes\n",
      "--------------------------------------------\n",
      "mit_press\n",
      "\t 7 mit press\n",
      "--------------------------------------------\n",
      "pareschi_r.\n",
      "\t 2 r. pareschi\n",
      "--------------------------------------------\n",
      "notices_sigplan\n",
      "\t 3 sigplan notices\n",
      "--------------------------------------------\n",
      "computing_generation_new\n",
      "\t 4 new generation computing\n",
      "--------------------------------------------\n",
      "a._bonner_kifer_m.\n",
      "\t 2 a. bonner and m. kifer\n",
      "--------------------------------------------\n",
      "c._delobel\n",
      "\t 3 c. delobel\n",
      "--------------------------------------------\n",
      "kifer_m.\n",
      "\t 2 m. kifer\n",
      "--------------------------------------------\n",
      "masunaga_y.\n",
      "\t 2 y. masunaga\n",
      "--------------------------------------------\n",
      "chikayama_t.\n",
      "\t 2 t. chikayama\n",
      "--------------------------------------------\n",
      "computer_fifth_generation\n",
      "\t 1 fifth generation computers\n",
      "\t 1 fifth generation computer\n",
      "--------------------------------------------\n",
      "computing_generation_newness\n",
      "\t 2 newness generation computing\n",
      "--------------------------------------------\n",
      "conference_fifth_generation_international\n",
      "\t 2 international conference on fifth generation\n",
      "--------------------------------------------\n",
      "iclp'91_paper_position_workshop\n",
      "\t 2 position paper on the iclp'91 workshop\n",
      "--------------------------------------------\n",
      "conery_j._s.\n",
      "\t 3 j. s. conery\n",
      "--------------------------------------------\n",
      "oregon_university\n",
      "\t 2 university of oregon\n",
      "--------------------------------------------\n",
      "a._davison\n",
      "\t 3 a. davison\n",
      "--------------------------------------------\n",
      "report_technical\n",
      "\t 5 technical report\n",
      "--------------------------------------------\n",
      "enjalbert_p.\n",
      "\t 2 p. enjalbert\n",
      "--------------------------------------------\n",
      "algebraic_logic_programming\n",
      "\t 2 algebraic and logic programming\n",
      "--------------------------------------------\n",
      "knowledge_representation\n",
      "\t 1 representation of knowledge\n",
      "\t 1 knowledge representation\n",
      "--------------------------------------------\n",
      "diego_san\n",
      "\t 2 san diego\n",
      "--------------------------------------------\n",
      "fagin_r.\n",
      "\t 2 r. fagin\n",
      "--------------------------------------------\n",
      "j._ullman\n",
      "\t 2 j. ullman\n",
      "--------------------------------------------\n",
      "m._vardi\n",
      "\t 2 m. vardi\n",
      "--------------------------------------------\n",
      "cerro_del_fari~nas_l.\n",
      "\t 3 l. fari~nas del cerro\n",
      "--------------------------------------------\n",
      "a._herzig\n",
      "\t 2 a. herzig\n",
      "--------------------------------------------\n",
      "academic_press\n",
      "\t 3 academic press\n",
      "--------------------------------------------\n",
      "linearity_logic\n",
      "\t 3 linearity logic\n",
      "--------------------------------------------\n",
      "d._harel\n",
      "\t 2 d. harel\n",
      "--------------------------------------------\n",
      "logic_process\n",
      "\t 2 process logic\n",
      "--------------------------------------------\n",
      "fullness_paper\n",
      "\t 2 fullness paper\n",
      "--------------------------------------------\n",
      "master_thesis\n",
      "\t 2 master 's thesis\n",
      "--------------------------------------------\n",
      "anonymity_avail_duck.dfki.uni-sb.de_ftp\n",
      "\t 3 avail by anonymity ftp from duck.dfki.uni-sb.de\n",
      "--------------------------------------------\n",
      "computer_logic_science\n",
      "\t 2 logic in computer science\n",
      "--------------------------------------------\n",
      "computer_ieee_press_society\n",
      "\t 7 ieee computer society press\n",
      "--------------------------------------------\n",
      "ishikawa_m._tokoro_y.\n",
      "\t 2 y. ishikawa and m. tokoro\n",
      "--------------------------------------------\n",
      "jungclaus_r.\n",
      "\t 3 r. jungclaus\n",
      "--------------------------------------------\n",
      "phd_thesis\n",
      "\t 2 phd thesis\n",
      "--------------------------------------------\n",
      "braunschweig_technical_university\n",
      "\t 2 technical university braunschweig\n",
      "--------------------------------------------\n",
      "g._saake\n",
      "\t 2 g. saake\n",
      "--------------------------------------------\n",
      "c._sernadas\n",
      "\t 2 c. sernadas\n",
      "--------------------------------------------\n",
      "abramsky_s._s._t.\n",
      "\t 2 s. abramsky and t. s.\n",
      "--------------------------------------------\n",
      "e._maibaum\n",
      "\t 2 e. maibaum\n",
      "--------------------------------------------\n",
      "conference_international_joint_theory\n",
      "\t 2 international joint conference on theory\n",
      "--------------------------------------------\n",
      "development_software\n",
      "\t 5 software development\n",
      "--------------------------------------------\n",
      "k._kahn_m.\n",
      "\t 5 k. m. kahn\n",
      "--------------------------------------------\n",
      "coincide_logicality_object\n",
      "\t 2 logicality coincide objects\n",
      "--------------------------------------------\n",
      "conference_european_object\n",
      "\t 3 european conference on object\n",
      "--------------------------------------------\n",
      "d._e._tribble\n",
      "\t 2 e. d. tribble\n",
      "--------------------------------------------\n",
      "m._miller_s.\n",
      "\t 2 m. s. miller\n",
      "--------------------------------------------\n",
      "bobrow_d._g.\n",
      "\t 2 d. g. bobrow\n",
      "--------------------------------------------\n",
      "object_oriented_programming\n",
      "\t 2 object oriented programming\n",
      "--------------------------------------------\n",
      "kanovich_m.\n",
      "\t 2 m. kanovich\n",
      "--------------------------------------------\n",
      "completeness_np\n",
      "\t 11 np completeness\n",
      "--------------------------------------------\n",
      "journal_logic_programming\n",
      "\t 2 journal of logic programming\n",
      "--------------------------------------------\n",
      "ccl_pub\n",
      "\t 2 pub / ccl\n",
      "--------------------------------------------\n",
      "report_research\n",
      "\t 4 research report\n",
      "--------------------------------------------\n",
      "altos_los\n",
      "\t 9 los altos\n",
      "--------------------------------------------\n",
      "kaufmann_morgan\n",
      "\t 9 morgan kaufmann\n",
      "--------------------------------------------\n",
      "hall_prentice\n",
      "\t 7 prentice hall\n",
      "--------------------------------------------\n",
      "j._meseguer\n",
      "\t 4 j. meseguer\n",
      "--------------------------------------------\n",
      "artificial_intelligence\n",
      "\t 25 artificial intelligence\n",
      "--------------------------------------------\n",
      "m._winslett\n",
      "\t 2 m. winslett\n",
      "--------------------------------------------\n",
      "chikayama_k._t._yoshida\n",
      "\t 2 k. yoshida and t. chikayama\n",
      "--------------------------------------------\n",
      "determinism_newness_parallel\n",
      "\t 2 newness determinism parallel\n",
      "--------------------------------------------\n",
      "communication_personalized\n",
      "\t 2 personalized communication\n",
      "--------------------------------------------\n",
      "c_split\n",
      "\t 3 split c\n",
      "--------------------------------------------\n",
      "ibm_sp-2-wn\n",
      "\t 6 ibm sp-2-wn\n",
      "--------------------------------------------\n",
      "cray_research_t3d.\n",
      "\t 2 cray research t3d.\n",
      "--------------------------------------------\n",
      "distribution_input\n",
      "\t 4 input distribution\n",
      "--------------------------------------------\n",
      "differ_platform\n",
      "\t 2 differ platforms\n",
      "--------------------------------------------\n",
      "algorithm_randomness_sample_sort\n",
      "\t 2 randomness sample sort algorithm\n",
      "--------------------------------------------\n",
      "algorithm_similarity\n",
      "\t 2 similarity algorithms\n",
      "--------------------------------------------\n",
      "algorithms_efficiency_prematureness\n",
      "\t 2 prematureness efficiency algorithms\n",
      "--------------------------------------------\n",
      "algorithm_randomized_sorting\n",
      "\t 2 randomized sorting algorithm\n",
      "--------------------------------------------\n",
      "memory_performance_requirement\n",
      "\t 2 performance and memory requirements\n",
      "--------------------------------------------\n",
      "regularity_sampling\n",
      "\t 3 regularity sampling\n",
      "--------------------------------------------\n",
      "communication_regularity\n",
      "\t 2 regularity communication\n",
      "--------------------------------------------\n",
      "primitiveness_transpose\n",
      "\t 2 transpose primitiveness\n",
      "--------------------------------------------\n",
      "sameness_size\n",
      "\t 2 sameness size\n",
      "--------------------------------------------\n",
      "array_singleness\n",
      "\t 2 singleness array\n",
      "--------------------------------------------\n",
      "communication_primitive\n",
      "\t 4 communication primitives\n",
      "--------------------------------------------\n",
      "algorithm_parallel\n",
      "\t 3 parallel algorithms\n",
      "--------------------------------------------\n",
      "oem_time\n",
      "\t 2 oem time\n",
      "--------------------------------------------\n",
      "block_permutation\n",
      "\t 2 block permutation\n",
      "--------------------------------------------\n",
      "p_processor\n",
      "\t 3 p processors\n",
      "\t 1 processors p\n",
      "--------------------------------------------\n",
      "input_size\n",
      "\t 3 input sizes\n",
      "\t 2 input size\n",
      "--------------------------------------------\n",
      "element_n\n",
      "\t 2 n elements\n",
      "--------------------------------------------\n",
      "group_p\n",
      "\t 2 p groups\n",
      "--------------------------------------------\n",
      "group_ith\n",
      "\t 2 ith group\n",
      "--------------------------------------------\n",
      "element_np\n",
      "\t 4 np elements\n",
      "--------------------------------------------\n",
      "processor_singleness\n",
      "\t 2 singleness processor\n",
      "--------------------------------------------\n",
      "input_value\n",
      "\t 2 input values\n",
      "\t 2 values of the input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 1 value input\n",
      "--------------------------------------------\n",
      "balance_load\n",
      "\t 6 load balance\n",
      "--------------------------------------------\n",
      "prematureness_study\n",
      "\t 1 prematureness studies\n",
      "\t 1 prematureness study\n",
      "--------------------------------------------\n",
      "completion_sorting\n",
      "\t 2 completion of sorting\n",
      "--------------------------------------------\n",
      "ffl_step\n",
      "\t 8 ffl step\n",
      "--------------------------------------------\n",
      "pi_processor\n",
      "\t 11 processor pi\n",
      "--------------------------------------------\n",
      "number_point\n",
      "\t 4 point numbers\n",
      "\t 1 point number\n",
      "--------------------------------------------\n",
      "pj_processor\n",
      "\t 4 processor pj\n",
      "--------------------------------------------\n",
      "pp_processor\n",
      "\t 4 processor pp\n",
      "--------------------------------------------\n",
      "binary_search\n",
      "\t 2 binary search\n",
      "--------------------------------------------\n",
      "less_value\n",
      "\t 2 value less\n",
      "--------------------------------------------\n",
      "element_th\n",
      "\t 3 th element\n",
      "--------------------------------------------\n",
      "input_pi_processor\n",
      "\t 2 input at processor pi\n",
      "--------------------------------------------\n",
      "log_o(sp_p\n",
      "\t 2 o(sp log p\n",
      "--------------------------------------------\n",
      "log_p\n",
      "\t 7 log p\n",
      "--------------------------------------------\n",
      "datum_type\n",
      "\t 2 data type\n",
      "--------------------------------------------\n",
      "cray_t3d\n",
      "\t 5 cray t3d\n",
      "--------------------------------------------\n",
      "double_precision\n",
      "\t 2 double precision\n",
      "--------------------------------------------\n",
      "double_version\n",
      "\t 1 double version\n",
      "\t 1 double versions\n",
      "--------------------------------------------\n",
      "maximum_value\n",
      "\t 2 maximum value\n",
      "--------------------------------------------\n",
      "input_randomness\n",
      "\t 2 randomness input\n",
      "--------------------------------------------\n",
      "datum_double_type\n",
      "\t 6 double data type\n",
      "--------------------------------------------\n",
      "benchmark_integer_manner_value\n",
      "\t 3 integer benchmark values in the manner\n",
      "--------------------------------------------\n",
      "number_randomness\n",
      "\t 7 randomness numbers\n",
      "--------------------------------------------\n",
      "benchmark_integer_value\n",
      "\t 2 integer benchmark values\n",
      "--------------------------------------------\n",
      "randomness_value\n",
      "\t 2 randomness values\n",
      "\t 2 randomness value\n",
      "--------------------------------------------\n",
      "duplicate_input\n",
      "\t 2 input of duplicates\n",
      "--------------------------------------------\n",
      "number_optimum_sample\n",
      "\t 2 optimum number of samples\n",
      "--------------------------------------------\n",
      "number_optimum\n",
      "\t 2 optimum number\n",
      "--------------------------------------------\n",
      "ii_table\n",
      "\t 1 table ii\n",
      "\t 1 tables i and ii\n",
      "--------------------------------------------\n",
      "good_performance\n",
      "\t 1 best performance\n",
      "\t 1 better performance\n",
      "--------------------------------------------\n",
      "benchmark_wr\n",
      "\t 5 wr benchmark\n",
      "--------------------------------------------\n",
      "benchmark_integer\n",
      "\t 2 integer benchmarks\n",
      "--------------------------------------------\n",
      "benchmark_double\n",
      "\t 2 double benchmarks\n",
      "--------------------------------------------\n",
      "result_tables_vii_viii\n",
      "\t 2 results in tables vii and viii\n",
      "--------------------------------------------\n",
      "machine_size\n",
      "\t 2 machine size\n",
      "--------------------------------------------\n",
      "integer_m\n",
      "\t 3 m integers\n",
      "--------------------------------------------\n",
      "particularity_platform\n",
      "\t 2 particularity platform\n",
      "--------------------------------------------\n",
      "ix_table\n",
      "\t 3 table ix\n",
      "--------------------------------------------\n",
      "operation_step_transpose\n",
      "\t 1 transpose operation in step\n",
      "\t 1 transpose operations in steps\n",
      "--------------------------------------------\n",
      "p_subsequence\n",
      "\t 2 p subsequences\n",
      "--------------------------------------------\n",
      "regularity_sample\n",
      "\t 2 regularity sample\n",
      "--------------------------------------------\n",
      "complexity_computation\n",
      "\t 4 computation complexity\n",
      "--------------------------------------------\n",
      "interaction_simulation\n",
      "\t 2 interaction simulation\n",
      "--------------------------------------------\n",
      "geography_information_system\n",
      "\t 1 geography information systems\n",
      "\t 1 geography information system\n",
      "--------------------------------------------\n",
      "address_architecture_space\n",
      "\t 4 address space architecture\n",
      "\t 1 address space architectures\n",
      "--------------------------------------------\n",
      "approach_effect\n",
      "\t 2 effect approach\n",
      "--------------------------------------------\n",
      "highness_performance\n",
      "\t 2 highness performance\n",
      "--------------------------------------------\n",
      "operation_query_range\n",
      "\t 2 range query operation\n",
      "--------------------------------------------\n",
      "declustering_method_system\n",
      "\t 2 system declustering methods\n",
      "\t 1 system declustering method\n",
      "--------------------------------------------\n",
      "declustering_method_randomness_range\n",
      "\t 2 randomness declustering methods for range\n",
      "--------------------------------------------\n",
      "problem_query\n",
      "\t 2 query problems\n",
      "--------------------------------------------\n",
      "declustering_randomness\n",
      "\t 3 randomness declustering\n",
      "--------------------------------------------\n",
      "balancing_dynamism_load\n",
      "\t 3 dynamism load balancing\n",
      "--------------------------------------------\n",
      "dlb_method_performance\n",
      "\t 2 performance of dlb methods\n",
      "--------------------------------------------\n",
      "declustering_method\n",
      "\t 2 declustering methods\n",
      "--------------------------------------------\n",
      "run_time\n",
      "\t 4 run time\n",
      "--------------------------------------------\n",
      "information_system\n",
      "\t 2 information systems\n",
      "\t 1 information system\n",
      "--------------------------------------------\n",
      "reality_terrain_time_visualization\n",
      "\t 3 reality time terrain visualization\n",
      "--------------------------------------------\n",
      "datum_space\n",
      "\t 6 space data\n",
      "--------------------------------------------\n",
      "line_segment\n",
      "\t 2 line segments\n",
      "--------------------------------------------\n",
      "gis_operation\n",
      "\t 1 gis operations\n",
      "\t 1 gis operation\n",
      "--------------------------------------------\n",
      "engine_graphic\n",
      "\t 5 graphics engine\n",
      "--------------------------------------------\n",
      "hpgis_unit\n",
      "\t 3 hpgis unit\n",
      "--------------------------------------------\n",
      "query_range\n",
      "\t 10 range query\n",
      "\t 2 range queries\n",
      "--------------------------------------------\n",
      "map_polygonal\n",
      "\t 1 polygonal map\n",
      "\t 1 polygonal maps\n",
      "--------------------------------------------\n",
      "frequency_operation\n",
      "\t 2 frequency of this operation\n",
      "--------------------------------------------\n",
      "computation_intersection\n",
      "\t 4 intersection computation\n",
      "--------------------------------------------\n",
      "gis_problem\n",
      "\t 2 gis problems\n",
      "\t 1 problem for the gis\n",
      "--------------------------------------------\n",
      "gis_problem_query_range\n",
      "\t 8 gis range query problem\n",
      "\t 1 problem the gis range query\n",
      "--------------------------------------------\n",
      "formulation_parallel\n",
      "\t 1 parallel formulations\n",
      "\t 1 parallel formulation\n",
      "--------------------------------------------\n",
      "gis_query_range\n",
      "\t 2 gis range query\n",
      "--------------------------------------------\n",
      "transfer_work\n",
      "\t 2 work transfer\n",
      "\t 1 work transfers\n",
      "--------------------------------------------\n",
      "search_structure\n",
      "\t 2 search structure\n",
      "--------------------------------------------\n",
      "declustering_method_stillness\n",
      "\t 2 stillness declustering methods\n",
      "--------------------------------------------\n",
      "idleness_processor\n",
      "\t 2 idleness processors\n",
      "\t 2 idleness processor\n",
      "--------------------------------------------\n",
      "datum_locality\n",
      "\t 4 locality data\n",
      "--------------------------------------------\n",
      "overhead_synchronization\n",
      "\t 2 synchronization overhead\n",
      "--------------------------------------------\n",
      "additional_work\n",
      "\t 2 additional work\n",
      "--------------------------------------------\n",
      "declustering_problem\n",
      "\t 2 declustering problem\n",
      "--------------------------------------------\n",
      "heuristic_method\n",
      "\t 2 heuristic methods\n",
      "--------------------------------------------\n",
      "more_work\n",
      "\t 2 more work\n",
      "--------------------------------------------\n",
      "filtering_step\n",
      "\t 2 filtering step\n",
      "--------------------------------------------\n",
      "leader_processor\n",
      "\t 4 leader processor\n",
      "--------------------------------------------\n",
      "imbalance_load_stillness\n",
      "\t 2 stillness load imbalance\n",
      "--------------------------------------------\n",
      "cost_synchronization\n",
      "\t 1 cost of synchronization\n",
      "\t 1 synchronization cost\n",
      "--------------------------------------------\n",
      "datum_object_space\n",
      "\t 2 space data objects\n",
      "--------------------------------------------\n",
      "dlb_method\n",
      "\t 2 dlb method\n",
      "--------------------------------------------\n",
      "declustering_operation\n",
      "\t 2 declustering operation\n",
      "--------------------------------------------\n",
      "edge_sequence\n",
      "\t 2 sequence of edges\n",
      "--------------------------------------------\n",
      "cost_preprocessing\n",
      "\t 3 preprocessing cost\n",
      "--------------------------------------------\n",
      "graph_method_similarity\n",
      "\t 2 similarity graph method\n",
      "--------------------------------------------\n",
      "experiment_result\n",
      "\t 2 results of this experiment\n",
      "--------------------------------------------\n",
      "chunk_size\n",
      "\t 2 chunk size\n",
      "\t 1 size chunks\n",
      "--------------------------------------------\n",
      "average_speedup\n",
      "\t 1 average speedup\n",
      "\t 1 average speedups\n",
      "--------------------------------------------\n",
      "balance_goodness_load\n",
      "\t 2 goodness load balance\n",
      "--------------------------------------------\n",
      "pool_size\n",
      "\t 4 pool size\n",
      "\t 1 size of the pool\n",
      "--------------------------------------------\n",
      "datum_totality\n",
      "\t 2 totality data\n",
      "--------------------------------------------\n",
      "algorithm_pram\n",
      "\t 2 pram algorithms\n",
      "\t 1 pram algorithm\n",
      "--------------------------------------------\n",
      "access_locality\n",
      "\t 1 locality of access\n",
      "\t 1 locality access\n",
      "--------------------------------------------\n",
      "architecture_uma\n",
      "\t 2 uma architectures\n",
      "\t 1 uma architecture\n",
      "--------------------------------------------\n",
      "address_globe_space\n",
      "\t 2 globe address space\n",
      "--------------------------------------------\n",
      "interaction_processor\n",
      "\t 2 processor interaction\n",
      "--------------------------------------------\n",
      "time_transfer_work\n",
      "\t 2 time work transfers\n",
      "--------------------------------------------\n",
      "computer_ieee\n",
      "\t 7 ieee computer\n",
      "--------------------------------------------\n",
      "engineering_ieee_software\n",
      "\t 5 ieee transactions on software engineering\n",
      "--------------------------------------------\n",
      "kumar_v.\n",
      "\t 2 v. kumar\n",
      "--------------------------------------------\n",
      "benjamin_company_cummings_publishing\n",
      "\t 2 benjamin / cummings publishing company\n",
      "--------------------------------------------\n",
      "data_engineering\n",
      "\t 3 data engineering\n",
      "--------------------------------------------\n",
      "data_ieee_knowledge_transaction\n",
      "\t 1 ieee transaction on knowledge and data\n",
      "\t 1 ieee transactions on knowledge and data\n",
      "--------------------------------------------\n",
      "genvoca_model\n",
      "\t 4 genvoca model\n",
      "--------------------------------------------\n",
      "design_software\n",
      "\t 4 software design\n",
      "--------------------------------------------\n",
      "generator_software_system\n",
      "\t 7 software system generators\n",
      "\t 2 software system generator\n",
      "--------------------------------------------\n",
      "class_interconnectedness\n",
      "\t 3 interconnectedness classes\n",
      "--------------------------------------------\n",
      "family_program\n",
      "\t 3 program families\n",
      "--------------------------------------------\n",
      "architecture_software\n",
      "\t 2 software architectures\n",
      "--------------------------------------------\n",
      "domain_specificity\n",
      "\t 2 domain specificity\n",
      "--------------------------------------------\n",
      "domain_model\n",
      "\t 1 domain models\n",
      "\t 1 domain model\n",
      "--------------------------------------------\n",
      "database_system\n",
      "\t 1 database systems\n",
      "\t 1 database system\n",
      "--------------------------------------------\n",
      "network_protocol\n",
      "\t 2 network protocols\n",
      "--------------------------------------------\n",
      "corporation_digital_equipment\n",
      "\t 3 digital equipment corporation\n",
      "--------------------------------------------\n",
      "component_composition\n",
      "\t 4 component composition\n",
      "\t 2 component compositions\n",
      "--------------------------------------------\n",
      "encapsulation_large_scale\n",
      "\t 2 large scale encapsulation\n",
      "--------------------------------------------\n",
      "generator_software\n",
      "\t 2 software generators\n",
      "--------------------------------------------\n",
      "component_such\n",
      "\t 2 such components\n",
      "--------------------------------------------\n",
      "component_encapsulation\n",
      "\t 1 component encapsulation\n",
      "\t 1 encapsulation a component\n",
      "--------------------------------------------\n",
      "domain_specific\n",
      "\t 2 domain specific\n",
      "--------------------------------------------\n",
      "atom_unit\n",
      "\t 1 atom units\n",
      "\t 1 atom unit\n",
      "--------------------------------------------\n",
      "construction_program\n",
      "\t 2 program construction\n",
      "--------------------------------------------\n",
      "datum_member\n",
      "\t 2 data members\n",
      "--------------------------------------------\n",
      "class_cursor\n",
      "\t 1 cursor classes\n",
      "\t 1 cursor class\n",
      "--------------------------------------------\n",
      "element_object\n",
      "\t 2 element objects\n",
      "--------------------------------------------\n",
      "class_container\n",
      "\t 2 container class\n",
      "\t 1 container classes\n",
      "--------------------------------------------\n",
      "component_interface\n",
      "\t 1 interface of a component\n",
      "\t 1 component interfaces\n",
      "--------------------------------------------\n",
      "interface_realm\n",
      "\t 2 realm interface\n",
      "--------------------------------------------\n",
      "detail_implementation\n",
      "\t 3 implementation details\n",
      "--------------------------------------------\n",
      "interface_realm?s\n",
      "\t 2 realm?s interface\n",
      "--------------------------------------------\n",
      "example_figure\n",
      "\t 2 example of figure\n",
      "\t 1 example figure\n",
      "\t 1 example in figure\n",
      "--------------------------------------------\n",
      "component_software\n",
      "\t 2 software components\n",
      "--------------------------------------------\n",
      "class_method\n",
      "\t 1 methods of two classes\n",
      "\t 1 class methods\n",
      "--------------------------------------------\n",
      "class_newness\n",
      "\t 2 newness class\n",
      "--------------------------------------------\n",
      "component_p++\n",
      "\t 3 p++ components\n",
      "--------------------------------------------\n",
      "code_directness_modification_source\n",
      "\t 2 directness source code modification\n",
      "--------------------------------------------\n",
      "parameter_realm\n",
      "\t 5 realm parameters\n",
      "\t 4 realm parameter\n",
      "\t 1 parameters of its realm\n",
      "--------------------------------------------\n",
      "interconnection_language_module\n",
      "\t 3 module interconnection languages\n",
      "--------------------------------------------\n",
      "constancy_parameter_type\n",
      "\t 3 constancy and type parameters\n",
      "--------------------------------------------\n",
      "component_realm\n",
      "\t 2 components and realms\n",
      "\t 1 realm and this component\n",
      "\t 1 components by realms\n",
      "--------------------------------------------\n",
      "parameter_type\n",
      "\t 3 type parameters\n",
      "\t 1 type parameter\n",
      "--------------------------------------------\n",
      "component_linked_list\n",
      "\t 2 linked_list component\n",
      "--------------------------------------------\n",
      "collection_component\n",
      "\t 1 collection component\n",
      "\t 1 collection components\n",
      "--------------------------------------------\n",
      "r_realm\n",
      "\t 3 realm r\n",
      "--------------------------------------------\n",
      "interface_r\n",
      "\t 2 interface r\n",
      "--------------------------------------------\n",
      "object_t\n",
      "\t 3 t objects\n",
      "--------------------------------------------\n",
      "collection_realm\n",
      "\t 2 collection realm\n",
      "--------------------------------------------\n",
      "otherness_researcher\n",
      "\t 2 otherness researchers\n",
      "--------------------------------------------\n",
      "c++_template\n",
      "\t 2 c++ templates\n",
      "\t 1 c++ template\n",
      "--------------------------------------------\n",
      "hierarchy_implementation\n",
      "\t 4 implementation hierarchies\n",
      "--------------------------------------------\n",
      "hierarchy_type\n",
      "\t 4 type hierarchies\n",
      "--------------------------------------------\n",
      "abstraction_datum\n",
      "\t 3 data abstraction\n",
      "--------------------------------------------\n",
      "realm_s\n",
      "\t 2 realm s\n",
      "--------------------------------------------\n",
      "inheritance_realm\n",
      "\t 2 realm inheritance\n",
      "--------------------------------------------\n",
      "parameterized_type\n",
      "\t 1 parameterized type\n",
      "\t 1 parameterized types\n",
      "--------------------------------------------\n",
      "code_generation_highness_quality\n",
      "\t 2 highness quality code generation\n",
      "--------------------------------------------\n",
      "ansi_c\n",
      "\t 3 ansi c\n",
      "--------------------------------------------\n",
      "abstract_class\n",
      "\t 2 abstract class\n",
      "--------------------------------------------\n",
      "d?az_guillermo_prieto_rub?n\n",
      "\t 2 rub?n prieto d?az and guillermo\n",
      "--------------------------------------------\n",
      "analysis_domain\n",
      "\t 2 domain analysis\n",
      "--------------------------------------------\n",
      "singhal_vivek\n",
      "\t 3 vivek singhal\n",
      "--------------------------------------------\n",
      "marty_sirkin\n",
      "\t 2 marty sirkin\n",
      "--------------------------------------------\n",
      "ernest_hemingway\n",
      "\t 2 ernest hemingway\n",
      "--------------------------------------------\n",
      "method_statistics\n",
      "\t 1 statistics methods\n",
      "\t 1 statistics method\n",
      "--------------------------------------------\n",
      "hardy_thomas\n",
      "\t 2 thomas hardy\n",
      "--------------------------------------------\n",
      "compression_text\n",
      "\t 2 text compression\n",
      "--------------------------------------------\n",
      "author_particularity\n",
      "\t 2 particularity author\n",
      "--------------------------------------------\n",
      "form_surface\n",
      "\t 2 surface forms\n",
      "--------------------------------------------\n",
      "computer_program\n",
      "\t 3 computer programs\n",
      "\t 3 computer program\n",
      "--------------------------------------------\n",
      "crowd_madding\n",
      "\t 4 madding crowd\n",
      "--------------------------------------------\n",
      "final_grammar\n",
      "\t 3 final grammar\n",
      "--------------------------------------------\n",
      "distribution_probability\n",
      "\t 4 probability distribution\n",
      "\t 1 probability distributions\n",
      "--------------------------------------------\n",
      "competition_hemingway_imitation\n",
      "\t 2 imitation hemingway competition\n",
      "--------------------------------------------\n",
      "bad_best_hemingway\n",
      "\t 2 best of bad hemingway\n",
      "--------------------------------------------\n",
      "hemingway_parody\n",
      "\t 2 hemingway parody\n",
      "\t 1 hemingway parodies\n",
      "--------------------------------------------\n",
      "phrase_verb\n",
      "\t 2 verb phrase\n",
      "--------------------------------------------\n",
      "generator_number_pseudo_randomness\n",
      "\t 2 pseudo randomness number generator\n",
      "--------------------------------------------\n",
      "sample_text\n",
      "\t 2 sample text\n",
      "--------------------------------------------\n",
      "expression_sample\n",
      "\t 4 sample expressions\n",
      "--------------------------------------------\n",
      "grammar_inference\n",
      "\t 2 grammar inference\n",
      "--------------------------------------------\n",
      "language_naturalness\n",
      "\t 4 naturalness language\n",
      "\t 2 naturalness languages\n",
      "--------------------------------------------\n",
      "finiteness_set\n",
      "\t 7 finiteness set\n",
      "--------------------------------------------\n",
      "sample_string\n",
      "\t 2 sample strings\n",
      "--------------------------------------------\n",
      "finiteness_vocabulary\n",
      "\t 2 finiteness vocabulary\n",
      "--------------------------------------------\n",
      "category_lexis\n",
      "\t 3 lexis categories\n",
      "--------------------------------------------\n",
      "induction_process\n",
      "\t 2 induction process\n",
      "--------------------------------------------\n",
      "category_symbol\n",
      "\t 3 category symbols\n",
      "--------------------------------------------\n",
      "smith_witten\n",
      "\t 2 smith and witten\n",
      "--------------------------------------------\n",
      "main_predicate\n",
      "\t 1 main predicate\n",
      "\t 1 main predicates\n",
      "--------------------------------------------\n",
      "mechanism_planning\n",
      "\t 2 planning mechanism\n",
      "--------------------------------------------\n",
      "control_information\n",
      "\t 1 information control\n",
      "\t 1 information and control\n",
      "\t 1 control information\n",
      "--------------------------------------------\n",
      "learning_machine\n",
      "\t 18 machine learning\n",
      "--------------------------------------------\n",
      "erlbaum_lawrence\n",
      "\t 3 lawrence erlbaum\n",
      "--------------------------------------------\n",
      "jersey_new\n",
      "\t 2 new jersey\n",
      "--------------------------------------------\n",
      "artificiality_intelligence\n",
      "\t 2 artificiality intelligence\n",
      "--------------------------------------------\n",
      "cognitive_science\n",
      "\t 5 cognitive science\n",
      "--------------------------------------------\n",
      "h._ian_witten\n",
      "\t 3 ian h. witten\n",
      "--------------------------------------------\n",
      "paper_series\n",
      "\t 2 paper series\n",
      "--------------------------------------------\n",
      "new_zealand\n",
      "\t 2 new zealand\n",
      "--------------------------------------------\n",
      "early_study\n",
      "\t 3 earlier study\n",
      "--------------------------------------------\n",
      "communication_human_mode\n",
      "\t 4 human communication modes\n",
      "--------------------------------------------\n",
      "communication_mode\n",
      "\t 5 communication modes\n",
      "\t 2 communication mode\n",
      "--------------------------------------------\n",
      "communication_mode_various\n",
      "\t 2 various communication modes\n",
      "--------------------------------------------\n",
      "group_size\n",
      "\t 10 group size\n",
      "\t 1 groups of size\n",
      "--------------------------------------------\n",
      "group_work\n",
      "\t 4 group work\n",
      "--------------------------------------------\n",
      "communication_human\n",
      "\t 2 human communication\n",
      "--------------------------------------------\n",
      "differ_type\n",
      "\t 2 differ types\n",
      "--------------------------------------------\n",
      "collaborate_group_work\n",
      "\t 2 collaborate group work\n",
      "--------------------------------------------\n",
      "decision_making\n",
      "\t 3 decision making\n",
      "--------------------------------------------\n",
      "group_member\n",
      "\t 2 group members\n",
      "--------------------------------------------\n",
      "group_large\n",
      "\t 2 larger groups\n",
      "\t 1 large groups\n",
      "--------------------------------------------\n",
      "communication_face_mode\n",
      "\t 5 face communication modes\n",
      "--------------------------------------------\n",
      "problem_workspace\n",
      "\t 2 workspace problem\n",
      "--------------------------------------------\n",
      "aspect_importance\n",
      "\t 2 importance aspects\n",
      "\t 1 importance aspect\n",
      "--------------------------------------------\n",
      "cooperate_environment_work\n",
      "\t 2 cooperate work environment\n",
      "--------------------------------------------\n",
      "face_face_meeting\n",
      "\t 2 face to face meetings\n",
      "--------------------------------------------\n",
      "meeting_remoteness\n",
      "\t 3 remoteness meetings\n",
      "--------------------------------------------\n",
      "audio_link\n",
      "\t 2 audio link\n",
      "--------------------------------------------\n",
      "jigsaw_puzzle\n",
      "\t 2 jigsaw puzzles\n",
      "\t 1 jigsaw puzzle\n",
      "--------------------------------------------\n",
      "task_type\n",
      "\t 3 task type\n",
      "\t 1 type of task\n",
      "--------------------------------------------\n",
      "cooperate_task\n",
      "\t 1 cooperate tasks\n",
      "\t 1 cooperate task\n",
      "--------------------------------------------\n",
      "effect_littleness\n",
      "\t 2 littleness effect\n",
      "--------------------------------------------\n",
      "communication_group_process\n",
      "\t 2 group communication process\n",
      "--------------------------------------------\n",
      "similarity_situation\n",
      "\t 6 similarity situations\n",
      "\t 1 similarity situation\n",
      "--------------------------------------------\n",
      "face_mode\n",
      "\t 3 face mode\n",
      "\t 1 face modes\n",
      "--------------------------------------------\n",
      "otherness_software\n",
      "\t 2 otherness software\n",
      "--------------------------------------------\n",
      "area_such\n",
      "\t 2 such areas\n",
      "--------------------------------------------\n",
      "control_floor\n",
      "\t 2 floor control\n",
      "--------------------------------------------\n",
      "camera_video\n",
      "\t 1 video cameras\n",
      "\t 1 video camera\n",
      "--------------------------------------------\n",
      "area_body_upper\n",
      "\t 3 upper body area\n",
      "--------------------------------------------\n",
      "computer_control_room\n",
      "\t 2 control room computer\n",
      "--------------------------------------------\n",
      "singleness_tape_video\n",
      "\t 3 singleness video tape\n",
      "--------------------------------------------\n",
      "tape_video\n",
      "\t 3 video tapes\n",
      "--------------------------------------------\n",
      "audio_conversation\n",
      "\t 1 audio conversations\n",
      "\t 1 audio conversation\n",
      "--------------------------------------------\n",
      "group_subject\n",
      "\t 3 subjects / between groups\n",
      "\t 1 subjects in each group\n",
      "--------------------------------------------\n",
      "differ_environment\n",
      "\t 2 differ environments\n",
      "--------------------------------------------\n",
      "environment_newness\n",
      "\t 2 newness environment\n",
      "--------------------------------------------\n",
      "audio_signal_video\n",
      "\t 1 video and audio signals\n",
      "\t 1 audio and video signals\n",
      "--------------------------------------------\n",
      "analysis_result\n",
      "\t 1 results of these analyses\n",
      "\t 1 results of this analysis\n",
      "\t 1 result of this analysis\n",
      "--------------------------------------------\n",
      "duration_totality\n",
      "\t 4 totality duration\n",
      "--------------------------------------------\n",
      "simultaneity_speech\n",
      "\t 2 simultaneity speech\n",
      "--------------------------------------------\n",
      "simultaneity_speech_utterance\n",
      "\t 2 simultaneity speech utterances\n",
      "--------------------------------------------\n",
      "value_variable\n",
      "\t 1 value of these variables\n",
      "\t 1 variable values\n",
      "--------------------------------------------\n",
      "session_tape_video\n",
      "\t 2 video tapes of the sessions\n",
      "--------------------------------------------\n",
      "first_program\n",
      "\t 1 first program\n",
      "\t 1 programs first\n",
      "--------------------------------------------\n",
      "duration_session\n",
      "\t 3 session duration\n",
      "\t 1 duration of the sessions\n",
      "--------------------------------------------\n",
      "longness_time\n",
      "\t 2 longness time\n",
      "--------------------------------------------\n",
      "result_summary\n",
      "\t 2 summary of the results\n",
      "--------------------------------------------\n",
      "level_significance\n",
      "\t 2 significance level\n",
      "--------------------------------------------\n",
      "differ_term\n",
      "\t 1 differ in terms\n",
      "\t 1 differ terms\n",
      "--------------------------------------------\n",
      "differ_result\n",
      "\t 1 differ from the result\n",
      "\t 1 differ results\n",
      "--------------------------------------------\n",
      "experiment_prematureness\n",
      "\t 2 prematureness experiment\n",
      "--------------------------------------------\n",
      "audio_channel\n",
      "\t 2 audio channel\n",
      "--------------------------------------------\n",
      "cambridge_press_university\n",
      "\t 2 cambridge university press\n",
      "--------------------------------------------\n",
      "cscw_environments\n",
      "\t 2 cscw environments\n",
      "--------------------------------------------\n",
      "j._s.\n",
      "\t 2 j. s.\n",
      "--------------------------------------------\n",
      "g._m.\n",
      "\t 3 g. m.\n",
      "--------------------------------------------\n",
      "communication_visual\n",
      "\t 2 visual communication\n",
      "--------------------------------------------\n",
      "computer_human_interaction\n",
      "\t 2 human computer interaction\n",
      "--------------------------------------------\n",
      "elsevier_science\n",
      "\t 5 elsevier science\n",
      "--------------------------------------------\n",
      "c._j.\n",
      "\t 1 j. c.\n",
      "\t 1 c. j.\n",
      "--------------------------------------------\n",
      "international_journal\n",
      "\t 3 international journal\n",
      "--------------------------------------------\n",
      "machine_man\n",
      "\t 2 man machine\n",
      "--------------------------------------------\n",
      "content_visual\n",
      "\t 3 visual content\n",
      "--------------------------------------------\n",
      "feature_visual\n",
      "\t 4 visual features\n",
      "--------------------------------------------\n",
      "compressed_domain\n",
      "\t 6 compressed domain\n",
      "\t 1 compressed domains\n",
      "--------------------------------------------\n",
      "feature_level_lowness\n",
      "\t 2 lowness level features\n",
      "--------------------------------------------\n",
      "quad_tree\n",
      "\t 7 quad tree\n",
      "--------------------------------------------\n",
      "feature_map\n",
      "\t 5 feature map\n",
      "\t 1 feature maps\n",
      "--------------------------------------------\n",
      "columbia_university\n",
      "\t 2 columbia university\n",
      "--------------------------------------------\n",
      "datum_visual\n",
      "\t 2 visual data\n",
      "--------------------------------------------\n",
      "database_image\n",
      "\t 2 image database\n",
      "\t 1 image databases\n",
      "\t 1 image in the database\n",
      "--------------------------------------------\n",
      "example_pictorial_query\n",
      "\t 1 query by pictorial examples\n",
      "\t 1 query by pictorial example\n",
      "--------------------------------------------\n",
      "content_image\n",
      "\t 1 image contents\n",
      "\t 1 image content\n",
      "\t 1 images by content\n",
      "--------------------------------------------\n",
      "database_visual\n",
      "\t 1 visual databases\n",
      "\t 1 visual database\n",
      "--------------------------------------------\n",
      "feature_level_lowness_visual\n",
      "\t 2 lowness level visual features\n",
      "--------------------------------------------\n",
      "database_picture_satellite\n",
      "\t 2 satellite picture databases\n",
      "--------------------------------------------\n",
      "compression_image\n",
      "\t 5 image compression\n",
      "--------------------------------------------\n",
      "image_indexing\n",
      "\t 1 image indexing\n",
      "\t 1 indexing of images\n",
      "--------------------------------------------\n",
      "differ_feature_visual\n",
      "\t 2 differ visual features\n",
      "--------------------------------------------\n",
      "image_query\n",
      "\t 4 image query\n",
      "--------------------------------------------\n",
      "matching_similarity\n",
      "\t 2 similarity matching\n",
      "--------------------------------------------\n",
      "accurate_object_segmentation\n",
      "\t 2 accurate object segmentation\n",
      "--------------------------------------------\n",
      "prominence_region\n",
      "\t 2 prominence regions\n",
      "--------------------------------------------\n",
      "distinctiveness_texture\n",
      "\t 2 distinctiveness textures\n",
      "--------------------------------------------\n",
      "key_texture\n",
      "\t 3 texture key\n",
      "--------------------------------------------\n",
      "query_texture\n",
      "\t 3 query by texture\n",
      "--------------------------------------------\n",
      "similarity_texture\n",
      "\t 1 similarity texture\n",
      "\t 1 similarity textures\n",
      "--------------------------------------------\n",
      "discrimination_texture\n",
      "\t 3 texture discrimination\n",
      "--------------------------------------------\n",
      "image_region\n",
      "\t 2 image regions\n",
      "\t 2 image region\n",
      "--------------------------------------------\n",
      "extraction_region_texture\n",
      "\t 3 texture region extraction\n",
      "--------------------------------------------\n",
      "bank_filter_gabor\n",
      "\t 3 gabor filter banks\n",
      "--------------------------------------------\n",
      "feature_set\n",
      "\t 2 feature sets\n",
      "--------------------------------------------\n",
      "transform_wavelet\n",
      "\t 3 wavelet transform\n",
      "--------------------------------------------\n",
      "decomposition_wavelet\n",
      "\t 2 wavelet decomposition\n",
      "--------------------------------------------\n",
      "class_texture\n",
      "\t 1 texture classes\n",
      "\t 1 texture class\n",
      "--------------------------------------------\n",
      "completeness_set\n",
      "\t 2 completeness set\n",
      "--------------------------------------------\n",
      "analysis_discriminant_fisher_technique\n",
      "\t 2 fisher discriminant analysis technique\n",
      "--------------------------------------------\n",
      "distance_mahalanobis\n",
      "\t 1 mahalanobis distance\n",
      "\t 1 mahalanobis distances\n",
      "--------------------------------------------\n",
      "element_feature\n",
      "\t 3 feature elements\n",
      "--------------------------------------------\n",
      "discriminant_function\n",
      "\t 3 discriminant function\n",
      "--------------------------------------------\n",
      "block_image_neighboring\n",
      "\t 1 neighboring blocks within each image\n",
      "\t 1 neighboring image blocks\n",
      "--------------------------------------------\n",
      "segmentation_texture\n",
      "\t 4 texture segmentation\n",
      "--------------------------------------------\n",
      "quad_structure_tree\n",
      "\t 2 quad tree structure\n",
      "--------------------------------------------\n",
      "distance_optimum_threshold\n",
      "\t 2 optimum distance threshold\n",
      "--------------------------------------------\n",
      "application_practice_such\n",
      "\t 2 practice applications such\n",
      "--------------------------------------------\n",
      "database_image_medical\n",
      "\t 3 medical image databases\n",
      "--------------------------------------------\n",
      "b_figure\n",
      "\t 3 b figure\n",
      "--------------------------------------------\n",
      "node_quad_tree\n",
      "\t 2 quad tree node\n",
      "\t 1 quad tree nodes\n",
      "--------------------------------------------\n",
      "color_differ\n",
      "\t 2 differ colors\n",
      "\t 1 differ color\n",
      "--------------------------------------------\n",
      "color_space\n",
      "\t 6 color space\n",
      "\t 1 color spaces\n",
      "--------------------------------------------\n",
      "color_differ_space\n",
      "\t 2 differ color spaces\n",
      "--------------------------------------------\n",
      "color_histograms\n",
      "\t 2 color histograms\n",
      "--------------------------------------------\n",
      "color_histogram\n",
      "\t 5 color histogram\n",
      "\t 3 color histograms\n",
      "--------------------------------------------\n",
      "color_intersection\n",
      "\t 2 color intersection\n",
      "--------------------------------------------\n",
      "color_pair\n",
      "\t 3 color pairs\n",
      "--------------------------------------------\n",
      "color_extraction_region_singleness\n",
      "\t 2 singleness color region extraction\n",
      "--------------------------------------------\n",
      "color_histogram_indexing\n",
      "\t 2 color histogram indexing\n",
      "--------------------------------------------\n",
      "color_represent\n",
      "\t 2 represent color\n",
      "--------------------------------------------\n",
      "color_region\n",
      "\t 2 color regions\n",
      "--------------------------------------------\n",
      "color_region_singleness\n",
      "\t 2 singleness color regions\n",
      "--------------------------------------------\n",
      "datum_image_rawness\n",
      "\t 2 rawness image data\n",
      "--------------------------------------------\n",
      "application_specificity\n",
      "\t 1 specificity applications\n",
      "\t 1 specificity application\n",
      "--------------------------------------------\n",
      "color_list_represent\n",
      "\t 2 represent color list\n",
      "--------------------------------------------\n",
      "differ_way\n",
      "\t 2 differ ways\n",
      "\t 1 differ way\n",
      "--------------------------------------------\n",
      "distance_image\n",
      "\t 2 distance image\n",
      "--------------------------------------------\n",
      "distance_function\n",
      "\t 7 distance function\n",
      "--------------------------------------------\n",
      "importance_issue\n",
      "\t 2 importance issue\n",
      "\t 1 importance issues\n",
      "--------------------------------------------\n",
      "color_indexing\n",
      "\t 2 color indexing\n",
      "--------------------------------------------\n",
      "edge_point\n",
      "\t 3 edge points\n",
      "--------------------------------------------\n",
      "differ_scale\n",
      "\t 2 differ scales\n",
      "--------------------------------------------\n",
      "detection_edge\n",
      "\t 2 edge detection\n",
      "--------------------------------------------\n",
      "domain_wavelet\n",
      "\t 2 wavelet domain\n",
      "--------------------------------------------\n",
      "edge_information\n",
      "\t 2 edge information\n",
      "--------------------------------------------\n",
      "link_split\n",
      "\t 2 split and link\n",
      "--------------------------------------------\n",
      "block_image\n",
      "\t 2 image block\n",
      "\t 1 image blocks\n",
      "--------------------------------------------\n",
      "block_boundary\n",
      "\t 4 block boundaries\n",
      "--------------------------------------------\n",
      "feature_otherness\n",
      "\t 2 otherness features\n",
      "--------------------------------------------\n",
      "color_pattern\n",
      "\t 2 color pattern\n",
      "--------------------------------------------\n",
      "differ_feature\n",
      "\t 2 differ features\n",
      "--------------------------------------------\n",
      "image_object\n",
      "\t 1 image objects\n",
      "\t 1 image object\n",
      "--------------------------------------------\n",
      "edge_missing_segment\n",
      "\t 2 missing edge segment\n",
      "\t 1 missing edge segments\n",
      "--------------------------------------------\n",
      "extraction_feature_image\n",
      "\t 2 image feature extraction\n",
      "--------------------------------------------\n",
      "demand_testbed\n",
      "\t 2 demand testbed\n",
      "--------------------------------------------\n",
      "b_color\n",
      "\t 2 b color\n",
      "--------------------------------------------\n",
      "c_edge\n",
      "\t 2 c edge\n",
      "--------------------------------------------\n",
      "issue_special\n",
      "\t 5 special issue\n",
      "--------------------------------------------\n",
      "f._j.r._s_smith\n",
      "\t 2 j.r. smith and s f.\n",
      "--------------------------------------------\n",
      "francisco_san\n",
      "\t 4 san francisco\n",
      "--------------------------------------------\n",
      "database_ii_systems_visual\n",
      "\t 3 visual database systems ii\n",
      "--------------------------------------------\n",
      "pattern_recognition\n",
      "\t 2 pattern recognition\n",
      "--------------------------------------------\n",
      "ieee_information_theory_transaction\n",
      "\t 3 ieee transactions on information theory\n",
      "--------------------------------------------\n",
      "ieee_pami_t\n",
      "\t 2 ieee t pami\n",
      "--------------------------------------------\n",
      "ieee_trans\n",
      "\t 2 ieee trans\n",
      "--------------------------------------------\n",
      "automatic_generation_index\n",
      "\t 1 automatic generation of such an index\n",
      "\t 1 automatic index generation\n",
      "--------------------------------------------\n",
      "learning_unsupervised\n",
      "\t 2 unsupervised learning\n",
      "--------------------------------------------\n",
      "congress_dewey_library_system\n",
      "\t 2 library of congress system or dewey\n",
      "--------------------------------------------\n",
      "decimal_system\n",
      "\t 2 decimal system\n",
      "--------------------------------------------\n",
      "document_newness\n",
      "\t 3 newness documents\n",
      "--------------------------------------------\n",
      "document_language_naturalness\n",
      "\t 3 naturalness language documents\n",
      "--------------------------------------------\n",
      "balance_difficultness\n",
      "\t 2 difficultness balance\n",
      "--------------------------------------------\n",
      "human_library_patron\n",
      "\t 2 human library patron\n",
      "--------------------------------------------\n",
      "foreseeable_future\n",
      "\t 2 foreseeable future\n",
      "--------------------------------------------\n",
      "datum_engineering\n",
      "\t 2 data engineering\n",
      "--------------------------------------------\n",
      "learning_method\n",
      "\t 3 learning method\n",
      "--------------------------------------------\n",
      "document_fullness_text\n",
      "\t 2 fullness text documents\n",
      "--------------------------------------------\n",
      "library_tradition\n",
      "\t 2 tradition library\n",
      "\t 1 tradition libraries\n",
      "--------------------------------------------\n",
      "document_relatedness\n",
      "\t 2 relatedness documents\n",
      "--------------------------------------------\n",
      "dorado_el\n",
      "\t 5 el dorado\n",
      "--------------------------------------------\n",
      "hierarchy_index\n",
      "\t 4 hierarchy index\n",
      "\t 3 hierarchy indexes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "richness_structure\n",
      "\t 2 richness structure\n",
      "--------------------------------------------\n",
      "document_fullness_ijcai-95_text\n",
      "\t 3 fullness text documents ijcai-95\n",
      "--------------------------------------------\n",
      "web_wide_world\n",
      "\t 2 world wide web\n",
      "--------------------------------------------\n",
      "avail_information\n",
      "\t 1 information avail\n",
      "\t 1 avail information\n",
      "--------------------------------------------\n",
      "factor_more\n",
      "\t 3 more factors\n",
      "--------------------------------------------\n",
      "observe_variable\n",
      "\t 3 observe variables\n",
      "--------------------------------------------\n",
      "cluster_document\n",
      "\t 2 cluster of documents\n",
      "\t 1 documents in one cluster\n",
      "--------------------------------------------\n",
      "value_vary\n",
      "\t 2 vary values\n",
      "--------------------------------------------\n",
      "keyword_otherness\n",
      "\t 3 otherness keywords\n",
      "\t 1 keyword and the otherness\n",
      "--------------------------------------------\n",
      "relevance_task\n",
      "\t 1 relevance to a task\n",
      "\t 1 relevance to their task\n",
      "--------------------------------------------\n",
      "factor_value\n",
      "\t 4 factor values\n",
      "\t 1 factor value\n",
      "\t 1 values for each factor\n",
      "--------------------------------------------\n",
      "classical_test\n",
      "\t 1 classical tests\n",
      "\t 1 classical test\n",
      "--------------------------------------------\n",
      "conditionality_probability\n",
      "\t 2 conditionality probabilities\n",
      "--------------------------------------------\n",
      "hidden_variable\n",
      "\t 2 hidden variables\n",
      "--------------------------------------------\n",
      "assignment_possibility\n",
      "\t 2 possibility assignments\n",
      "--------------------------------------------\n",
      "assignment_probability\n",
      "\t 3 probability assignment\n",
      "--------------------------------------------\n",
      "combination_possibility\n",
      "\t 2 possibility combinations\n",
      "--------------------------------------------\n",
      "order_randomness\n",
      "\t 3 randomness order\n",
      "--------------------------------------------\n",
      "assumption_underlying\n",
      "\t 2 underlying assumptions\n",
      "--------------------------------------------\n",
      "document_similarity\n",
      "\t 1 documents similarity\n",
      "\t 1 document similarity\n",
      "\t 1 similarity documents\n",
      "--------------------------------------------\n",
      "binary_variable\n",
      "\t 2 binary variables\n",
      "--------------------------------------------\n",
      "document_many\n",
      "\t 2 many documents\n",
      "--------------------------------------------\n",
      "machine_specialized\n",
      "\t 2 specialized machine\n",
      "--------------------------------------------\n",
      "library_patron\n",
      "\t 1 library patrons\n",
      "\t 1 library patron\n",
      "--------------------------------------------\n",
      "part_phrase\n",
      "\t 2 part phrases\n",
      "\t 1 part phrase\n",
      "--------------------------------------------\n",
      "inductive_learning\n",
      "\t 2 inductive learning\n",
      "--------------------------------------------\n",
      "information_retrieval\n",
      "\t 3 information retrieval\n",
      "--------------------------------------------\n",
      "idea_key\n",
      "\t 2 key ideas\n",
      "\t 1 key idea\n",
      "--------------------------------------------\n",
      "cluster_summary\n",
      "\t 2 cluster summary\n",
      "--------------------------------------------\n",
      "keyword_particularity\n",
      "\t 2 particularity keyword\n",
      "--------------------------------------------\n",
      "list_stop\n",
      "\t 3 stop list\n",
      "--------------------------------------------\n",
      "common_word\n",
      "\t 2 common words\n",
      "--------------------------------------------\n",
      "directory_yahoo\n",
      "\t 2 yahoo directory\n",
      "--------------------------------------------\n",
      "artificial_intelligence_journal_research\n",
      "\t 2 journal of artificial intelligence research\n",
      "--------------------------------------------\n",
      "computer_programming\n",
      "\t 2 computer programming\n",
      "--------------------------------------------\n",
      "software_visualization\n",
      "\t 4 software visualization\n",
      "--------------------------------------------\n",
      "computer_curriculum_programming\n",
      "\t 4 computer programming curriculum\n",
      "--------------------------------------------\n",
      "part_time\n",
      "\t 2 part time\n",
      "--------------------------------------------\n",
      "al_eisenstadt_et\n",
      "\t 2 eisenstadt et al\n",
      "--------------------------------------------\n",
      "key_role\n",
      "\t 2 key role\n",
      "--------------------------------------------\n",
      "program_work\n",
      "\t 2 program works\n",
      "--------------------------------------------\n",
      "client_independence_platform_software\n",
      "\t 1 platform independence software for the client\n",
      "\t 1 platform independence - the client software\n",
      "--------------------------------------------\n",
      "asynchronous_communication\n",
      "\t 3 asynchronous communication\n",
      "--------------------------------------------\n",
      "internet_laboratory_software_visualization\n",
      "\t 9 internet software visualization laboratory\n",
      "--------------------------------------------\n",
      "approach_appropriateness_stage\n",
      "\t 2 stage appropriateness approach\n",
      "--------------------------------------------\n",
      "great_number\n",
      "\t 1 greater number\n",
      "\t 1 numbers greater\n",
      "--------------------------------------------\n",
      "environment_isvl\n",
      "\t 3 isvl environment\n",
      "--------------------------------------------\n",
      "algorithm_animation_system\n",
      "\t 2 algorithm animation systems\n",
      "--------------------------------------------\n",
      "brayshaw_eisenstadt\n",
      "\t 1 eisenstadt and brayshaw\n",
      "\t 1 brayshaw and eisenstadt\n",
      "--------------------------------------------\n",
      "code_level\n",
      "\t 4 code level\n",
      "--------------------------------------------\n",
      "al_domingue_et\n",
      "\t 2 domingue et al\n",
      "--------------------------------------------\n",
      "education_experience\n",
      "\t 2 education experience\n",
      "--------------------------------------------\n",
      "learning_process\n",
      "\t 2 learning process\n",
      "--------------------------------------------\n",
      "machine_prolog_transparence\n",
      "\t 2 transparence prolog machine\n",
      "--------------------------------------------\n",
      "knowledge_structure\n",
      "\t 6 knowledge structures\n",
      "\t 1 knowledge structure\n",
      "--------------------------------------------\n",
      "differ_kind\n",
      "\t 2 differ kinds\n",
      "--------------------------------------------\n",
      "display_sv\n",
      "\t 2 sv display\n",
      "--------------------------------------------\n",
      "implicitness_information\n",
      "\t 2 implicitness information\n",
      "--------------------------------------------\n",
      "notation_secondary\n",
      "\t 2 secondary notation\n",
      "--------------------------------------------\n",
      "explicitness_information\n",
      "\t 2 explicitness information\n",
      "--------------------------------------------\n",
      "expert_sv\n",
      "\t 2 expert sv\n",
      "--------------------------------------------\n",
      "open_university\n",
      "\t 2 open university\n",
      "--------------------------------------------\n",
      "overview_strategy\n",
      "\t 2 overview strategy\n",
      "--------------------------------------------\n",
      "execution_large_space\n",
      "\t 1 larger execution spaces\n",
      "\t 1 large execution spaces\n",
      "--------------------------------------------\n",
      "server_structure\n",
      "\t 1 structures on the server\n",
      "\t 1 server structures\n",
      "--------------------------------------------\n",
      "button_control_panel\n",
      "\t 2 button in the control panel\n",
      "--------------------------------------------\n",
      "control_panel\n",
      "\t 2 control panel\n",
      "--------------------------------------------\n",
      "currency_page_student\n",
      "\t 1 currency students page\n",
      "\t 1 currency student page\n",
      "--------------------------------------------\n",
      "low_split\n",
      "\t 2 lower split\n",
      "--------------------------------------------\n",
      "school_summer_virtual\n",
      "\t 2 virtual summer school\n",
      "--------------------------------------------\n",
      "algorithm_level\n",
      "\t 2 algorithm level\n",
      "--------------------------------------------\n",
      "own_work\n",
      "\t 2 own work\n",
      "--------------------------------------------\n",
      "h._m.\n",
      "\t 2 m. h.\n",
      "--------------------------------------------\n",
      "h._m._t.\n",
      "\t 2 m. t. h.\n",
      "--------------------------------------------\n",
      "artificial_conference_intelligence\n",
      "\t 2 conference on artificial intelligence\n",
      "--------------------------------------------\n",
      "acm_press\n",
      "\t 3 acm press\n",
      "--------------------------------------------\n",
      "block_concept_edit_string\n",
      "\t 2 concept of string block edit\n",
      "--------------------------------------------\n",
      "a_string\n",
      "\t 6 strings a\n",
      "--------------------------------------------\n",
      "certain_phenomenon\n",
      "\t 2 certain phenomena\n",
      "--------------------------------------------\n",
      "application_importance_reality_world\n",
      "\t 2 importance reality world applications\n",
      "--------------------------------------------\n",
      "basic_problem\n",
      "\t 2 basic problem\n",
      "--------------------------------------------\n",
      "family_variation\n",
      "\t 2 family of variations\n",
      "--------------------------------------------\n",
      "biology_molecule\n",
      "\t 2 molecule biology\n",
      "--------------------------------------------\n",
      "distance_edit\n",
      "\t 3 edit distance\n",
      "--------------------------------------------\n",
      "paper_prematureness\n",
      "\t 2 prematureness paper\n",
      "--------------------------------------------\n",
      "computing_pen\n",
      "\t 2 pen computing\n",
      "--------------------------------------------\n",
      "good_match\n",
      "\t 4 best match\n",
      "--------------------------------------------\n",
      "distance_edit_simpleness\n",
      "\t 2 simpleness edit distance\n",
      "--------------------------------------------\n",
      "long_sequence\n",
      "\t 1 longer sequences\n",
      "\t 1 longer sequence\n",
      "--------------------------------------------\n",
      "avail_tool\n",
      "\t 1 avail tool\n",
      "\t 1 tools avail\n",
      "--------------------------------------------\n",
      "high_level_structure\n",
      "\t 2 higher level structure\n",
      "--------------------------------------------\n",
      "dog_laziness\n",
      "\t 2 laziness dog\n",
      "--------------------------------------------\n",
      "matching_string\n",
      "\t 3 string matching\n",
      "--------------------------------------------\n",
      "block_t\n",
      "\t 2 t block\n",
      "--------------------------------------------\n",
      "substring_t\n",
      "\t 2 t substrings\n",
      "--------------------------------------------\n",
      "cover_disjoint\n",
      "\t 5 disjoint cover\n",
      "\t 1 disjoint covers\n",
      "--------------------------------------------\n",
      "family_substring\n",
      "\t 3 substring family\n",
      "\t 1 substring families\n",
      "--------------------------------------------\n",
      "cd_cd\n",
      "\t 5 cd cd\n",
      "--------------------------------------------\n",
      "problem_sameness\n",
      "\t 2 sameness problem\n",
      "--------------------------------------------\n",
      "block_distance_edit\n",
      "\t 5 block edit distance\n",
      "--------------------------------------------\n",
      "cost_function\n",
      "\t 6 cost function\n",
      "--------------------------------------------\n",
      "block_distance_edit_problem\n",
      "\t 2 block edit distance problem\n",
      "--------------------------------------------\n",
      "lateness_section\n",
      "\t 1 lateness section\n",
      "\t 1 lateness sections\n",
      "--------------------------------------------\n",
      "membership_np\n",
      "\t 2 membership in np\n",
      "--------------------------------------------\n",
      "hardness_np\n",
      "\t 2 np hardness\n",
      "--------------------------------------------\n",
      "b_string\n",
      "\t 3 string b\n",
      "\t 1 b strings\n",
      "--------------------------------------------\n",
      "problem_scheduling\n",
      "\t 4 scheduling problem\n",
      "--------------------------------------------\n",
      "deadline_late\n",
      "\t 2 latest deadline\n",
      "--------------------------------------------\n",
      "copy_template\n",
      "\t 1 copy of the template\n",
      "\t 1 copy of this template\n",
      "--------------------------------------------\n",
      "block_such\n",
      "\t 1 such block\n",
      "\t 1 such blocks\n",
      "--------------------------------------------\n",
      "lemma_proof\n",
      "\t 2 proof of lemma\n",
      "\t 1 proof of the lemma\n",
      "--------------------------------------------\n",
      "match_property\n",
      "\t 9 match property\n",
      "--------------------------------------------\n",
      "1)th_block_character_s01\n",
      "\t 2 1)th block of 2n characters in s01\n",
      "--------------------------------------------\n",
      "step_substring_time\n",
      "\t 2 time step substring\n",
      "--------------------------------------------\n",
      "definition_dist\n",
      "\t 2 definition of dist\n",
      "--------------------------------------------\n",
      "job_substring\n",
      "\t 2 job substring\n",
      "--------------------------------------------\n",
      "character_first\n",
      "\t 1 first 2n characters\n",
      "\t 1 first character\n",
      "--------------------------------------------\n",
      "#_string\n",
      "\t 2 string #\n",
      "--------------------------------------------\n",
      "slot_time\n",
      "\t 1 time slot\n",
      "\t 1 time slots\n",
      "--------------------------------------------\n",
      "cost_cover_disjoint\n",
      "\t 2 cost disjoint cover\n",
      "--------------------------------------------\n",
      "proof_theorem\n",
      "\t 1 proof of theorem\n",
      "\t 1 proof of the theorem\n",
      "--------------------------------------------\n",
      "block_cd_cd_edit\n",
      "\t 7 cd cd block edit\n",
      "--------------------------------------------\n",
      "reduction_sameness\n",
      "\t 2 sameness reduction\n",
      "--------------------------------------------\n",
      "distance_problem\n",
      "\t 1 distance problems\n",
      "\t 1 distance problem\n",
      "--------------------------------------------\n",
      "job_step_time\n",
      "\t 1 time steps and jobs\n",
      "\t 1 time step or job\n",
      "--------------------------------------------\n",
      "distance_match_measure_validity\n",
      "\t 2 distance measure so that a validity match\n",
      "--------------------------------------------\n",
      "match_such\n",
      "\t 2 such match\n",
      "--------------------------------------------\n",
      "matrix_w\n",
      "\t 2 matrix w\n",
      "\t 1 w matrix\n",
      "--------------------------------------------\n",
      "algorithm_cd_cd_m(i\n",
      "\t 2 algorithm cd cd m(i\n",
      "--------------------------------------------\n",
      "o(m2_t\n",
      "\t 2 o(m2 + t\n",
      "--------------------------------------------\n",
      "o(m2_time\n",
      "\t 2 o(m2 time\n",
      "--------------------------------------------\n",
      "o(mn_time\n",
      "\t 2 time o(mn\n",
      "--------------------------------------------\n",
      "open_question\n",
      "\t 2 open question\n",
      "--------------------------------------------\n",
      "appropriateness_means\n",
      "\t 2 appropriateness means\n",
      "--------------------------------------------\n",
      "investigation_primary\n",
      "\t 3 primary investigation\n",
      "--------------------------------------------\n",
      "differ_empiricism_technique\n",
      "\t 2 differ empiricism techniques\n",
      "--------------------------------------------\n",
      "externality_validity\n",
      "\t 2 externality validity\n",
      "--------------------------------------------\n",
      "practice_unsupported\n",
      "\t 2 unsupported practice\n",
      "--------------------------------------------\n",
      "controlled_investigation\n",
      "\t 2 controlled investigation\n",
      "--------------------------------------------\n",
      "interview_structured\n",
      "\t 5 structured interviews\n",
      "\t 3 structured interview\n",
      "--------------------------------------------\n",
      "experience_object\n",
      "\t 2 experience object\n",
      "--------------------------------------------\n",
      "highness_level_system_understanding\n",
      "\t 2 highness level system understanding\n",
      "--------------------------------------------\n",
      "issue_otherness\n",
      "\t 2 otherness issues\n",
      "--------------------------------------------\n",
      "experiment_laboratory\n",
      "\t 2 laboratory experiments\n",
      "--------------------------------------------\n",
      "collateral_power\n",
      "\t 2 collateral power\n",
      "--------------------------------------------\n",
      "group_user_wide\n",
      "\t 2 wider user group\n",
      "--------------------------------------------\n",
      "externality_replication\n",
      "\t 2 externality replication\n",
      "--------------------------------------------\n",
      "productivity_software\n",
      "\t 2 software productivity\n",
      "--------------------------------------------\n",
      "defect_efficiency_removal\n",
      "\t 2 defect removal efficiency\n",
      "--------------------------------------------\n",
      "component_reuse\n",
      "\t 2 component reuse\n",
      "--------------------------------------------\n",
      "huitt_wilde\n",
      "\t 2 wilde and huitt\n",
      "--------------------------------------------\n",
      "object_problem\n",
      "\t 1 problems with object\n",
      "\t 1 problems with the object\n",
      "--------------------------------------------\n",
      "evidence_initial\n",
      "\t 2 initial evidence\n",
      "--------------------------------------------\n",
      "concept_entropy\n",
      "\t 2 concept entropy\n",
      "--------------------------------------------\n",
      "class_hierarchy\n",
      "\t 2 class hierarchies\n",
      "\t 2 class hierarchy\n",
      "--------------------------------------------\n",
      "further_investigation\n",
      "\t 3 further investigation\n",
      "--------------------------------------------\n",
      "interviewing_structured\n",
      "\t 2 structured interviewing\n",
      "--------------------------------------------\n",
      "interview_template\n",
      "\t 2 interview template\n",
      "\t 1 template from which the interview\n",
      "--------------------------------------------\n",
      "pressure_time\n",
      "\t 3 time pressures\n",
      "--------------------------------------------\n",
      "knowledge_own\n",
      "\t 2 own knowledge\n",
      "--------------------------------------------\n",
      "datum_verb\n",
      "\t 2 verb data\n",
      "--------------------------------------------\n",
      "acquisition_knowledge\n",
      "\t 6 knowledge acquisition\n",
      "--------------------------------------------\n",
      "datum_quantitative\n",
      "\t 2 quantitative data\n",
      "--------------------------------------------\n",
      "binding_dynamism\n",
      "\t 6 dynamism binding\n",
      "--------------------------------------------\n",
      "invocation_method\n",
      "\t 2 method invocations\n",
      "--------------------------------------------\n",
      "class_x\n",
      "\t 2 class x\n",
      "--------------------------------------------\n",
      "reuse_software\n",
      "\t 3 software reuse\n",
      "--------------------------------------------\n",
      "program_understanding\n",
      "\t 2 program understanding\n",
      "--------------------------------------------\n",
      "newness_problem\n",
      "\t 2 newness problems\n",
      "--------------------------------------------\n",
      "bush_ponder\n",
      "\t 2 ponder and bush\n",
      "--------------------------------------------\n",
      "difficulty_understanding\n",
      "\t 4 understanding difficulties\n",
      "--------------------------------------------\n",
      "few_instance\n",
      "\t 2 few instances\n",
      "--------------------------------------------\n",
      "method_smallness\n",
      "\t 2 smallness methods\n",
      "--------------------------------------------\n",
      "software_tool\n",
      "\t 2 software tools\n",
      "--------------------------------------------\n",
      "initial_interview\n",
      "\t 2 initial interview\n",
      "--------------------------------------------\n",
      "majority_subject\n",
      "\t 2 majority of subjects\n",
      "--------------------------------------------\n",
      "interview_transcript\n",
      "\t 2 interview transcript\n",
      "\t 1 interview transcripts\n",
      "--------------------------------------------\n",
      "curve_learning\n",
      "\t 2 learning curve\n",
      "--------------------------------------------\n",
      "several_subject\n",
      "\t 2 several subjects\n",
      "--------------------------------------------\n",
      "j_subject\n",
      "\t 2 subject j\n",
      "\t 1 subjects j\n",
      "--------------------------------------------\n",
      "l_subject\n",
      "\t 3 subject l\n",
      "--------------------------------------------\n",
      "hybrid_language\n",
      "\t 2 hybrid languages\n",
      "--------------------------------------------\n",
      "b_subject\n",
      "\t 5 subjects b\n",
      "\t 1 subject b\n",
      "--------------------------------------------\n",
      "m_subject\n",
      "\t 2 subject m\n",
      "--------------------------------------------\n",
      "comment_individuality\n",
      "\t 17 individuality comments\n",
      "--------------------------------------------\n",
      "design_documentation\n",
      "\t 2 design documentation\n",
      "--------------------------------------------\n",
      "k_subject\n",
      "\t 2 subject k\n",
      "--------------------------------------------\n",
      "a_subject\n",
      "\t 2 subjects a\n",
      "\t 1 subject a\n",
      "--------------------------------------------\n",
      "similarity_statement\n",
      "\t 1 similarity statements\n",
      "\t 1 similarity statement\n",
      "--------------------------------------------\n",
      "otherness_system\n",
      "\t 2 otherness systems\n",
      "--------------------------------------------\n",
      "g_subject\n",
      "\t 3 subject g\n",
      "--------------------------------------------\n",
      "class_relationship\n",
      "\t 1 class relationships\n",
      "\t 1 relationship between two classes\n",
      "--------------------------------------------\n",
      "member_variable\n",
      "\t 2 member variables\n",
      "--------------------------------------------\n",
      "h_subject\n",
      "\t 5 subject h\n",
      "--------------------------------------------\n",
      "case_common\n",
      "\t 1 common case\n",
      "\t 1 common cases\n",
      "--------------------------------------------\n",
      "badness_design\n",
      "\t 2 badness design\n",
      "--------------------------------------------\n",
      "fix_quickness\n",
      "\t 1 quickness fix\n",
      "\t 1 quickness fixes\n",
      "--------------------------------------------\n",
      "d_subject\n",
      "\t 2 subject d\n",
      "\t 1 subjects d\n",
      "--------------------------------------------\n",
      "h_k_subject\n",
      "\t 2 subjects h and k\n",
      "--------------------------------------------\n",
      "c_subject\n",
      "\t 3 subject c\n",
      "\t 2 subjects c\n",
      "--------------------------------------------\n",
      "system_understanding\n",
      "\t 1 system understanding\n",
      "\t 1 understanding system\n",
      "--------------------------------------------\n",
      "inheritance_level\n",
      "\t 3 levels of inheritance\n",
      "--------------------------------------------\n",
      "inheritance_multiple\n",
      "\t 12 multiple inheritance\n",
      "--------------------------------------------\n",
      "inheritance_singleness\n",
      "\t 2 singleness inheritance\n",
      "--------------------------------------------\n",
      "e_subject\n",
      "\t 3 subject e\n",
      "\t 1 subjects e\n",
      "--------------------------------------------\n",
      "equivalent_program_structured\n",
      "\t 1 equivalent structured programs\n",
      "\t 1 equivalent structured program\n",
      "--------------------------------------------\n",
      "mindset_object\n",
      "\t 2 object mindset\n",
      "--------------------------------------------\n",
      "more_object\n",
      "\t 1 more object\n",
      "\t 1 more objects\n",
      "--------------------------------------------\n",
      "practice_programming\n",
      "\t 1 programming practice\n",
      "\t 1 programming practices\n",
      "--------------------------------------------\n",
      "goodness_practice_programming\n",
      "\t 2 goodness programming practice\n",
      "--------------------------------------------\n",
      "degradation_software\n",
      "\t 2 software degradation\n",
      "--------------------------------------------\n",
      "corlett_e_j_wilson\n",
      "\t 3 j wilson and e corlett\n",
      "--------------------------------------------\n",
      "evaluation_human_work\n",
      "\t 3 evaluation of human work\n",
      "--------------------------------------------\n",
      "ergonomic_methodology_practice\n",
      "\t 3 practice ergonomics methodology\n",
      "--------------------------------------------\n",
      "francis_taylor\n",
      "\t 3 taylor and francis\n",
      "--------------------------------------------\n",
      "a_brooks\n",
      "\t 2 a brooks\n",
      "--------------------------------------------\n",
      "daly_j\n",
      "\t 2 j daly\n",
      "--------------------------------------------\n",
      "j_miller\n",
      "\t 2 j miller\n",
      "--------------------------------------------\n",
      "m_roper\n",
      "\t 2 m roper\n",
      "--------------------------------------------\n",
      "m_wood\n",
      "\t 2 m wood\n",
      "--------------------------------------------\n",
      "conference_ieee_international_proceeding\n",
      "\t 2 proceedings of the ieee international conference\n",
      "--------------------------------------------\n",
      "maintenance_object_support\n",
      "\t 2 maintenance support for object\n",
      "--------------------------------------------\n",
      "set_training\n",
      "\t 3 training set\n",
      "--------------------------------------------\n",
      "accuracy_generalization\n",
      "\t 11 generalization accuracy\n",
      "--------------------------------------------\n",
      "accuracy_generalization_high\n",
      "\t 1 highest generalization accuracy\n",
      "\t 1 higher generalization accuracy\n",
      "--------------------------------------------\n",
      "application_many\n",
      "\t 3 many applications\n",
      "--------------------------------------------\n",
      "class_output\n",
      "\t 5 output class\n",
      "\t 2 output classes\n",
      "--------------------------------------------\n",
      "algorithm_near_neighbor\n",
      "\t 3 nearest neighbor algorithm\n",
      "--------------------------------------------\n",
      "instance_training\n",
      "\t 1 instance in the training\n",
      "\t 1 training instances\n",
      "--------------------------------------------\n",
      "instance_noise\n",
      "\t 9 noise instances\n",
      "\t 5 noise instance\n",
      "--------------------------------------------\n",
      "input_vector\n",
      "\t 3 input vector\n",
      "\t 2 input vectors\n",
      "--------------------------------------------\n",
      "requirement_storage\n",
      "\t 6 storage requirements\n",
      "--------------------------------------------\n",
      "attribute_input\n",
      "\t 3 input attributes\n",
      "--------------------------------------------\n",
      "instance_newness_reduction_technique\n",
      "\t 2 newness instance reduction techniques\n",
      "--------------------------------------------\n",
      "dataset_experiment\n",
      "\t 2 experiments on 29 datasets\n",
      "--------------------------------------------\n",
      "reduction_technique\n",
      "\t 4 reduction technique\n",
      "\t 1 reduction techniques\n",
      "--------------------------------------------\n",
      "condensed_nearest_neighbor_rule\n",
      "\t 2 condensed nearest neighbor rule\n",
      "--------------------------------------------\n",
      "instance_s.\n",
      "\t 2 instances in s.\n",
      "--------------------------------------------\n",
      "class_differ\n",
      "\t 3 differ class\n",
      "--------------------------------------------\n",
      "accuracy_high\n",
      "\t 2 higher accuracy\n",
      "--------------------------------------------\n",
      "instance_s\n",
      "\t 1 instance from s\n",
      "\t 1 instance in s\n",
      "--------------------------------------------\n",
      "instance_otherness\n",
      "\t 1 otherness instances\n",
      "\t 1 otherness instance\n",
      "--------------------------------------------\n",
      "border_point\n",
      "\t 12 border points\n",
      "--------------------------------------------\n",
      "near_neighbor\n",
      "\t 6 nearest neighbors\n",
      "\t 2 nearest neighbor\n",
      "--------------------------------------------\n",
      "boundary_decision_smooth\n",
      "\t 2 smoother decision boundaries\n",
      "--------------------------------------------\n",
      "internal_point\n",
      "\t 2 internal points\n",
      "--------------------------------------------\n",
      "algorithm_wilson?s\n",
      "\t 2 wilson?s algorithm\n",
      "--------------------------------------------\n",
      "k_nn\n",
      "\t 2 k nn\n",
      "--------------------------------------------\n",
      "algorithm_learning\n",
      "\t 1 learning algorithms\n",
      "\t 1 learning algorithm\n",
      "--------------------------------------------\n",
      "instance_typicality\n",
      "\t 3 typicality instance\n",
      "--------------------------------------------\n",
      "algorithm_tibl\n",
      "\t 2 tibl algorithm\n",
      "--------------------------------------------\n",
      "cameron_jones\n",
      "\t 3 cameron jones\n",
      "--------------------------------------------\n",
      "encoding_heuristic_length\n",
      "\t 2 encoding length heuristic\n",
      "--------------------------------------------\n",
      "s_subset\n",
      "\t 3 subset s\n",
      "--------------------------------------------\n",
      "instance_near\n",
      "\t 1 nearest two instances\n",
      "\t 1 nearest instance\n",
      "--------------------------------------------\n",
      "accuracy_classification\n",
      "\t 2 classification accuracy\n",
      "--------------------------------------------\n",
      "observation_several\n",
      "\t 2 several observations\n",
      "--------------------------------------------\n",
      "algorithm_reduction\n",
      "\t 1 reduction algorithm\n",
      "\t 1 reduction algorithms\n",
      "--------------------------------------------\n",
      "instance_original\n",
      "\t 2 original instances\n",
      "\t 1 original instance\n",
      "--------------------------------------------\n",
      "rule_wilson?s\n",
      "\t 3 wilson?s rule\n",
      "--------------------------------------------\n",
      "k_value\n",
      "\t 2 value of k\n",
      "--------------------------------------------\n",
      "direction_search\n",
      "\t 1 direction of search\n",
      "\t 1 search direction\n",
      "--------------------------------------------\n",
      "algorithm_decremental\n",
      "\t 2 decremental algorithms\n",
      "--------------------------------------------\n",
      "cluster_entireness\n",
      "\t 2 entireness clusters\n",
      "--------------------------------------------\n",
      "class_own\n",
      "\t 1 own class\n",
      "\t 1 own classes\n",
      "--------------------------------------------\n",
      "instance_reduction_technique\n",
      "\t 2 instance reduction techniques\n",
      "--------------------------------------------\n",
      "center_point\n",
      "\t 6 center points\n",
      "--------------------------------------------\n",
      "boundary_decision\n",
      "\t 2 decision boundaries\n",
      "\t 2 decision boundary\n",
      "--------------------------------------------\n",
      "border_closeness_point\n",
      "\t 2 closeness border points\n",
      "--------------------------------------------\n",
      "instance_many\n",
      "\t 2 many instances\n",
      "--------------------------------------------\n",
      "attribute_nominal\n",
      "\t 2 nominal attributes\n",
      "--------------------------------------------\n",
      "instance_p\n",
      "\t 2 instance p\n",
      "--------------------------------------------\n",
      "enemy_near\n",
      "\t 4 nearest enemy\n",
      "--------------------------------------------\n",
      "accuracy_generalization_highness\n",
      "\t 2 highness generalization accuracy\n",
      "--------------------------------------------\n",
      "class_p.ai_sameness\n",
      "\t 2 sameness class as p.ai\n",
      "--------------------------------------------\n",
      "class_differ_p.ai\n",
      "\t 2 differ class than p.ai\n",
      "--------------------------------------------\n",
      "level_sameness\n",
      "\t 2 sameness level\n",
      "--------------------------------------------\n",
      "low_requirement_storage\n",
      "\t 2 lower storage requirements\n",
      "\t 1 lowest storage requirements\n",
      "--------------------------------------------\n",
      "potency_problem\n",
      "\t 1 potency problem\n",
      "\t 1 potency problems\n",
      "--------------------------------------------\n",
      "input_space\n",
      "\t 2 input space\n",
      "--------------------------------------------\n",
      "original_training\n",
      "\t 3 original training\n",
      "--------------------------------------------\n",
      "order_removal\n",
      "\t 1 order of removal\n",
      "\t 1 order of their removal\n",
      "--------------------------------------------\n",
      "noise_point\n",
      "\t 1 noise point\n",
      "\t 1 noise points\n",
      "--------------------------------------------\n",
      "algorithm_knn\n",
      "\t 2 knn algorithm\n",
      "--------------------------------------------\n",
      "accuracy_average_generalization\n",
      "\t 3 average generalization accuracy\n",
      "--------------------------------------------\n",
      "dataset_vowel\n",
      "\t 2 vowel dataset\n",
      "--------------------------------------------\n",
      "developer_software\n",
      "\t 1 developers of software\n",
      "\t 1 software developer\n",
      "--------------------------------------------\n",
      "issue_many\n",
      "\t 1 many issues\n",
      "\t 1 many of these issues\n",
      "\t 1 many of the issues\n",
      "--------------------------------------------\n",
      "culture_otherness\n",
      "\t 1 cultures otherness\n",
      "\t 1 otherness cultures\n",
      "--------------------------------------------\n",
      "culture_differ\n",
      "\t 2 differ cultures\n",
      "--------------------------------------------\n",
      "error_message\n",
      "\t 2 error messages\n",
      "\t 1 error message\n",
      "--------------------------------------------\n",
      "such_text\n",
      "\t 2 such text\n",
      "--------------------------------------------\n",
      "culture_element\n",
      "\t 2 culture elements\n",
      "--------------------------------------------\n",
      "output_text\n",
      "\t 1 output text\n",
      "\t 1 text output\n",
      "--------------------------------------------\n",
      "del_galdo\n",
      "\t 3 del galdo\n",
      "--------------------------------------------\n",
      "case_upper\n",
      "\t 2 upper case\n",
      "--------------------------------------------\n",
      "case_low\n",
      "\t 2 lower case\n",
      "--------------------------------------------\n",
      "sameness_thing\n",
      "\t 2 sameness thing\n",
      "--------------------------------------------\n",
      "newness_version\n",
      "\t 3 newness version\n",
      "\t 1 newness versions\n",
      "--------------------------------------------\n",
      "locale_part_specificity\n",
      "\t 2 locale specificity part\n",
      "--------------------------------------------\n",
      "externality_file\n",
      "\t 2 externality files\n",
      "\t 1 externality file\n",
      "--------------------------------------------\n",
      "file_message\n",
      "\t 3 message files\n",
      "\t 1 message file\n",
      "--------------------------------------------\n",
      "guide_open_portability\n",
      "\t 2 open portability guide\n",
      "--------------------------------------------\n",
      "nls_ultrix\n",
      "\t 2 ultrix nls\n",
      "--------------------------------------------\n",
      "string_text\n",
      "\t 3 text strings\n",
      "--------------------------------------------\n",
      "goodness_knowledge\n",
      "\t 2 goodness knowledge\n",
      "--------------------------------------------\n",
      "directness_translation\n",
      "\t 1 directness translation\n",
      "\t 1 directness translations\n",
      "--------------------------------------------\n",
      "argument_runtime\n",
      "\t 2 runtime arguments\n",
      "--------------------------------------------\n",
      "parameter_specification\n",
      "\t 2 parameter specifications\n",
      "--------------------------------------------\n",
      "interface_us\n",
      "\t 3 user interfaces\n",
      "\t 1 user interface\n",
      "--------------------------------------------\n",
      "jakob_nielsen\n",
      "\t 8 jakob nielsen\n",
      "--------------------------------------------\n",
      "international_use\n",
      "\t 6 international use\n",
      "--------------------------------------------\n",
      "designing_interface_user\n",
      "\t 3 designing user interfaces\n",
      "--------------------------------------------\n",
      "achievement_methodology\n",
      "\t 2 methodology achievements\n",
      "--------------------------------------------\n",
      "expert_generation_second_system\n",
      "\t 2 second generation expert systems\n",
      "--------------------------------------------\n",
      "domain_knowledge_principled\n",
      "\t 4 principled knowledge about the domain\n",
      "--------------------------------------------\n",
      "first_principle\n",
      "\t 2 first principles\n",
      "--------------------------------------------\n",
      "concept_model\n",
      "\t 6 concept model\n",
      "--------------------------------------------\n",
      "inference_step\n",
      "\t 3 inference steps\n",
      "\t 1 inference step\n",
      "--------------------------------------------\n",
      "applied_artificial_intelligence\n",
      "\t 4 applied artificial intelligence\n",
      "--------------------------------------------\n",
      "expert_system\n",
      "\t 3 expert systems\n",
      "--------------------------------------------\n",
      "domain_technique\n",
      "\t 3 technique domains\n",
      "\t 2 technique domain\n",
      "--------------------------------------------\n",
      "engineer_knowledge\n",
      "\t 4 knowledge engineer\n",
      "--------------------------------------------\n",
      "knowledge_surface\n",
      "\t 2 surface knowledge\n",
      "--------------------------------------------\n",
      "abstract_knowledge_structure\n",
      "\t 2 abstract knowledge structures\n",
      "--------------------------------------------\n",
      "surface_system\n",
      "\t 2 surface systems\n",
      "--------------------------------------------\n",
      "knowledge_level\n",
      "\t 3 knowledge level\n",
      "--------------------------------------------\n",
      "object_physicality\n",
      "\t 3 physicality objects\n",
      "--------------------------------------------\n",
      "inference_structure\n",
      "\t 2 inference structure\n",
      "\t 1 inference structures\n",
      "--------------------------------------------\n",
      "specification_task\n",
      "\t 1 specification of the tasks\n",
      "\t 1 task specification\n",
      "--------------------------------------------\n",
      "abstract_description_task\n",
      "\t 2 abstract task descriptions\n",
      "--------------------------------------------\n",
      "differ_level\n",
      "\t 2 differ levels\n",
      "--------------------------------------------\n",
      "domain_knowledge\n",
      "\t 3 domain knowledge\n",
      "--------------------------------------------\n",
      "class_meta\n",
      "\t 2 meta classes\n",
      "--------------------------------------------\n",
      "knowledge_task\n",
      "\t 1 task knowledge\n",
      "\t 1 knowledge about the tasks\n",
      "--------------------------------------------\n",
      "level_strategy\n",
      "\t 4 strategy level\n",
      "--------------------------------------------\n",
      "method_reasoning\n",
      "\t 2 reasoning methods\n",
      "\t 1 reasoning method\n",
      "--------------------------------------------\n",
      "al_et_patil\n",
      "\t 2 patil et al\n",
      "--------------------------------------------\n",
      "domain_medical\n",
      "\t 2 medical domain\n",
      "--------------------------------------------\n",
      "qualitative_simulation\n",
      "\t 3 qualitative simulation\n",
      "--------------------------------------------\n",
      "approach_kads\n",
      "\t 2 kads approach\n",
      "--------------------------------------------\n",
      "interpretation_model\n",
      "\t 2 interpretation models\n",
      "--------------------------------------------\n",
      "design_model\n",
      "\t 2 design model\n",
      "--------------------------------------------\n",
      "process_reasoning\n",
      "\t 4 reasoning process\n",
      "\t 1 reasoning processes\n",
      "--------------------------------------------\n",
      "classification_heuristic\n",
      "\t 2 heuristic classification\n",
      "--------------------------------------------\n",
      "acquisition_knowledge_process\n",
      "\t 2 knowledge acquisition process\n",
      "--------------------------------------------\n",
      "genus_task\n",
      "\t 2 genus task\n",
      "\t 1 genus tasks\n",
      "--------------------------------------------\n",
      "control_strategy\n",
      "\t 1 control strategy\n",
      "\t 1 control strategies\n",
      "--------------------------------------------\n",
      "expert_first_generation_system\n",
      "\t 2 first generation expert systems\n",
      "--------------------------------------------\n",
      "differ_domain\n",
      "\t 2 differ domains\n",
      "--------------------------------------------\n",
      "most_system\n",
      "\t 2 most systems\n",
      "--------------------------------------------\n",
      "i._mozetic\n",
      "\t 2 mozetic i.\n",
      "--------------------------------------------\n",
      "breuker_j.a.\n",
      "\t 2 breuker j.a.\n",
      "--------------------------------------------\n",
      "g._schreiber\n",
      "\t 2 schreiber g.\n",
      "--------------------------------------------\n",
      "b._bredeweg\n",
      "\t 2 bredeweg b.\n",
      "--------------------------------------------\n",
      "hayward_s.a.\n",
      "\t 2 hayward s.a.\n",
      "--------------------------------------------\n",
      "b._chandrasekaran\n",
      "\t 8 chandrasekaran b.\n",
      "--------------------------------------------\n",
      "bylander_t.\n",
      "\t 2 bylander t.\n",
      "--------------------------------------------\n",
      "10th_conference_international_joint\n",
      "\t 2 10th international joint conference\n",
      "--------------------------------------------\n",
      "j._sticklen\n",
      "\t 4 sticklen j.\n",
      "--------------------------------------------\n",
      "cis_lair_osu_technical\n",
      "\t 2 osu cis lair technical\n",
      "--------------------------------------------\n",
      "engineering_knowledge_review\n",
      "\t 2 knowledge engineering review\n",
      "--------------------------------------------\n",
      "davis_r.\n",
      "\t 2 davis r.\n",
      "--------------------------------------------\n",
      "conference_national_third\n",
      "\t 2 third national conference\n",
      "--------------------------------------------\n",
      "kaufmann_william\n",
      "\t 2 william kaufmann\n",
      "--------------------------------------------\n",
      "hunter_j.\n",
      "\t 4 hunter j.\n",
      "--------------------------------------------\n",
      "artificial_intelligence_medicine\n",
      "\t 2 artificial intelligence in medicine\n",
      "--------------------------------------------\n",
      "b.j._wielinga\n",
      "\t 2 wielinga b.j.\n",
      "--------------------------------------------\n",
      "causal_modeling\n",
      "\t 3 causal modeling\n",
      "--------------------------------------------\n",
      "conference_european_second\n",
      "\t 2 second european conference\n",
      "--------------------------------------------\n",
      "e.t._keravnou\n",
      "\t 2 keravnou e.t.\n",
      "--------------------------------------------\n",
      "j._washbrook\n",
      "\t 2 washbrook j.\n",
      "--------------------------------------------\n",
      "expert_systems\n",
      "\t 3 expert systems\n",
      "--------------------------------------------\n",
      "j.de_kleer\n",
      "\t 2 kleer j.de\n",
      "--------------------------------------------\n",
      "r._reiter\n",
      "\t 2 reiter r.\n",
      "--------------------------------------------\n",
      "marcus_s.(ed\n",
      "\t 2 marcus s.(ed\n",
      "--------------------------------------------\n",
      "acquisition_automating_knowledge\n",
      "\t 2 automating knowledge acquisition\n",
      "--------------------------------------------\n",
      "ai_magazine\n",
      "\t 2 ai magazine\n",
      "--------------------------------------------\n",
      "patil_r.s.\n",
      "\t 3 patil r.s.\n",
      "--------------------------------------------\n",
      "p._szolovits\n",
      "\t 2 szolovits p.\n",
      "--------------------------------------------\n",
      "schwartz_w.b.\n",
      "\t 2 schwartz w.b.\n",
      "--------------------------------------------\n",
      "diagnosis_medical\n",
      "\t 2 medical diagnosis\n",
      "--------------------------------------------\n",
      "press_westview\n",
      "\t 2 westview press\n",
      "--------------------------------------------\n",
      "b._wielinga\n",
      "\t 2 wielinga b.\n",
      "--------------------------------------------\n",
      "l._steel\n",
      "\t 4 steels l.\n",
      "--------------------------------------------\n",
      "based_model_reasoning\n",
      "\t 2 model based reasoning\n",
      "--------------------------------------------\n",
      "particularity_piece\n",
      "\t 2 particularity pieces\n",
      "--------------------------------------------\n",
      "currency_task\n",
      "\t 2 currency task\n",
      "--------------------------------------------\n",
      "performance_task\n",
      "\t 3 performance task\n",
      "--------------------------------------------\n",
      "declare_representation\n",
      "\t 2 declare representations\n",
      "--------------------------------------------\n",
      "failure_type\n",
      "\t 2 failure types\n",
      "\t 1 types of failures\n",
      "--------------------------------------------\n",
      "aqua_meta\n",
      "\t 8 meta aqua\n",
      "--------------------------------------------\n",
      "drug_smuggling\n",
      "\t 1 drug smuggling\n",
      "\t 1 smuggling drugs\n",
      "--------------------------------------------\n",
      "expectation_failure\n",
      "\t 7 expectation failure\n",
      "\t 3 expectation failures\n",
      "--------------------------------------------\n",
      "anomaly_situation\n",
      "\t 2 anomaly situation\n",
      "\t 1 anomaly situations\n",
      "--------------------------------------------\n",
      "goal_knowledge\n",
      "\t 4 knowledge goals\n",
      "\t 3 knowledge goal\n",
      "--------------------------------------------\n",
      "agent_reason\n",
      "\t 2 agent reasons\n",
      "--------------------------------------------\n",
      "reasoning_trace\n",
      "\t 1 trace of the reasoning\n",
      "\t 1 reasoning traces\n",
      "\t 1 trace of reasoning\n",
      "--------------------------------------------\n",
      "failure_reasoning\n",
      "\t 3 reasoning failure\n",
      "\t 1 reasoning failures\n",
      "--------------------------------------------\n",
      "general_meta_xp\n",
      "\t 4 general meta xp\n",
      "--------------------------------------------\n",
      "chain_reasoning\n",
      "\t 3 reasoning chain\n",
      "--------------------------------------------\n",
      "concept_memory\n",
      "\t 1 concept memory\n",
      "\t 1 concept in memory\n",
      "--------------------------------------------\n",
      "index_newness\n",
      "\t 2 newness index\n",
      "--------------------------------------------\n",
      "explanation_pattern\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 3 explanation patterns\n",
      "\t 1 explanation pattern\n",
      "--------------------------------------------\n",
      "method_particularity_reasoning\n",
      "\t 1 particularity reasoning methods\n",
      "\t 1 particularity reasoning method\n",
      "--------------------------------------------\n",
      "introspect_meta_xps\n",
      "\t 2 introspect meta xps\n",
      "--------------------------------------------\n",
      "assignment_blame\n",
      "\t 2 blame assignment\n",
      "--------------------------------------------\n",
      "error_reasoning\n",
      "\t 2 reasoning error\n",
      "--------------------------------------------\n",
      "cause_explanation\n",
      "\t 2 cause explanations\n",
      "--------------------------------------------\n",
      "animateness_object\n",
      "\t 2 animateness objects\n",
      "--------------------------------------------\n",
      "process_understanding\n",
      "\t 2 understanding process\n",
      "--------------------------------------------\n",
      "composite_meta_xp\n",
      "\t 2 composite meta xp\n",
      "--------------------------------------------\n",
      "novelsituation_xp\n",
      "\t 3 xp novelsituation\n",
      "--------------------------------------------\n",
      "indexedstructure_mis_xp\n",
      "\t 2 xp mis indexedstructure\n",
      "--------------------------------------------\n",
      "incorrectworld_model_xp\n",
      "\t 2 xp incorrectworld model\n",
      "--------------------------------------------\n",
      "coherence_concept\n",
      "\t 2 concept coherence\n",
      "--------------------------------------------\n",
      "nodes_pre_xp\n",
      "\t 2 pre xp nodes\n",
      "--------------------------------------------\n",
      "explains_node\n",
      "\t 3 explains node\n",
      "--------------------------------------------\n",
      "asserted_node_xp-\n",
      "\t 2 xp- asserted node\n",
      "--------------------------------------------\n",
      "currency_implementation\n",
      "\t 2 currency implementation\n",
      "--------------------------------------------\n",
      "algorithm_understanding\n",
      "\t 2 understanding algorithm\n",
      "--------------------------------------------\n",
      "concept_input\n",
      "\t 1 input to the concept\n",
      "\t 1 input concept\n",
      "\t 1 input concepts\n",
      "--------------------------------------------\n",
      "meta_xp\n",
      "\t 10 meta xp\n",
      "--------------------------------------------\n",
      "generation_hypothesis_strategy\n",
      "\t 1 strategies for hypothesis generation\n",
      "\t 1 hypothesis generation strategy\n",
      "--------------------------------------------\n",
      "reasoning_task\n",
      "\t 2 reasoning task\n",
      "--------------------------------------------\n",
      "asserted_nodes_xp\n",
      "\t 2 xp asserted nodes\n",
      "--------------------------------------------\n",
      "decision_model\n",
      "\t 1 decision models\n",
      "\t 1 decision model\n",
      "--------------------------------------------\n",
      "story_understanding\n",
      "\t 2 story understanding\n",
      "--------------------------------------------\n",
      "avail_strategy\n",
      "\t 2 avail strategies\n",
      "--------------------------------------------\n",
      "hayes_roth\n",
      "\t 3 hayes roth\n",
      "--------------------------------------------\n",
      "meta_xps\n",
      "\t 3 meta xps\n",
      "--------------------------------------------\n",
      "novel_situation\n",
      "\t 3 novel situation\n",
      "\t 1 novel situations\n",
      "--------------------------------------------\n",
      "failure_retrieval\n",
      "\t 6 retrieval failure\n",
      "--------------------------------------------\n",
      "prediction_successfulness\n",
      "\t 4 successfulness prediction\n",
      "\t 1 successfulness predictions\n",
      "--------------------------------------------\n",
      "a_node\n",
      "\t 2 node a\n",
      "--------------------------------------------\n",
      "a_e\n",
      "\t 2 a and e\n",
      "--------------------------------------------\n",
      "mentally_outcome\n",
      "\t 4 outcome mentally\n",
      "--------------------------------------------\n",
      "input_new_result\n",
      "\t 3 results new input\n",
      "--------------------------------------------\n",
      "chain_co_domain_domain\n",
      "\t 3 chain domain domain co\n",
      "--------------------------------------------\n",
      "co_domain_domain_domain\n",
      "\t 3 domain co - domain domain\n",
      "\t 1 domain domain co - domain\n",
      "--------------------------------------------\n",
      "co_domain_figure\n",
      "\t 2 co - domain figure\n",
      "--------------------------------------------\n",
      "item_memory\n",
      "\t 1 item in memory\n",
      "\t 1 memory item\n",
      "--------------------------------------------\n",
      "co_domain_domain_falsifie\n",
      "\t 2 falsifies domain co - domain\n",
      "--------------------------------------------\n",
      "actuality_outcome\n",
      "\t 3 actuality outcome\n",
      "--------------------------------------------\n",
      "annual_conference_sixth\n",
      "\t 2 sixth annual conference\n",
      "--------------------------------------------\n",
      "cognitive_science_society\n",
      "\t 4 cognitive science society\n",
      "--------------------------------------------\n",
      "conference_international_seventh\n",
      "\t 2 seventh international conference\n",
      "--------------------------------------------\n",
      "university_yale\n",
      "\t 2 yale university\n",
      "--------------------------------------------\n",
      "haven_new\n",
      "\t 2 new haven\n",
      "--------------------------------------------\n",
      "based_case_reasoning\n",
      "\t 2 case based reasoning\n",
      "--------------------------------------------\n",
      "class_evolution\n",
      "\t 3 class evolution\n",
      "--------------------------------------------\n",
      "class_dictionary_graph\n",
      "\t 25 class dictionary graph\n",
      "--------------------------------------------\n",
      "pattern_propagation\n",
      "\t 19 propagation pattern\n",
      "\t 10 propagation patterns\n",
      "--------------------------------------------\n",
      "class_structure\n",
      "\t 6 class structure\n",
      "\t 4 class structures\n",
      "--------------------------------------------\n",
      "c++_code\n",
      "\t 5 c++ code\n",
      "--------------------------------------------\n",
      "cycle_life_software\n",
      "\t 3 software life cycle\n",
      "--------------------------------------------\n",
      "class_dictionary_graph_propagation\n",
      "\t 2 class dictionary graphs and propagation\n",
      "--------------------------------------------\n",
      "class_construction\n",
      "\t 3 construction class\n",
      "\t 1 construction classes\n",
      "--------------------------------------------\n",
      "class_repetition\n",
      "\t 1 repetition class\n",
      "\t 1 repetition classes\n",
      "--------------------------------------------\n",
      "class_several\n",
      "\t 2 several classes\n",
      "--------------------------------------------\n",
      "class_company\n",
      "\t 7 company class\n",
      "--------------------------------------------\n",
      "department_name\n",
      "\t 2 name and departments\n",
      "--------------------------------------------\n",
      "class_department\n",
      "\t 2 department class\n",
      "--------------------------------------------\n",
      "class_employee\n",
      "\t 10 employee class\n",
      "--------------------------------------------\n",
      "c_v\n",
      "\t 2 v c\n",
      "--------------------------------------------\n",
      "class_v\n",
      "\t 4 class v\n",
      "--------------------------------------------\n",
      "class_newness_structure\n",
      "\t 4 newness class structure\n",
      "--------------------------------------------\n",
      "salary_value\n",
      "\t 2 salary value\n",
      "--------------------------------------------\n",
      "message_request\n",
      "\t 2 message request\n",
      "--------------------------------------------\n",
      "request_sumsal\n",
      "\t 2 sumsal request\n",
      "--------------------------------------------\n",
      "graph_propagation\n",
      "\t 21 propagation graph\n",
      "\t 1 propagation graphs\n",
      "--------------------------------------------\n",
      "class_responsibility\n",
      "\t 1 responsibility each class\n",
      "\t 1 class responsibility\n",
      "--------------------------------------------\n",
      "salary_totality_variable\n",
      "\t 2 salary totality variable\n",
      "\t 1 totality salary variable\n",
      "--------------------------------------------\n",
      "class_importance\n",
      "\t 2 importance classes\n",
      "--------------------------------------------\n",
      "message_trivia\n",
      "\t 2 trivia message\n",
      "--------------------------------------------\n",
      "change_class_structure\n",
      "\t 2 class structure changes\n",
      "--------------------------------------------\n",
      "interface_statement\n",
      "\t 2 interface statement\n",
      "--------------------------------------------\n",
      "message_sumsal\n",
      "\t 2 sumsal message\n",
      "--------------------------------------------\n",
      "name_part\n",
      "\t 2 name part\n",
      "--------------------------------------------\n",
      "directive_propagation\n",
      "\t 10 propagation directive\n",
      "--------------------------------------------\n",
      "class_dictionary_edge_set\n",
      "\t 2 set of edges in the class dictionary\n",
      "--------------------------------------------\n",
      "v_vertex\n",
      "\t 3 vertex v\n",
      "--------------------------------------------\n",
      "form_text\n",
      "\t 2 text form\n",
      "--------------------------------------------\n",
      "interface_method\n",
      "\t 2 method interface\n",
      "\t 1 method interfaces\n",
      "--------------------------------------------\n",
      "employee_part\n",
      "\t 2 employees part\n",
      "--------------------------------------------\n",
      "change_class_dictionary_graph\n",
      "\t 2 change in the class dictionary graph\n",
      "\t 1 changes in the class dictionary graph\n",
      "--------------------------------------------\n",
      "corresponding_graph_propagation\n",
      "\t 2 corresponding propagation graph\n",
      "--------------------------------------------\n",
      "edge_singleness\n",
      "\t 2 singleness edge\n",
      "--------------------------------------------\n",
      "target_vertex\n",
      "\t 2 target vertex\n",
      "--------------------------------------------\n",
      "otherness_relationship\n",
      "\t 2 otherness relationships\n",
      "--------------------------------------------\n",
      "class_company_dictionary_graph\n",
      "\t 1 class dictionary graph for companies\n",
      "\t 1 company class dictionary graph\n",
      "--------------------------------------------\n",
      "class_conglomerate\n",
      "\t 2 conglomerate class\n",
      "--------------------------------------------\n",
      "vertex_w\n",
      "\t 2 vertex w\n",
      "--------------------------------------------\n",
      "graph_original_propagation\n",
      "\t 2 original propagation graph\n",
      "--------------------------------------------\n",
      "newness_subclass\n",
      "\t 3 newness subclass\n",
      "--------------------------------------------\n",
      "evolution_schema\n",
      "\t 2 schema evolution\n",
      "--------------------------------------------\n",
      "j._karl_lieberherr\n",
      "\t 2 karl j. lieberherr\n"
     ]
    }
   ],
   "source": [
    "printgroup(concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "be_deem\n",
      "\t 3 is deemed\n",
      "\t 2 are deemed\n",
      "\t 1 were deemed\n",
      "--------------------------------------------\n",
      "be_have_modify\n",
      "\t 2 had been modified\n",
      "\t 1 has been modified\n",
      "\t 1 is modified to have\n",
      "--------------------------------------------\n",
      "have_implement\n",
      "\t 4 have implemented\n",
      "--------------------------------------------\n",
      "reduce_significantly\n",
      "\t 2 significantly reduce\n",
      "--------------------------------------------\n",
      "account_as\n",
      "\t 2 account for as\n",
      "--------------------------------------------\n",
      "be_have_propose\n",
      "\t 2 have been proposed\n",
      "\t 1 has been proposed\n",
      "--------------------------------------------\n",
      "be_provide\n",
      "\t 4 is to provide\n",
      "\t 3 be provided\n",
      "\t 2 are provided\n",
      "\t 1 was provided\n",
      "--------------------------------------------\n",
      "be_particularly\n",
      "\t 3 is particularly\n",
      "\t 2 be particularly\n",
      "--------------------------------------------\n",
      "be_concern\n",
      "\t 4 is concerned\n",
      "\t 1 be concerned\n",
      "\t 1 was concerned\n",
      "--------------------------------------------\n",
      "be_require\n",
      "\t 6 is required\n",
      "\t 2 be required\n",
      "\t 2 are required\n",
      "\t 1 is that they require\n",
      "\t 1 being required\n",
      "\t 1 was required\n",
      "--------------------------------------------\n",
      "be_make\n",
      "\t 11 be made\n",
      "\t 6 is made\n",
      "\t 5 are made\n",
      "\t 3 was made\n",
      "\t 1 were made\n",
      "\t 1 is how to make\n",
      "--------------------------------------------\n",
      "not_reveal\n",
      "\t 3 not reveal\n",
      "--------------------------------------------\n",
      "be_more\n",
      "\t 12 are more\n",
      "\t 10 is more\n",
      "\t 2 is a more\n",
      "\t 1 were more\n",
      "\t 1 is one of the more\n",
      "\t 1 was more\n",
      "\t 1 be more\n",
      "\t 1 's a more\n",
      "--------------------------------------------\n",
      "also_be_more\n",
      "\t 1 are also more\n",
      "\t 1 is also more\n",
      "--------------------------------------------\n",
      "be_modify\n",
      "\t 3 be modified\n",
      "\t 2 is modified\n",
      "\t 1 be a modified\n",
      "--------------------------------------------\n",
      "be_not\n",
      "\t 41 is not\n",
      "\t 22 are not\n",
      "\t 22 not be\n",
      "\t 4 was not\n",
      "\t 4 were not\n",
      "\t 1 not been\n",
      "\t 1 was n't\n",
      "--------------------------------------------\n",
      "be_call\n",
      "\t 12 is called\n",
      "\t 3 be called\n",
      "\t 2 are called\n",
      "\t 1 calls is\n",
      "--------------------------------------------\n",
      "be_label\n",
      "\t 1 are labeled\n",
      "\t 1 were labeled\n",
      "\t 1 is labelled\n",
      "--------------------------------------------\n",
      "be_construct\n",
      "\t 4 be constructed\n",
      "\t 3 are constructed\n",
      "\t 1 were constructed\n",
      "--------------------------------------------\n",
      "be_traverse\n",
      "\t 1 were traversed\n",
      "\t 1 was traversed\n",
      "\t 1 being traversed\n",
      "--------------------------------------------\n",
      "be_run\n",
      "\t 1 was run\n",
      "\t 1 run is\n",
      "\t 1 is run\n",
      "--------------------------------------------\n",
      "be_set\n",
      "\t 2 is set\n",
      "\t 2 are set\n",
      "\t 1 is to set\n",
      "\t 1 be set\n",
      "--------------------------------------------\n",
      "be_test\n",
      "\t 2 is tested\n",
      "\t 1 be tested\n",
      "\t 1 being tested\n",
      "\t 1 are tested\n",
      "\t 1 are testing\n",
      "\t 1 was tested\n",
      "\t 1 were tested\n",
      "--------------------------------------------\n",
      "be_limit\n",
      "\t 3 is limited\n",
      "--------------------------------------------\n",
      "be_most\n",
      "\t 3 are most\n",
      "\t 2 is most\n",
      "\t 2 is the most\n",
      "\t 1 are the most\n",
      "--------------------------------------------\n",
      "be_longer_no\n",
      "\t 4 is no longer\n",
      "\t 1 are no longer\n",
      "\t 1 no longer be\n",
      "--------------------------------------------\n",
      "formally_more\n",
      "\t 2 more formally\n",
      "--------------------------------------------\n",
      "be_execute\n",
      "\t 5 is executed\n",
      "\t 2 are executed\n",
      "--------------------------------------------\n",
      "be_lexically\n",
      "\t 2 are lexically\n",
      "--------------------------------------------\n",
      "do_not\n",
      "\t 4 does not\n",
      "\t 3 do not\n",
      "\t 2 not do\n",
      "\t 1 did not\n",
      "--------------------------------------------\n",
      "be_typically\n",
      "\t 2 is typically\n",
      "\t 1 are typically\n",
      "\t 1 typically are\n",
      "--------------------------------------------\n",
      "all_at\n",
      "\t 3 at all\n",
      "--------------------------------------------\n",
      "forth_so\n",
      "\t 7 so forth\n",
      "--------------------------------------------\n",
      "include_not\n",
      "\t 2 not including\n",
      "\t 1 not included\n",
      "\t 1 not include\n",
      "--------------------------------------------\n",
      "do_need_not\n",
      "\t 2 do not need\n",
      "\t 2 does not need\n",
      "\t 1 do n't need\n",
      "--------------------------------------------\n",
      "do_not_require\n",
      "\t 3 do not require\n",
      "--------------------------------------------\n",
      "base_be\n",
      "\t 12 is based\n",
      "\t 8 are based\n",
      "\t 4 was based\n",
      "\t 1 be based\n",
      "--------------------------------------------\n",
      "be_syntactically\n",
      "\t 4 are syntactically\n",
      "--------------------------------------------\n",
      "identically_label\n",
      "\t 3 identically labeled\n",
      "--------------------------------------------\n",
      "have_syntactically\n",
      "\t 2 have syntactically\n",
      "--------------------------------------------\n",
      "do_not_take\n",
      "\t 1 does not take\n",
      "\t 1 do not take\n",
      "--------------------------------------------\n",
      "call_compare\n",
      "\t 1 compare calls\n",
      "\t 1 calls compare\n",
      "--------------------------------------------\n",
      "be_semantically\n",
      "\t 3 are semantically\n",
      "\t 2 be semantically\n",
      "--------------------------------------------\n",
      "add_be_have\n",
      "\t 2 has been added\n",
      "--------------------------------------------\n",
      "compare_find\n",
      "\t 3 compare finds\n",
      "--------------------------------------------\n",
      "compare_consider\n",
      "\t 1 compare must consider\n",
      "\t 1 compare considers\n",
      "--------------------------------------------\n",
      "be_now\n",
      "\t 2 is now\n",
      "\t 1 now we are\n",
      "--------------------------------------------\n",
      "be_have\n",
      "\t 6 has been\n",
      "\t 4 have been\n",
      "\t 2 had been\n",
      "\t 1 have to be\n",
      "\t 1 is to have\n",
      "--------------------------------------------\n",
      "have_only_return\n",
      "\t 2 have returned only\n",
      "--------------------------------------------\n",
      "analyze_do_need_not\n",
      "\t 2 does not need to analyze\n",
      "--------------------------------------------\n",
      "be_insert\n",
      "\t 3 is inserted\n",
      "\t 1 be inserted\n",
      "--------------------------------------------\n",
      "invoke_then\n",
      "\t 2 then invokes\n",
      "--------------------------------------------\n",
      "make_still\n",
      "\t 2 still make\n",
      "--------------------------------------------\n",
      "have_only\n",
      "\t 4 has only\n",
      "\t 1 have only\n",
      "--------------------------------------------\n",
      "be_here\n",
      "\t 1 here is\n",
      "\t 1 here it may be\n",
      "\t 1 is here\n",
      "--------------------------------------------\n",
      "be_write\n",
      "\t 3 is written\n",
      "\t 3 are written\n",
      "\t 1 is ` written\n",
      "\t 1 is to write\n",
      "--------------------------------------------\n",
      "identify_precisely\n",
      "\t 2 precisely identifying\n",
      "\t 1 precisely identifies\n",
      "--------------------------------------------\n",
      "be_present\n",
      "\t 5 be presented\n",
      "\t 4 are presented\n",
      "\t 1 is presented\n",
      "--------------------------------------------\n",
      "be_use\n",
      "\t 31 be used\n",
      "\t 17 is used\n",
      "\t 9 are used\n",
      "\t 8 were used\n",
      "\t 6 was used\n",
      "\t 2 is to use\n",
      "\t 1 used to be\n",
      "\t 1 are using\n",
      "\t 1 used is\n",
      "--------------------------------------------\n",
      "find_not\n",
      "\t 3 not find\n",
      "--------------------------------------------\n",
      "also_be\n",
      "\t 9 are also\n",
      "\t 8 is also\n",
      "\t 4 also be\n",
      "\t 3 was also\n",
      "\t 2 were also\n",
      "--------------------------------------------\n",
      "be_show\n",
      "\t 15 is shown\n",
      "\t 7 are shown\n",
      "\t 1 showed that there are\n",
      "\t 1 show which are\n",
      "\t 1 is to show\n",
      "--------------------------------------------\n",
      "do_hold_not\n",
      "\t 5 does not hold\n",
      "--------------------------------------------\n",
      "exactly_select\n",
      "\t 2 selects exactly\n",
      "--------------------------------------------\n",
      "show_up\n",
      "\t 1 show up\n",
      "\t 1 showed up\n",
      "--------------------------------------------\n",
      "be_follow\n",
      "\t 8 is as follows\n",
      "\t 2 is followed\n",
      "\t 1 are as follows\n",
      "\t 1 following is\n",
      "\t 1 be followed\n",
      "--------------------------------------------\n",
      "be_bound\n",
      "\t 5 is bounded\n",
      "\t 1 are bounded\n",
      "--------------------------------------------\n",
      "be_let\n",
      "\t 1 let n be\n",
      "\t 1 let c(j;i;1 be\n",
      "--------------------------------------------\n",
      "also_increase\n",
      "\t 1 also increases\n",
      "\t 1 also increase\n",
      "--------------------------------------------\n",
      "force_unnecessarily\n",
      "\t 2 unnecessarily force\n",
      "--------------------------------------------\n",
      "more_yield\n",
      "\t 2 yield more\n",
      "--------------------------------------------\n",
      "add_be\n",
      "\t 7 is added\n",
      "\t 4 be added\n",
      "\t 2 are added\n",
      "\t 1 added to these are\n",
      "\t 1 was added\n",
      "--------------------------------------------\n",
      "be_remove\n",
      "\t 8 is removed\n",
      "\t 3 are removed\n",
      "\t 3 be removed\n",
      "\t 1 were removed\n",
      "--------------------------------------------\n",
      "be_even_more\n",
      "\t 3 is even more\n",
      "--------------------------------------------\n",
      "be_precisely\n",
      "\t 2 is precisely\n",
      "--------------------------------------------\n",
      "be_select\n",
      "\t 3 are selected\n",
      "\t 1 is selected\n",
      "\t 1 be selected\n",
      "\t 1 were selected\n",
      "--------------------------------------------\n",
      "also_keep\n",
      "\t 1 also keeps\n",
      "\t 1 also keep\n",
      "--------------------------------------------\n",
      "begin_have\n",
      "\t 1 has begun\n",
      "\t 1 have begun\n",
      "--------------------------------------------\n",
      "be_reach\n",
      "\t 3 is reached\n",
      "\t 2 was reached\n",
      "--------------------------------------------\n",
      "occur_only\n",
      "\t 1 occur only\n",
      "\t 1 occurs only\n",
      "--------------------------------------------\n",
      "be_change\n",
      "\t 4 be changed\n",
      "\t 2 is changed\n",
      "\t 1 are changed\n",
      "\t 1 was changed\n",
      "--------------------------------------------\n",
      "also_apply\n",
      "\t 2 also apply\n",
      "--------------------------------------------\n",
      "begin_traverse\n",
      "\t 3 begins traversing\n",
      "--------------------------------------------\n",
      "eventually_reach\n",
      "\t 1 eventually reaches\n",
      "\t 1 eventually reach\n",
      "--------------------------------------------\n",
      "do_not_reinvoke\n",
      "\t 2 does not reinvoke\n",
      "--------------------------------------------\n",
      "be_compare\n",
      "\t 5 are compared\n",
      "\t 1 be compared\n",
      "\t 1 is to compare\n",
      "--------------------------------------------\n",
      "find_have\n",
      "\t 3 have found\n",
      "\t 1 has found\n",
      "--------------------------------------------\n",
      "also_make\n",
      "\t 3 also make\n",
      "--------------------------------------------\n",
      "control_only\n",
      "\t 2 only for controlled\n",
      "--------------------------------------------\n",
      "have_not\n",
      "\t 3 not have\n",
      "\t 1 not having\n",
      "\t 1 have not\n",
      "--------------------------------------------\n",
      "be_often\n",
      "\t 5 is often\n",
      "\t 2 are often\n",
      "--------------------------------------------\n",
      "do_know_not\n",
      "\t 1 do not know\n",
      "\t 1 does not know\n",
      "\t 1 do n't know\n",
      "\t 1 did not know\n",
      "--------------------------------------------\n",
      "affect_do_not\n",
      "\t 3 does not affect\n",
      "\t 3 do not affect\n",
      "--------------------------------------------\n",
      "be_too\n",
      "\t 2 is too\n",
      "\t 1 be neither too\n",
      "\t 1 are too\n",
      "--------------------------------------------\n",
      "be_exercise\n",
      "\t 1 was exercised\n",
      "\t 1 be exercised\n",
      "--------------------------------------------\n",
      "also_have\n",
      "\t 6 also has\n",
      "\t 4 also have\n",
      "\t 1 also had\n",
      "--------------------------------------------\n",
      "run_then\n",
      "\t 2 then ran\n",
      "--------------------------------------------\n",
      "modify_retest\n",
      "\t 1 retest modified\n",
      "\t 1 retesting modified\n",
      "--------------------------------------------\n",
      "require_run\n",
      "\t 3 required to run\n",
      "\t 1 requires run\n",
      "--------------------------------------------\n",
      "also_show\n",
      "\t 3 also show\n",
      "\t 2 also shows\n",
      "--------------------------------------------\n",
      "only_save\n",
      "\t 1 saved only\n",
      "\t 1 only save\n",
      "--------------------------------------------\n",
      "be_relatively\n",
      "\t 2 is relatively\n",
      "\t 1 be relatively\n",
      "\t 1 is a relatively\n",
      "\t 1 are at a relatively\n",
      "--------------------------------------------\n",
      "be_essentially\n",
      "\t 3 is essentially\n",
      "\t 1 are essentially\n",
      "--------------------------------------------\n",
      "do_so\n",
      "\t 7 do so\n",
      "--------------------------------------------\n",
      "be_have_rewrite\n",
      "\t 2 has been rewritten\n",
      "--------------------------------------------\n",
      "be_create_have\n",
      "\t 1 have been created\n",
      "\t 1 is created which has\n",
      "--------------------------------------------\n",
      "contain_only\n",
      "\t 1 contain only\n",
      "\t 1 contains only\n",
      "--------------------------------------------\n",
      "be_reasonably\n",
      "\t 1 is reasonably\n",
      "\t 1 was reasonably\n",
      "--------------------------------------------\n",
      "determine_exactly\n",
      "\t 1 determines exactly\n",
      "\t 1 determine exactly\n",
      "--------------------------------------------\n",
      "build_require\n",
      "\t 2 required to build\n",
      "--------------------------------------------\n",
      "consider_only\n",
      "\t 1 consider only\n",
      "\t 1 considering only\n",
      "--------------------------------------------\n",
      "have_report\n",
      "\t 2 have reported\n",
      "--------------------------------------------\n",
      "be_influence\n",
      "\t 1 was influenced\n",
      "\t 1 is influenced\n",
      "--------------------------------------------\n",
      "be_expose\n",
      "\t 1 is exposed\n",
      "\t 1 be exposed\n",
      "--------------------------------------------\n",
      "be_consider\n",
      "\t 4 be considered\n",
      "\t 3 is considered\n",
      "\t 1 is to consider\n",
      "\t 1 are considered\n",
      "--------------------------------------------\n",
      "exist_there\n",
      "\t 5 there exist\n",
      "\t 1 there exists\n",
      "--------------------------------------------\n",
      "have_show\n",
      "\t 5 have shown\n",
      "\t 1 has shown\n",
      "--------------------------------------------\n",
      "be_increase\n",
      "\t 1 is increasing\n",
      "\t 1 are increasing\n",
      "\t 1 is an increasing\n",
      "\t 1 be increased\n",
      "--------------------------------------------\n",
      "be_create\n",
      "\t 4 is created\n",
      "\t 3 are created\n",
      "\t 1 be created\n",
      "--------------------------------------------\n",
      "be_release\n",
      "\t 2 is released\n",
      "--------------------------------------------\n",
      "be_reduce\n",
      "\t 4 be reduced\n",
      "\t 3 is reduced\n",
      "\t 1 is to reduce\n",
      "\t 1 was reduced\n",
      "--------------------------------------------\n",
      "discover_have\n",
      "\t 2 have discovered\n",
      "--------------------------------------------\n",
      "focus_have\n",
      "\t 2 have focused\n",
      "\t 1 has focused\n",
      "--------------------------------------------\n",
      "be_ensure\n",
      "\t 1 is that of ensuring\n",
      "\t 1 is ensured\n",
      "--------------------------------------------\n",
      "help_identify\n",
      "\t 1 help identify\n",
      "\t 1 helps identify\n",
      "--------------------------------------------\n",
      "find_try\n",
      "\t 2 try to find\n",
      "--------------------------------------------\n",
      "guarantee_not\n",
      "\t 2 not guarantee\n",
      "--------------------------------------------\n",
      "be_simply\n",
      "\t 5 is simply\n",
      "\t 2 are simply\n",
      "--------------------------------------------\n",
      "be_much\n",
      "\t 2 is much\n",
      "\t 1 are much\n",
      "--------------------------------------------\n",
      "have_start\n",
      "\t 1 have started\n",
      "\t 1 has started\n",
      "--------------------------------------------\n",
      "matter_no\n",
      "\t 2 no matter\n",
      "--------------------------------------------\n",
      "be_need\n",
      "\t 7 is needed\n",
      "\t 4 are needed\n",
      "\t 2 be needed\n",
      "\t 1 needed is\n",
      "\t 1 was needed\n",
      "--------------------------------------------\n",
      "be_expect\n",
      "\t 2 be expected\n",
      "\t 1 be the expected\n",
      "--------------------------------------------\n",
      "be_even\n",
      "\t 2 is even\n",
      "\t 1 are even\n",
      "\t 1 even if this is\n",
      "--------------------------------------------\n",
      "do_provide\n",
      "\t 2 does provide\n",
      "--------------------------------------------\n",
      "be_however_not\n",
      "\t 1 however it is not\n",
      "\t 1 however is not\n",
      "--------------------------------------------\n",
      "have_use\n",
      "\t 6 have used\n",
      "\t 1 uses has\n",
      "\t 1 have to use\n",
      "--------------------------------------------\n",
      "be_very\n",
      "\t 18 is very\n",
      "\t 7 be very\n",
      "\t 4 are very\n",
      "\t 1 is a very\n",
      "\t 1 was very\n",
      "--------------------------------------------\n",
      "be_define\n",
      "\t 5 is defined\n",
      "\t 4 be defined\n",
      "\t 1 were defined\n",
      "\t 1 are defined\n",
      "--------------------------------------------\n",
      "be_supply\n",
      "\t 2 be supplied\n",
      "--------------------------------------------\n",
      "only_use\n",
      "\t 2 using only\n",
      "\t 2 uses only\n",
      "\t 1 only use\n",
      "--------------------------------------------\n",
      "be_extremely\n",
      "\t 3 is extremely\n",
      "\t 1 are extremely\n",
      "\t 1 be extremely\n",
      "--------------------------------------------\n",
      "be_include\n",
      "\t 4 is included\n",
      "\t 2 be included\n",
      "\t 2 being included\n",
      "\t 1 are included\n",
      "--------------------------------------------\n",
      "be_report\n",
      "\t 2 be reported\n",
      "\t 1 was reported\n",
      "\t 1 is reported\n",
      "--------------------------------------------\n",
      "be_still\n",
      "\t 6 is still\n",
      "\t 3 still be\n",
      "\t 2 are still\n",
      "--------------------------------------------\n",
      "appear_be\n",
      "\t 2 appears to be\n",
      "\t 1 appear to be\n",
      "--------------------------------------------\n",
      "be_distinguish\n",
      "\t 1 be distinguished\n",
      "\t 1 is distinguished\n",
      "--------------------------------------------\n",
      "be_divide\n",
      "\t 2 be divided\n",
      "--------------------------------------------\n",
      "associate_be\n",
      "\t 2 is associated\n",
      "\t 1 are associated\n",
      "\t 1 be associated\n",
      "--------------------------------------------\n",
      "associate_be_usually\n",
      "\t 1 usually being associated\n",
      "\t 1 is usually associated\n",
      "--------------------------------------------\n",
      "be_terminate\n",
      "\t 1 is terminated\n",
      "\t 1 be terminated\n",
      "--------------------------------------------\n",
      "be_duplicate\n",
      "\t 1 be duplicated\n",
      "\t 1 is duplicated\n",
      "--------------------------------------------\n",
      "be_not_suit_well\n",
      "\t 1 is not well suited\n",
      "\t 1 are not suited well\n",
      "--------------------------------------------\n",
      "be_sufficiently\n",
      "\t 2 is sufficiently\n",
      "--------------------------------------------\n",
      "be_generate_use\n",
      "\t 1 be used to generate\n",
      "\t 1 be used to generated\n",
      "--------------------------------------------\n",
      "allow_thus\n",
      "\t 2 thus allowing\n",
      "--------------------------------------------\n",
      "understand_well\n",
      "\t 2 well understood\n",
      "--------------------------------------------\n",
      "be_relate\n",
      "\t 1 be related\n",
      "\t 1 being related\n",
      "--------------------------------------------\n",
      "be_give\n",
      "\t 8 is given\n",
      "\t 2 were given\n",
      "\t 2 be given\n",
      "\t 1 are given\n",
      "--------------------------------------------\n",
      "as_far\n",
      "\t 2 as far\n",
      "--------------------------------------------\n",
      "be_match\n",
      "\t 4 be matched\n",
      "\t 3 is matched\n",
      "--------------------------------------------\n",
      "below_see\n",
      "\t 3 see below\n",
      "--------------------------------------------\n",
      "be_take\n",
      "\t 4 is taken\n",
      "\t 1 be taken\n",
      "\t 1 were taken\n",
      "\t 1 are taking\n",
      "\t 1 are taken\n",
      "--------------------------------------------\n",
      "attach_be\n",
      "\t 2 be attached\n",
      "\t 1 are attached\n",
      "--------------------------------------------\n",
      "be_find\n",
      "\t 9 be found\n",
      "\t 3 is found\n",
      "\t 2 was found\n",
      "\t 1 being found\n",
      "\t 1 is to find\n",
      "\t 1 are found\n",
      "\t 1 find but it is\n",
      "--------------------------------------------\n",
      "do_match_not\n",
      "\t 1 does not match\n",
      "\t 1 do not match\n",
      "--------------------------------------------\n",
      "be_substitute\n",
      "\t 3 be substituted\n",
      "\t 1 are substituted\n",
      "--------------------------------------------\n",
      "be_replace\n",
      "\t 3 is replaced\n",
      "--------------------------------------------\n",
      "allow_be_not\n",
      "\t 2 are not allowed\n",
      "--------------------------------------------\n",
      "be_introduce\n",
      "\t 2 is introduced\n",
      "\t 1 were introduced\n",
      "\t 1 be introduced\n",
      "--------------------------------------------\n",
      "be_precede\n",
      "\t 2 be preceded\n",
      "--------------------------------------------\n",
      "be_pass\n",
      "\t 3 is passed\n",
      "\t 1 be passed\n",
      "\t 1 were passed\n",
      "--------------------------------------------\n",
      "be_quite\n",
      "\t 4 is quite\n",
      "\t 2 be quite\n",
      "\t 1 are quite\n",
      "--------------------------------------------\n",
      "out_turn\n",
      "\t 3 turns out\n",
      "\t 2 turn out\n",
      "\t 1 out turned\n",
      "--------------------------------------------\n",
      "be_exactly\n",
      "\t 2 is exactly\n",
      "--------------------------------------------\n",
      "be_thus\n",
      "\t 1 thus is\n",
      "\t 1 thus there was\n",
      "--------------------------------------------\n",
      "on_so\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 8 so on\n",
      "--------------------------------------------\n",
      "be_hold\n",
      "\t 2 is held\n",
      "\t 1 be held\n",
      "--------------------------------------------\n",
      "be_treat\n",
      "\t 3 be treated\n",
      "\t 1 is treated\n",
      "--------------------------------------------\n",
      "assign_be\n",
      "\t 1 was assigned\n",
      "\t 1 are assigned\n",
      "\t 1 were assigned\n",
      "--------------------------------------------\n",
      "be_remarkably\n",
      "\t 1 is remarkably\n",
      "\t 1 be remarkably\n",
      "--------------------------------------------\n",
      "have_mean\n",
      "\t 1 has meant\n",
      "\t 1 means that we will have\n",
      "--------------------------------------------\n",
      "be_do\n",
      "\t 5 be done\n",
      "\t 2 was done\n",
      "\t 2 is done\n",
      "\t 1 were done\n",
      "\t 1 be doing\n",
      "--------------------------------------------\n",
      "be_develop\n",
      "\t 1 were developed\n",
      "\t 1 was developed\n",
      "\t 1 is that it develops\n",
      "\t 1 are developing\n",
      "\t 1 was to develop\n",
      "--------------------------------------------\n",
      "as_well\n",
      "\t 30 as well\n",
      "--------------------------------------------\n",
      "be_publish\n",
      "\t 1 be published\n",
      "\t 1 were published\n",
      "--------------------------------------------\n",
      "be_implement\n",
      "\t 3 was implemented\n",
      "\t 3 are implemented\n",
      "\t 3 is implemented\n",
      "\t 2 were implemented\n",
      "\t 1 be implemented\n",
      "\t 1 being implemented\n",
      "--------------------------------------------\n",
      "be_realize\n",
      "\t 1 realized there were\n",
      "\t 1 be realized\n",
      "--------------------------------------------\n",
      "be_visualize\n",
      "\t 1 be visualized\n",
      "\t 1 being visualized\n",
      "--------------------------------------------\n",
      "lay_out\n",
      "\t 1 laid out\n",
      "\t 1 lays out\n",
      "--------------------------------------------\n",
      "be_completely\n",
      "\t 3 is completely\n",
      "\t 1 be completely\n",
      "\t 1 are there completely\n",
      "--------------------------------------------\n",
      "be_describe\n",
      "\t 4 are described\n",
      "\t 4 is described\n",
      "\t 1 be described\n",
      "--------------------------------------------\n",
      "be_build\n",
      "\t 2 be built\n",
      "\t 1 is to build\n",
      "\t 1 is built\n",
      "--------------------------------------------\n",
      "be_display\n",
      "\t 1 is displayed\n",
      "\t 1 be displayed\n",
      "--------------------------------------------\n",
      "actually_be\n",
      "\t 2 is actually\n",
      "--------------------------------------------\n",
      "do_not_use\n",
      "\t 2 did not use\n",
      "\t 2 does not use\n",
      "\t 1 do not use\n",
      "--------------------------------------------\n",
      "away_far\n",
      "\t 2 far away\n",
      "--------------------------------------------\n",
      "be_choose\n",
      "\t 2 are chosen\n",
      "\t 1 chose are\n",
      "\t 1 is chosen\n",
      "\t 1 was chosen\n",
      "--------------------------------------------\n",
      "apply_be\n",
      "\t 7 be applied\n",
      "\t 2 is applied\n",
      "--------------------------------------------\n",
      "be_especially\n",
      "\t 1 be especially\n",
      "\t 1 is especially\n",
      "--------------------------------------------\n",
      "be_touch\n",
      "\t 1 were touched\n",
      "\t 1 are touched\n",
      "--------------------------------------------\n",
      "even_further\n",
      "\t 2 even further\n",
      "--------------------------------------------\n",
      "do_have_not\n",
      "\t 7 do not have\n",
      "\t 4 does not have\n",
      "\t 1 do n't have\n",
      "--------------------------------------------\n",
      "become_even_more\n",
      "\t 1 even become more\n",
      "\t 1 becomes even more\n",
      "--------------------------------------------\n",
      "be_conduct\n",
      "\t 1 be conducted\n",
      "\t 1 were conducted\n",
      "--------------------------------------------\n",
      "very_well\n",
      "\t 2 very well\n",
      "--------------------------------------------\n",
      "be_restrict\n",
      "\t 1 are restricted\n",
      "\t 1 be restricted\n",
      "--------------------------------------------\n",
      "be_determine\n",
      "\t 5 is determined\n",
      "--------------------------------------------\n",
      "be_extend\n",
      "\t 1 be extended\n",
      "\t 1 is to extend\n",
      "--------------------------------------------\n",
      "be_improve\n",
      "\t 4 be improved\n",
      "\t 1 was improved\n",
      "\t 1 is to improve\n",
      "\t 1 is improved\n",
      "--------------------------------------------\n",
      "be_share\n",
      "\t 2 are shared\n",
      "\t 2 is shared\n",
      "\t 1 being shared\n",
      "\t 1 be shared\n",
      "--------------------------------------------\n",
      "be_invalidate\n",
      "\t 1 are invalidated\n",
      "\t 1 be invalidated\n",
      "--------------------------------------------\n",
      "be_keep_use\n",
      "\t 2 is used to keep\n",
      "\t 1 be used to keep\n",
      "--------------------------------------------\n",
      "be_be\n",
      "\t 1 is that they are\n",
      "\t 1 is to be\n",
      "\t 1 is why it is\n",
      "\t 1 is because there is\n",
      "--------------------------------------------\n",
      "use_write\n",
      "\t 2 use write\n",
      "--------------------------------------------\n",
      "be_manage\n",
      "\t 1 be managed\n",
      "\t 1 is to manage\n",
      "--------------------------------------------\n",
      "always_have\n",
      "\t 1 always have\n",
      "\t 1 always has\n",
      "--------------------------------------------\n",
      "have_read\n",
      "\t 2 has read\n",
      "\t 2 have read\n",
      "\t 1 has a read\n",
      "--------------------------------------------\n",
      "be_only\n",
      "\t 8 is only\n",
      "\t 2 were only\n",
      "\t 1 only be\n",
      "\t 1 was only\n",
      "\t 1 be only\n",
      "--------------------------------------------\n",
      "be_suppose\n",
      "\t 1 suppose that there are\n",
      "\t 1 are supposed\n",
      "--------------------------------------------\n",
      "even_only\n",
      "\t 1 even if only\n",
      "\t 1 even with only\n",
      "--------------------------------------------\n",
      "be_globally_perform\n",
      "\t 1 are globally performed\n",
      "\t 1 be globally performed\n",
      "--------------------------------------------\n",
      "then_use\n",
      "\t 2 then uses\n",
      "\t 1 then use\n",
      "\t 1 then using\n",
      "--------------------------------------------\n",
      "be_view\n",
      "\t 2 be viewed\n",
      "\t 1 are viewed\n",
      "\t 1 are viewing\n",
      "\t 1 were viewed\n",
      "--------------------------------------------\n",
      "also_reduce\n",
      "\t 2 also reduce\n",
      "--------------------------------------------\n",
      "be_order\n",
      "\t 2 are ordered\n",
      "\t 1 were ordered\n",
      "--------------------------------------------\n",
      "allow_be\n",
      "\t 4 is allowed\n",
      "\t 4 are allowed\n",
      "\t 2 is to allow\n",
      "\t 2 were allowed\n",
      "\t 1 be allowed\n",
      "\t 1 allows them to be\n",
      "--------------------------------------------\n",
      "be_perform\n",
      "\t 5 be performed\n",
      "\t 3 is performed\n",
      "\t 3 is performing\n",
      "\t 2 are performed\n",
      "--------------------------------------------\n",
      "allow_be_perform\n",
      "\t 2 is allowed to perform\n",
      "\t 1 is performing allows\n",
      "--------------------------------------------\n",
      "access_be_much_perform\n",
      "\t 2 accesses much be performed\n",
      "--------------------------------------------\n",
      "only_perform\n",
      "\t 1 perform only\n",
      "\t 1 performs only\n",
      "--------------------------------------------\n",
      "be_delay\n",
      "\t 1 be delayed\n",
      "\t 1 is delayed\n",
      "--------------------------------------------\n",
      "be_then\n",
      "\t 2 then be\n",
      "\t 2 is then\n",
      "\t 1 then it is\n",
      "--------------------------------------------\n",
      "be_guarantee\n",
      "\t 1 are guaranteed\n",
      "\t 1 is guaranteed\n",
      "\t 1 be guaranteed\n",
      "--------------------------------------------\n",
      "be_have_perform\n",
      "\t 2 have been performed\n",
      "\t 2 has been performed\n",
      "--------------------------------------------\n",
      "make_then\n",
      "\t 2 then make\n",
      "\t 1 made then\n",
      "\t 1 then made\n",
      "\t 1 then makes\n",
      "--------------------------------------------\n",
      "be_transfer\n",
      "\t 2 is transferred\n",
      "\t 2 be transferred\n",
      "\t 1 transferred is\n",
      "--------------------------------------------\n",
      "be_minimize\n",
      "\t 1 is to minimize\n",
      "\t 1 is minimized\n",
      "--------------------------------------------\n",
      "be_calculate\n",
      "\t 1 are calculated\n",
      "\t 1 is calculated\n",
      "--------------------------------------------\n",
      "be_close\n",
      "\t 1 be close\n",
      "\t 1 is close\n",
      "--------------------------------------------\n",
      "be_ne_not\n",
      "\t 3 need not be\n",
      "--------------------------------------------\n",
      "be_simulate\n",
      "\t 1 being simulated\n",
      "\t 1 are simulated\n",
      "--------------------------------------------\n",
      "be_evaluate\n",
      "\t 3 is evaluated\n",
      "\t 2 be evaluated\n",
      "\t 1 are evaluating\n",
      "\t 1 was to evaluate\n",
      "--------------------------------------------\n",
      "be_simulate_use\n",
      "\t 1 were simulated using\n",
      "\t 1 is used to simulate\n",
      "--------------------------------------------\n",
      "be_measure\n",
      "\t 1 is measured\n",
      "\t 1 are measured\n",
      "\t 1 were measured\n",
      "\t 1 is how to measure\n",
      "--------------------------------------------\n",
      "become_more\n",
      "\t 2 becomes more\n",
      "--------------------------------------------\n",
      "actually_perform\n",
      "\t 1 actually performs\n",
      "\t 1 actually perform\n",
      "--------------------------------------------\n",
      "be_roughly\n",
      "\t 1 is roughly\n",
      "\t 1 are roughly\n",
      "--------------------------------------------\n",
      "be_generate\n",
      "\t 5 is generated\n",
      "\t 4 be generated\n",
      "\t 3 are generated\n",
      "\t 2 were generated\n",
      "\t 1 was generated\n",
      "--------------------------------------------\n",
      "be_distribute_evenly\n",
      "\t 1 be evenly distributed\n",
      "\t 1 is evenly distributed\n",
      "--------------------------------------------\n",
      "be_spend\n",
      "\t 2 is spend\n",
      "--------------------------------------------\n",
      "allow_more\n",
      "\t 1 allows for more\n",
      "\t 1 allow for a more\n",
      "\t 1 allowing more\n",
      "--------------------------------------------\n",
      "be_partition\n",
      "\t 1 be partitioned\n",
      "\t 1 is partitioned\n",
      "--------------------------------------------\n",
      "be_support\n",
      "\t 3 was supported\n",
      "\t 3 be supported\n",
      "\t 2 is supported\n",
      "\t 1 was supporting\n",
      "--------------------------------------------\n",
      "be_largely\n",
      "\t 2 is largely\n",
      "\t 1 are largely\n",
      "--------------------------------------------\n",
      "accommodate_be\n",
      "\t 2 be accommodated\n",
      "--------------------------------------------\n",
      "be_design\n",
      "\t 2 was designed\n",
      "\t 1 is designed\n",
      "\t 1 was designing\n",
      "--------------------------------------------\n",
      "be_cover\n",
      "\t 2 are covered\n",
      "\t 1 be covered\n",
      "--------------------------------------------\n",
      "be_therefore\n",
      "\t 3 is therefore\n",
      "\t 1 therefore those are\n",
      "\t 1 therefore it is\n",
      "\t 1 's therefore\n",
      "--------------------------------------------\n",
      "be_store\n",
      "\t 3 be stored\n",
      "\t 2 are stored\n",
      "\t 1 is stored\n",
      "--------------------------------------------\n",
      "be_initiate\n",
      "\t 2 is initiated\n",
      "--------------------------------------------\n",
      "greatly_simplify\n",
      "\t 1 greatly simplifies\n",
      "\t 1 simplifies greatly\n",
      "\t 1 greatly simplify\n",
      "--------------------------------------------\n",
      "address_not\n",
      "\t 1 not addressing\n",
      "\t 1 not addressed\n",
      "--------------------------------------------\n",
      "be_rather\n",
      "\t 4 is rather\n",
      "\t 3 are rather\n",
      "\t 1 rather is\n",
      "--------------------------------------------\n",
      "do_have\n",
      "\t 1 do have\n",
      "\t 1 has done\n",
      "--------------------------------------------\n",
      "be_mix\n",
      "\t 3 are mixed\n",
      "--------------------------------------------\n",
      "be_see\n",
      "\t 6 be seen\n",
      "\t 1 see that this is\n",
      "\t 1 see if there was\n",
      "--------------------------------------------\n",
      "not_use\n",
      "\t 2 not use\n",
      "--------------------------------------------\n",
      "be_generally\n",
      "\t 2 is generally\n",
      "\t 1 generally being\n",
      "\t 1 are generally\n",
      "--------------------------------------------\n",
      "now_turn\n",
      "\t 1 turn now\n",
      "\t 1 now turn\n",
      "--------------------------------------------\n",
      "be_interpret\n",
      "\t 2 be interpreted\n",
      "\t 1 is interpreted\n",
      "--------------------------------------------\n",
      "accept_generally\n",
      "\t 2 generally accepted\n",
      "--------------------------------------------\n",
      "build_up\n",
      "\t 2 built up\n",
      "--------------------------------------------\n",
      "be_be_design\n",
      "\t 1 is being designed\n",
      "\t 1 is that it is designed\n",
      "\t 1 is designed to be\n",
      "\t 1 was designed is\n",
      "--------------------------------------------\n",
      "assume_be\n",
      "\t 3 is assumed\n",
      "\t 1 are assumed\n",
      "\t 1 was assumed\n",
      "\t 1 be assumed\n",
      "\t 1 is to assume\n",
      "--------------------------------------------\n",
      "be_somewhat\n",
      "\t 1 is somewhat\n",
      "\t 1 are somewhat\n",
      "--------------------------------------------\n",
      "be_form\n",
      "\t 2 are formed\n",
      "--------------------------------------------\n",
      "be_define_follow\n",
      "\t 2 is defined as follows\n",
      "\t 1 are defined as follows\n",
      "\t 1 were defined as follows\n",
      "--------------------------------------------\n",
      "be_express\n",
      "\t 4 be expressed\n",
      "\t 2 is expressed\n",
      "\t 1 are expressed\n",
      "--------------------------------------------\n",
      "also_see\n",
      "\t 2 see also\n",
      "--------------------------------------------\n",
      "be_not_so\n",
      "\t 1 so it is not\n",
      "\t 1 not be so\n",
      "\t 1 were not so\n",
      "--------------------------------------------\n",
      "be_mention\n",
      "\t 2 was mentioned\n",
      "\t 1 be mentioned\n",
      "--------------------------------------------\n",
      "be_however\n",
      "\t 1 however there is\n",
      "\t 1 is however\n",
      "--------------------------------------------\n",
      "be_propose\n",
      "\t 1 are proposed\n",
      "\t 1 was proposed\n",
      "\t 1 were proposed\n",
      "--------------------------------------------\n",
      "be_represent\n",
      "\t 7 is represented\n",
      "\t 6 are represented\n",
      "\t 2 be represented\n",
      "\t 1 was to represent\n",
      "\t 1 are representing\n",
      "\t 1 represent what must be\n",
      "\t 1 is to represent\n",
      "--------------------------------------------\n",
      "be_receive\n",
      "\t 2 is received\n",
      "--------------------------------------------\n",
      "be_bind\n",
      "\t 6 is bound\n",
      "\t 1 is to bind\n",
      "\t 1 bound is\n",
      "--------------------------------------------\n",
      "be_suspend\n",
      "\t 3 is suspended\n",
      "\t 1 be suspended\n",
      "\t 1 are suspended\n",
      "--------------------------------------------\n",
      "be_be_do\n",
      "\t 1 is being done\n",
      "\t 1 was done so that it would be\n",
      "--------------------------------------------\n",
      "care_do_n't\n",
      "\t 2 do n't care\n",
      "--------------------------------------------\n",
      "be_compute\n",
      "\t 3 be computed\n",
      "\t 1 are computed\n",
      "\t 1 is computed\n",
      "--------------------------------------------\n",
      "achieve_be\n",
      "\t 2 be achieved\n",
      "\t 1 are achieved\n",
      "--------------------------------------------\n",
      "arrange_be\n",
      "\t 2 be arranged\n",
      "--------------------------------------------\n",
      "be_not_quite\n",
      "\t 2 is not quite\n",
      "--------------------------------------------\n",
      "not_only\n",
      "\t 3 not only\n",
      "--------------------------------------------\n",
      "be_pursue\n",
      "\t 1 are pursued\n",
      "\t 1 be pursued\n",
      "--------------------------------------------\n",
      "be_consume\n",
      "\t 3 is consumed\n",
      "\t 2 are consumed\n",
      "--------------------------------------------\n",
      "also_know\n",
      "\t 2 also knows\n",
      "--------------------------------------------\n",
      "be_establish\n",
      "\t 1 be established\n",
      "\t 1 is established\n",
      "--------------------------------------------\n",
      "be_connect\n",
      "\t 1 be connected\n",
      "\t 1 are connected\n",
      "--------------------------------------------\n",
      "be_employ\n",
      "\t 2 be employed\n",
      "\t 1 are those that employ\n",
      "--------------------------------------------\n",
      "be_move\n",
      "\t 1 be moved\n",
      "\t 1 is moving\n",
      "--------------------------------------------\n",
      "be_not_only\n",
      "\t 2 is not only\n",
      "\t 1 not only is\n",
      "--------------------------------------------\n",
      "be_split\n",
      "\t 2 is split\n",
      "\t 1 be split\n",
      "--------------------------------------------\n",
      "allow_also\n",
      "\t 3 also allows\n",
      "--------------------------------------------\n",
      "allow_do_not\n",
      "\t 2 does not allow\n",
      "--------------------------------------------\n",
      "be_not_simply\n",
      "\t 2 are not simply\n",
      "--------------------------------------------\n",
      "be_well\n",
      "\t 1 are well\n",
      "\t 1 be well\n",
      "\t 1 is well\n",
      "--------------------------------------------\n",
      "course_of\n",
      "\t 3 of course\n",
      "--------------------------------------------\n",
      "be_not_use\n",
      "\t 3 not be used\n",
      "\t 1 was not used\n",
      "--------------------------------------------\n",
      "apply_be_have\n",
      "\t 2 has been applied\n",
      "--------------------------------------------\n",
      "just_not\n",
      "\t 3 not just\n",
      "--------------------------------------------\n",
      "be_rewrite\n",
      "\t 1 be rewritten\n",
      "\t 1 is that a rewriting\n",
      "\t 1 are rewritten\n",
      "--------------------------------------------\n",
      "almost_be\n",
      "\t 1 are almost\n",
      "\t 1 is almost\n",
      "--------------------------------------------\n",
      "use_usually\n",
      "\t 1 usually uses\n",
      "\t 1 usually use\n",
      "--------------------------------------------\n",
      "be_know_well\n",
      "\t 2 is well known\n",
      "--------------------------------------------\n",
      "be_translate\n",
      "\t 3 be translated\n",
      "\t 1 is translated\n",
      "--------------------------------------------\n",
      "ask_then\n",
      "\t 1 then we may ask\n",
      "\t 1 then ask\n",
      "--------------------------------------------\n",
      "do_not_seem\n",
      "\t 2 does not seem\n",
      "\t 1 do not seem\n",
      "--------------------------------------------\n",
      "be_think\n",
      "\t 1 be thought\n",
      "\t 1 think is\n",
      "\t 1 thought it was\n",
      "--------------------------------------------\n",
      "assume_have\n",
      "\t 2 assume we have\n",
      "\t 1 have assumed\n",
      "--------------------------------------------\n",
      "be_highly\n",
      "\t 1 is highly\n",
      "\t 1 be highly\n",
      "--------------------------------------------\n",
      "be_conclude\n",
      "\t 2 be concluded\n",
      "\t 1 concludes that there are\n",
      "--------------------------------------------\n",
      "build_in\n",
      "\t 2 built in\n",
      "--------------------------------------------\n",
      "object_orient\n",
      "\t 14 object oriented\n",
      "--------------------------------------------\n",
      "closely_compare\n",
      "\t 2 compares closely\n",
      "--------------------------------------------\n",
      "be_nearly\n",
      "\t 4 is nearly\n",
      "--------------------------------------------\n",
      "do_make_not\n",
      "\t 2 does not make\n",
      "--------------------------------------------\n",
      "be_distribute\n",
      "\t 1 is distributed\n",
      "\t 1 being distributed\n",
      "--------------------------------------------\n",
      "be_model\n",
      "\t 2 being modeled\n",
      "\t 1 be modeled\n",
      "\t 1 being modelled\n",
      "--------------------------------------------\n",
      "be_sort\n",
      "\t 2 are sorted\n",
      "\t 2 be sorted\n",
      "\t 1 sorting is\n",
      "\t 1 is sorted\n",
      "--------------------------------------------\n",
      "select_then\n",
      "\t 2 then selects\n",
      "\t 1 then by selecting\n",
      "--------------------------------------------\n",
      "be_leave\n",
      "\t 2 be left\n",
      "\t 1 is left\n",
      "\t 1 was left\n",
      "--------------------------------------------\n",
      "be_schedule\n",
      "\t 2 are scheduled\n",
      "\t 1 is scheduled\n",
      "\t 1 be scheduled\n",
      "--------------------------------------------\n",
      "be_parameteriz\n",
      "\t 2 is parameterized\n",
      "\t 1 be parameterized\n",
      "--------------------------------------------\n",
      "algorithm_sort\n",
      "\t 2 sort algorithm\n",
      "--------------------------------------------\n",
      "be_place\n",
      "\t 1 is placed\n",
      "\t 1 were placed\n",
      "--------------------------------------------\n",
      "be_compute_use\n",
      "\t 2 is used to compute\n",
      "--------------------------------------------\n",
      "be_map\n",
      "\t 2 be mapped\n",
      "\t 2 is mapped\n",
      "\t 2 are mapped\n",
      "--------------------------------------------\n",
      "always_be\n",
      "\t 1 always be\n",
      "\t 1 is always\n",
      "--------------------------------------------\n",
      "be_implement_use\n",
      "\t 1 was implemented using\n",
      "\t 1 were implemented using\n",
      "--------------------------------------------\n",
      "be_set_then\n",
      "\t 2 are then set\n",
      "--------------------------------------------\n",
      "require_sort\n",
      "\t 3 required to sort\n",
      "--------------------------------------------\n",
      "as_sort\n",
      "\t 2 sort as\n",
      "--------------------------------------------\n",
      "be_certainly\n",
      "\t 3 is certainly\n",
      "--------------------------------------------\n",
      "appear_first\n",
      "\t 2 first appear\n",
      "--------------------------------------------\n",
      "be_quite_still\n",
      "\t 2 is still quite\n",
      "--------------------------------------------\n",
      "be_entirely\n",
      "\t 2 is entirely\n",
      "--------------------------------------------\n",
      "do_meet_not\n",
      "\t 1 do not meet\n",
      "\t 1 did not meet\n",
      "--------------------------------------------\n",
      "focu_parallelize\n",
      "\t 3 focus on parallelizing\n",
      "--------------------------------------------\n",
      "be_retrieve\n",
      "\t 4 be retrieved\n",
      "\t 2 are retrieved\n",
      "\t 1 is retrieved\n",
      "--------------------------------------------\n",
      "focu_only\n",
      "\t 1 only focus\n",
      "\t 1 focus only\n",
      "--------------------------------------------\n",
      "be_refer\n",
      "\t 2 is referred\n",
      "--------------------------------------------\n",
      "be_obtain\n",
      "\t 3 be obtained\n",
      "\t 1 is obtained\n",
      "\t 1 was obtained\n",
      "--------------------------------------------\n",
      "be_either_parallelize\n",
      "\t 2 be parallelized either\n",
      "--------------------------------------------\n",
      "distribute_equally_fail\n",
      "\t 2 fail to equally distribute\n",
      "--------------------------------------------\n",
      "balance_try\n",
      "\t 2 tries to balance\n",
      "--------------------------------------------\n",
      "be_keep\n",
      "\t 2 be kept\n",
      "\t 1 is kept\n",
      "--------------------------------------------\n",
      "be_note\n",
      "\t 3 be noted\n",
      "\t 1 note that there are\n",
      "\t 1 is noted\n",
      "--------------------------------------------\n",
      "as_be_not\n",
      "\t 2 is not as\n",
      "--------------------------------------------\n",
      "be_vary\n",
      "\t 3 is varied\n",
      "--------------------------------------------\n",
      "be_predict\n",
      "\t 1 is predicted\n",
      "\t 1 be predicted\n",
      "--------------------------------------------\n",
      "be_enhance\n",
      "\t 1 is to enhance\n",
      "\t 1 is an enhanced\n",
      "--------------------------------------------\n",
      "be_classify_generally\n",
      "\t 2 are generally classified\n",
      "--------------------------------------------\n",
      "access_directly\n",
      "\t 2 directly access\n",
      "--------------------------------------------\n",
      "only_read_share\n",
      "\t 2 read only shared\n",
      "--------------------------------------------\n",
      "reduce_thus\n",
      "\t 2 thus reducing\n",
      "\t 1 thus reduce\n",
      "--------------------------------------------\n",
      "be_design_not\n",
      "\t 1 are not designed\n",
      "\t 1 not be designed\n",
      "\t 1 were not designed\n",
      "--------------------------------------------\n",
      "mention_previously\n",
      "\t 3 previously mentioned\n",
      "--------------------------------------------\n",
      "do_not_reveal\n",
      "\t 2 does not reveal\n",
      "\t 1 do not reveal\n",
      "--------------------------------------------\n",
      "earlier_mention\n",
      "\t 3 mentioned earlier\n",
      "--------------------------------------------\n",
      "be_identify\n",
      "\t 2 is to identify\n",
      "\t 1 be identified\n",
      "\t 1 are identified\n",
      "\t 1 is identified\n",
      "--------------------------------------------\n",
      "be_rarely\n",
      "\t 2 is rarely\n",
      "--------------------------------------------\n",
      "be_understand\n",
      "\t 2 be understood\n",
      "\t 1 understanding is\n",
      "--------------------------------------------\n",
      "be_transform\n",
      "\t 2 is transformed\n",
      "--------------------------------------------\n",
      "have_substantially\n",
      "\t 1 has substantially\n",
      "\t 1 have substantially\n",
      "--------------------------------------------\n",
      "be_integrate\n",
      "\t 1 are integrated\n",
      "\t 1 be integrated\n",
      "--------------------------------------------\n",
      "be_grow\n",
      "\t 1 is growing\n",
      "\t 1 is a growing\n",
      "--------------------------------------------\n",
      "have_identify\n",
      "\t 1 has identified\n",
      "\t 1 have identified\n",
      "--------------------------------------------\n",
      "be_discuss\n",
      "\t 2 are discussed\n",
      "\t 2 was discussed\n",
      "\t 1 discussed was\n",
      "--------------------------------------------\n",
      "have_make\n",
      "\t 2 have made\n",
      "--------------------------------------------\n",
      "be_glean\n",
      "\t 1 was gleaned\n",
      "\t 1 were gleaned\n",
      "--------------------------------------------\n",
      "call_so\n",
      "\t 2 so called\n",
      "--------------------------------------------\n",
      "be_derive\n",
      "\t 3 be derived\n",
      "\t 1 were derived\n",
      "--------------------------------------------\n",
      "even_so\n",
      "\t 2 even so\n",
      "--------------------------------------------\n",
      "be_know\n",
      "\t 2 is known\n",
      "--------------------------------------------\n",
      "be_study\n",
      "\t 1 is to study\n",
      "\t 1 are studying\n",
      "--------------------------------------------\n",
      "again_once\n",
      "\t 3 once again\n",
      "--------------------------------------------\n",
      "be_only_use\n",
      "\t 1 only be used\n",
      "\t 1 be used with only\n",
      "--------------------------------------------\n",
      "assign_be_only\n",
      "\t 1 only be assigned\n",
      "\t 1 is assigned to only\n",
      "--------------------------------------------\n",
      "be_examine\n",
      "\t 1 was to examine\n",
      "\t 1 be examined\n",
      "\t 1 is to examine\n",
      "--------------------------------------------\n",
      "incorporate_more\n",
      "\t 2 incorporate more\n",
      "--------------------------------------------\n",
      "examine_have\n",
      "\t 2 have examined\n",
      "\t 1 has examined\n",
      "\t 1 had examined\n",
      "--------------------------------------------\n",
      "share_support\n",
      "\t 2 supported shared\n",
      "\t 1 supporting shared\n",
      "--------------------------------------------\n",
      "be_carry_out\n",
      "\t 2 were carried out\n",
      "\t 1 be carried out\n",
      "\t 1 is carried out\n",
      "--------------------------------------------\n",
      "be_collect\n",
      "\t 2 were collected\n",
      "--------------------------------------------\n",
      "be_reflect\n",
      "\t 1 was reflected\n",
      "\t 1 is reflected\n",
      "--------------------------------------------\n",
      "have_very\n",
      "\t 2 have very\n",
      "\t 1 have a very\n",
      "\t 1 had very\n",
      "--------------------------------------------\n",
      "above_mention\n",
      "\t 2 mentioned above\n",
      "--------------------------------------------\n",
      "be_decide\n",
      "\t 1 was decided\n",
      "\t 1 is to decide\n",
      "\t 1 is decided\n",
      "--------------------------------------------\n",
      "do_show\n",
      "\t 2 did show\n",
      "--------------------------------------------\n",
      "demonstrate_have\n",
      "\t 1 has demonstrated\n",
      "\t 1 have demonstrated\n",
      "--------------------------------------------\n",
      "appreciate_be\n",
      "\t 1 is appreciated\n",
      "\t 1 be appreciated\n",
      "--------------------------------------------\n",
      "be_record\n",
      "\t 3 were recorded\n",
      "\t 1 was recorded\n",
      "--------------------------------------------\n",
      "ask_be\n",
      "\t 2 were asked\n",
      "\t 2 was asked\n",
      "--------------------------------------------\n",
      "analyse_be\n",
      "\t 1 were analysed\n",
      "\t 1 was analysed\n",
      "--------------------------------------------\n",
      "affect_be\n",
      "\t 1 were affected\n",
      "\t 1 be affected\n",
      "--------------------------------------------\n",
      "achieve_hope\n",
      "\t 2 hope to achieve\n",
      "--------------------------------------------\n",
      "be_usually\n",
      "\t 3 is usually\n",
      "--------------------------------------------\n",
      "importantly_more\n",
      "\t 2 more importantly\n",
      "--------------------------------------------\n",
      "be_extract_use\n",
      "\t 1 was used in extracting\n",
      "\t 1 is to use the extracted\n",
      "--------------------------------------------\n",
      "do_exclude_not\n",
      "\t 2 does not exclude\n",
      "--------------------------------------------\n",
      "be_extract\n",
      "\t 1 be extracted\n",
      "\t 1 are extracted\n",
      "--------------------------------------------\n",
      "be_describe_use\n",
      "\t 1 be used to describe\n",
      "\t 1 be described using\n",
      "--------------------------------------------\n",
      "be_merge\n",
      "\t 4 are merged\n",
      "--------------------------------------------\n",
      "also_be_illustrate\n",
      "\t 2 is also illustrated\n",
      "--------------------------------------------\n",
      "be_correlate\n",
      "\t 1 is correlated\n",
      "\t 1 are no correlated\n",
      "--------------------------------------------\n",
      "choose_have\n",
      "\t 2 have chosen\n",
      "--------------------------------------------\n",
      "be_formulate\n",
      "\t 1 be formulated\n",
      "\t 1 is formulated\n",
      "--------------------------------------------\n",
      "be_remove_use\n",
      "\t 1 are used to remove\n",
      "\t 1 be removed using\n",
      "\t 1 are removed using\n",
      "--------------------------------------------\n",
      "achieve_be_use\n",
      "\t 1 are achieved by using\n",
      "\t 1 be achieved using\n",
      "--------------------------------------------\n",
      "be_search\n",
      "\t 1 be searched\n",
      "\t 1 is to search\n",
      "--------------------------------------------\n",
      "be_have_incorporate\n",
      "\t 1 has been incorporated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t 1 have been incorporated\n",
      "--------------------------------------------\n",
      "apply_be_then\n",
      "\t 1 then be applied\n",
      "\t 1 then it is applied\n",
      "--------------------------------------------\n",
      "as_much\n",
      "\t 4 as much\n",
      "--------------------------------------------\n",
      "infrequently_update\n",
      "\t 2 updated infrequently\n",
      "--------------------------------------------\n",
      "automatically_be_generate\n",
      "\t 2 be generated automatically\n",
      "--------------------------------------------\n",
      "apply_consistently\n",
      "\t 2 applied consistently\n",
      "--------------------------------------------\n",
      "acquire_know\n",
      "\t 2 know or acquire\n",
      "--------------------------------------------\n",
      "apply_have\n",
      "\t 1 have to apply\n",
      "\t 1 have applied\n",
      "--------------------------------------------\n",
      "be_determine_use\n",
      "\t 1 is determined using\n",
      "\t 1 was determined using\n",
      "--------------------------------------------\n",
      "be_learn\n",
      "\t 1 be learned\n",
      "\t 1 learn is\n",
      "--------------------------------------------\n",
      "be_so\n",
      "\t 1 are so\n",
      "\t 1 so there is\n",
      "--------------------------------------------\n",
      "be_contain\n",
      "\t 3 is contained\n",
      "\t 1 is a contains\n",
      "\t 1 were contained\n",
      "--------------------------------------------\n",
      "add_be_only\n",
      "\t 2 are only added\n",
      "--------------------------------------------\n",
      "be_index\n",
      "\t 1 being indexed\n",
      "\t 1 be re indexed\n",
      "--------------------------------------------\n",
      "do_just_know_not\n",
      "\t 2 just do not know\n",
      "--------------------------------------------\n",
      "be_ignore\n",
      "\t 1 be ignored\n",
      "\t 1 is ignored\n",
      "--------------------------------------------\n",
      "augment_be\n",
      "\t 1 is augmented\n",
      "\t 1 be augmented\n",
      "--------------------------------------------\n",
      "be_compound\n",
      "\t 1 is compounded\n",
      "\t 1 are compounded\n",
      "--------------------------------------------\n",
      "already_exist\n",
      "\t 1 already exist\n",
      "\t 1 exist already\n",
      "--------------------------------------------\n",
      "be_have_make\n",
      "\t 2 have been made\n",
      "--------------------------------------------\n",
      "be_have_say\n",
      "\t 1 has been said\n",
      "\t 1 are said to have\n",
      "--------------------------------------------\n",
      "be_summarise\n",
      "\t 1 be summarised\n",
      "\t 1 are summarised\n",
      "--------------------------------------------\n",
      "focus_tend\n",
      "\t 2 tend to focus\n",
      "--------------------------------------------\n",
      "be_term\n",
      "\t 1 were termed\n",
      "\t 1 was termed\n",
      "\t 1 are termed\n",
      "--------------------------------------------\n",
      "be_work\n",
      "\t 2 is working\n",
      "\t 1 are working\n",
      "--------------------------------------------\n",
      "be_permit\n",
      "\t 2 is permitted\n",
      "--------------------------------------------\n",
      "become_then\n",
      "\t 1 then becomes\n",
      "\t 1 then become\n",
      "--------------------------------------------\n",
      "be_draw\n",
      "\t 1 are drawn\n",
      "\t 1 drawn are\n",
      "\t 1 be drawn\n",
      "--------------------------------------------\n",
      "be_miss\n",
      "\t 1 is missing\n",
      "\t 1 is either missing\n",
      "\t 1 are missing\n",
      "--------------------------------------------\n",
      "know_well\n",
      "\t 2 well known\n",
      "--------------------------------------------\n",
      "do_not_overlap\n",
      "\t 2 do not overlap\n",
      "--------------------------------------------\n",
      "be_break\n",
      "\t 1 are broken\n",
      "\t 1 is broken\n",
      "--------------------------------------------\n",
      "now_prove\n",
      "\t 2 now prove\n",
      "--------------------------------------------\n",
      "be_not_take\n",
      "\t 1 are not taken\n",
      "\t 1 be taken not\n",
      "--------------------------------------------\n",
      "be_exist\n",
      "\t 1 exists that is\n",
      "\t 1 is existing\n",
      "--------------------------------------------\n",
      "be_cover_not\n",
      "\t 2 not be covered\n",
      "\t 1 were not covered\n",
      "--------------------------------------------\n",
      "more_use\n",
      "\t 1 used more\n",
      "\t 1 use more\n",
      "--------------------------------------------\n",
      "cost_have\n",
      "\t 1 have cost\n",
      "\t 1 has cost\n",
      "--------------------------------------------\n",
      "now_present\n",
      "\t 2 now present\n",
      "--------------------------------------------\n",
      "be_constrain\n",
      "\t 1 is constrained\n",
      "\t 1 are constrained\n",
      "--------------------------------------------\n",
      "experience_interview\n",
      "\t 3 interviewing experienced\n",
      "--------------------------------------------\n",
      "be_explore\n",
      "\t 2 are exploring\n",
      "\t 1 be explored\n",
      "--------------------------------------------\n",
      "be_justify\n",
      "\t 2 is justified\n",
      "--------------------------------------------\n",
      "be_consider_have_not_previously\n",
      "\t 2 have not been previously considered\n",
      "--------------------------------------------\n",
      "argue_be\n",
      "\t 3 is argued\n",
      "--------------------------------------------\n",
      "control_more\n",
      "\t 2 more controlled\n",
      "--------------------------------------------\n",
      "be_direct\n",
      "\t 1 be directed\n",
      "\t 1 is directed\n",
      "\t 1 was directed\n",
      "\t 1 is a directed\n",
      "--------------------------------------------\n",
      "be_interview\n",
      "\t 1 interviewing is\n",
      "\t 1 are interviewed\n",
      "\t 1 were interviewed\n",
      "--------------------------------------------\n",
      "also_remove\n",
      "\t 1 also remove\n",
      "\t 1 also removes\n",
      "--------------------------------------------\n",
      "as_long\n",
      "\t 3 as long\n",
      "--------------------------------------------\n",
      "be_realise\n",
      "\t 1 is to realise\n",
      "\t 1 is realised\n",
      "--------------------------------------------\n",
      "mention_not\n",
      "\t 1 not mention\n",
      "\t 1 not mentioned\n",
      "--------------------------------------------\n",
      "assume_only\n",
      "\t 1 assume that only\n",
      "\t 1 only assume\n",
      "--------------------------------------------\n",
      "answer_attempt\n",
      "\t 1 attempting to answer\n",
      "\t 1 attempts to answer\n",
      "--------------------------------------------\n",
      "address_be\n",
      "\t 2 be addressed\n",
      "\t 1 is addressing\n",
      "--------------------------------------------\n",
      "have_have\n",
      "\t 1 had had\n",
      "\t 1 have had\n",
      "--------------------------------------------\n",
      "be_really\n",
      "\t 1 's really\n",
      "\t 1 be really\n",
      "--------------------------------------------\n",
      "be_design_properly\n",
      "\t 2 be properly designed\n",
      "\t 1 is designed properly\n",
      "--------------------------------------------\n",
      "be_inherit\n",
      "\t 1 been inherited\n",
      "\t 1 are inherited\n",
      "--------------------------------------------\n",
      "also_note\n",
      "\t 2 also noted\n",
      "--------------------------------------------\n",
      "design_well\n",
      "\t 3 well designed\n",
      "\t 1 designed well\n",
      "--------------------------------------------\n",
      "be_seem\n",
      "\t 2 seems to be\n",
      "--------------------------------------------\n",
      "orient_program\n",
      "\t 2 oriented programming\n",
      "--------------------------------------------\n",
      "be_classify\n",
      "\t 1 is classified\n",
      "\t 1 are classified\n",
      "--------------------------------------------\n",
      "address_have\n",
      "\t 2 have addressed\n",
      "--------------------------------------------\n",
      "be_classify_only_use\n",
      "\t 1 is classified using only\n",
      "\t 1 were classified using only\n",
      "--------------------------------------------\n",
      "be_classify_correctly\n",
      "\t 5 be classified correctly\n",
      "--------------------------------------------\n",
      "be_misclassifi\n",
      "\t 2 be misclassified\n",
      "--------------------------------------------\n",
      "agree_do_not\n",
      "\t 2 do not agree\n",
      "--------------------------------------------\n",
      "be_locate\n",
      "\t 3 is located\n",
      "--------------------------------------------\n",
      "avoid_repeat\n",
      "\t 2 avoid repeating\n",
      "--------------------------------------------\n",
      "be_check\n",
      "\t 1 is checked\n",
      "\t 1 are checked\n",
      "--------------------------------------------\n",
      "cause_sometimes\n",
      "\t 1 sometimes causes\n",
      "\t 1 sometimes cause\n",
      "--------------------------------------------\n",
      "be_classify_incorrectly\n",
      "\t 2 be classified incorrectly\n",
      "--------------------------------------------\n",
      "be_first_remove\n",
      "\t 2 are removed first\n",
      "--------------------------------------------\n",
      "be_do_use\n",
      "\t 1 is done using\n",
      "\t 1 be done either by using\n",
      "--------------------------------------------\n",
      "be_describe_modify\n",
      "\t 1 described above were modified\n",
      "\t 1 were modified to describe\n",
      "--------------------------------------------\n",
      "be_have_identify\n",
      "\t 2 have been identified\n",
      "--------------------------------------------\n",
      "be_speak\n",
      "\t 1 is spoken\n",
      "\t 1 speaks against is\n",
      "--------------------------------------------\n",
      "be_prepare\n",
      "\t 1 is prepared\n",
      "\t 1 be prepared\n",
      "\t 1 are prepared\n",
      "--------------------------------------------\n",
      "be_deal\n",
      "\t 1 be dealing\n",
      "\t 1 be dealt\n",
      "--------------------------------------------\n",
      "be_not_retrieve\n",
      "\t 1 not be retrieved\n",
      "\t 1 is not retrieved\n",
      "--------------------------------------------\n",
      "often_see\n",
      "\t 2 often seen\n",
      "--------------------------------------------\n",
      "be_face\n",
      "\t 1 are facing\n",
      "\t 1 be faced\n",
      "--------------------------------------------\n",
      "be_instantiate\n",
      "\t 2 be instantiated\n",
      "--------------------------------------------\n",
      "be_have_use\n",
      "\t 2 have been used\n",
      "--------------------------------------------\n",
      "effectively_learn\n",
      "\t 2 learn effectively\n",
      "--------------------------------------------\n",
      "not_only_possess\n",
      "\t 2 not only possess\n",
      "--------------------------------------------\n",
      "introspectively_reason\n",
      "\t 2 introspectively reason\n",
      "--------------------------------------------\n",
      "be_verify\n",
      "\t 2 are verified\n",
      "\t 2 be verified\n",
      "\t 2 is verified\n",
      "--------------------------------------------\n",
      "be_post\n",
      "\t 1 are posted\n",
      "\t 1 is posted\n",
      "--------------------------------------------\n",
      "be_resume\n",
      "\t 2 is resumed\n",
      "--------------------------------------------\n",
      "be_generalize\n",
      "\t 2 is generalized\n",
      "--------------------------------------------\n",
      "be_detect\n",
      "\t 1 are detected\n",
      "\t 1 is detected\n",
      "--------------------------------------------\n",
      "be_pose\n",
      "\t 2 is posed\n",
      "\t 1 are posed\n",
      "--------------------------------------------\n",
      "initiate_mentally\n",
      "\t 4 initiates mentally\n",
      "\t 2 mentally initiates\n",
      "--------------------------------------------\n",
      "hypothesize_in\n",
      "\t 3 hypothesized in\n",
      "--------------------------------------------\n",
      "apply_learn\n",
      "\t 2 apply learning\n",
      "--------------------------------------------\n",
      "have_then\n",
      "\t 2 then has\n",
      "--------------------------------------------\n",
      "abstract_be\n",
      "\t 2 is abstracted\n",
      "--------------------------------------------\n",
      "be_occur\n",
      "\t 1 occurs either when it is\n",
      "\t 1 occur is\n",
      "--------------------------------------------\n",
      "be_regenerate_simply\n",
      "\t 1 is simply regenerated\n",
      "\t 1 was simply regenerated\n"
     ]
    }
   ],
   "source": [
    "printgroup(predicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute equality -> were passing on -> greater judgment\n",
      "absurdity way -> has been -> such person\n",
      "excuse into an acceptance -> so changed -> few words\n",
      "least account of “ the one -> not to make -> delicate face\n",
      "mercy on account -> was recommended -> goodness character\n",
      "accurate knowledge -> had obtained -> magwitch ’s affairs\n",
      "badness heart ache -> got out -> worse heart ache\n",
      "additional relish -> was eating -> independence circumstances\n",
      "advance another two hundred yards -> had not -> inexpressible terror\n",
      "adversary ’s head -> have flung -> entertainer ’s\n",
      "submit to a word of advice -> has been -> constancy terror\n",
      "world affairs -> began to wear -> gloom appearance\n",
      "afternoon ’s bustle -> opening more -> red eyes\n",
      "summer afternoon -> toned down -> summer evening\n",
      "sunday afternoon -> washed up -> tea things\n",
      "tacit understanding that the aged -> n’t be -> presentable state\n",
      "air of authority -> not to be disputed -> manner express\n",
      "littleness alick in a frock -> having already made -> arrangements for his union\n",
      "greatness amazement -> was stopped -> joe ’s\n",
      "ancient trees before the house -> were still cut -> fashions as formality\n",
      "anything more about my father -> now said -> father ’s son\n",
      "way to those detached apartments -> still were -> paved yard\n",
      "appalling things -> did most -> nut crackers\n",
      "prematureness approaches -> have been thrown out -> general conversation condescension\n",
      "coarseness apron -> began cleaning up -> terribleness extent\n",
      "sinew oldness arms -> had made up -> richness attract mystery\n",
      "extend arrangements -> occasioned us to be cut off unceremoniously -> respect of breakfast\n",
      "arrest of everything -> standing still -> paleness decayed objects\n",
      "awake a littleness while -> had lain -> extraordinariness voices with which silence\n",
      "awareness of myself down in essex -> first become -> thieving turnips\n",
      "awareness of the mutuality relations -> thus became -> mr. pocket\n",
      "indescribable awe -> came out -> open woodenness gates\n",
      "awfulness dull -> hope i ’ve beat out -> something nigh the rights\n",
      "baby intelligence -> was received -> first distortions\n",
      "baby ood -> had put -> hith eyeth\n",
      "man of badness character -> have heard -> trueness name\n",
      "badness side -> ’s a -- it ’s -> human nature\n",
      "furrowed baldness head -> sat looking up -> iron greyness hair\n",
      "publicity balls -> anywhere else -> certain man\n",
      "bandage off most -> now comes -> coolness one\n",
      "mill pond bank -> be called -> chinks ’s basin\n",
      "top bar -> hooked on -> miss skiffins\n",
      "bareness boards -> had been knocked down -> tremendous blow\n",
      "bareness hedges -> saw the damp lying -> spareness grass\n",
      "oldness bill barley -> drifting by -> swiftness stream\n",
      "old barley -> were as -> oldness as the hills\n",
      "whole square basement -> seemed to pervade -> manor house\n",
      "chinks ’s basin -> only looked -> mill pond bank\n",
      "pipe at the battery -> far more -> sagaciousness air\n",
      "beautiful young lady -> has been -> miss havisham ’s\n",
      "freshness of her beauty -> was indeed gone -> indescribable majesty\n",
      "uneasiness bed -> never slept -> oldness sound sleep\n",
      "pot of beer -> had appeared -> jolly bargemen\n",
      "behalf of herbert -> had succeeded -> miss havisham\n",
      "gratitude to my benefactor -> was beginning to express -> greatness liberality\n",
      "reality benefactor -> had discovered -> miss havisham\n",
      "bentley drummle -> had come -> mr. pocket\n",
      "dear biddy -> had forgotten -> nothing of his life\n",
      "bigness for mr. wopsle greatness -> was getting too -> aunt ’s room\n",
      "cobbs ’s bill -> had not got -> lobbs ’s\n",
      "oldness billingsgate market with its oyster -> was soon passed -> boats and dutchmen\n",
      "birthday guineas -> set aside -> greater part\n",
      "bitterness sleet -> came rattling against us here -> east wind\n",
      "greatness blackness velvet pall -> as soon -> littleness window\n",
      "blackness pipe -> was going to fill -> negro head\n",
      "violence blasts of rain -> had accompanied -> rages of wind\n",
      "sameness blood -> n’t be -> sameness nature\n",
      "blueness coat -> had clothed -> canary waistcoat\n",
      "something bluntness and heaviness -> had been struck -> head and spine\n",
      "boat cloak -> had said -> naturalness part\n",
      "tallness and bony -> almost always wore -> coarseness apron\n",
      "story book -> had taken -> oldness lady\n",
      "money box -> am a keeping -> kitchen mantel shelf\n",
      "dear boy -> sit here alonger -> dear boy\n",
      "trabb ’s boy -> pulling up -> shirt collar\n",
      "uses and scents of the brewery -> have evaporated -> last reek\n",
      "fineness brightness day -> had become -> fog as the sun\n",
      "brooding state -> had taken -> especial notice\n",
      "half brother -> had now -> ampleness means\n",
      "brownness sail -> have followed -> ballast lighters\n",
      "shabbiness buildings -> ever squeezed together -> rank corner\n",
      "business office -> are located -> north 1500 west\n",
      "freshness butter -> make up -> cupboard ready\n",
      "fat office candles -> dimly lighted -> mr. jaggers\n",
      "privateness and personality capacity -> have been engaged -> confidence transaction\n",
      "greatest care -> are coming -> longness strides\n",
      "more of my intended career -> having been told -> mr. jaggers\n",
      "part to carols -> ’m rather -> best of reasons\n",
      "desperate case -> was comparatively -> earliness days\n",
      "white ceiling -> looked most affectionately -> dear magwitch\n",
      "celebrated forgery -> had been committed -> distinguished razor\n",
      "centre of the longness table -> had stopped -> miss havisham\n",
      "disclaimers of certain implied warranties -> do not allow -> exclusion or limitation\n",
      "miss havisham in her chair -> then he pushed -> large hand\n",
      "chance intercourse -> long ago -> differ circumstances\n",
      "oldness chap -> got up -> littleness room\n",
      "oldness chap -> now i was -> music in my ears\n",
      "chapter xii my mind -> grew very -> uneasiness on the subject\n",
      "chapter xiv -> was most -> miserableness thing\n",
      "chapter xxxiv -> have that growed -> accustomed to my expectations\n",
      "characteristic of the police people -> less suspected -> poorness joe\n",
      "charming girl -> had passed -> captive fairy\n",
      "cheerfulness face -> sadly missed -> ready response\n",
      "dinner the children -> were introduced -> mrs. coiler\n",
      "littleness child -> were dropped -> heavier for that grab of whisker\n",
      "otherness children -> were left behind -> dinner table\n",
      "roundness childishness eyes wider -> did not gradually open -> wider to the discovery\n",
      "choler gentleman -> had taken -> fourth place\n",
      "christmas eve -> had to stir -> pudding for next day\n",
      "clerk at church -> was to dine -> mr. hubble\n",
      "church last sunday -> accidentally held -> prayer book\n",
      "hopelessness circumstances -> had been surrounded -> miserableness littleness shop\n",
      "worthier circumstances -> presently presented -> genius of youthfulness love\n",
      "similarity claim -> had urged -> mr. drummle\n",
      "clara ’s esteem -> had risen -> young lady\n",
      "clarriker ’s house -> had talked -> whole evening\n",
      "clarriker ’s -> had shown -> extraordinariness inclination\n",
      "classes at mr. wopsle ’s -> reading reminded -> greatness aunt ’s\n",
      "ostentation clemency -> had just now exhibited -> sameness fat\n",
      "many otherness clerks -> claimed to have -> sameness detriment mastery\n",
      "upstairs clerks -> come down -> outer office\n",
      "client or a witness -> ceremoniously unfolding -> pocket handkerchief\n",
      "closed iron furnace -> has been -> dark corner\n",
      "gravity clothes -> have looked so -> longness veil\n",
      "greater part of my clothes -> slept well -> few hours\n",
      "coach office -> began haunting -> wood street\n",
      "hackney coachman -> seemed to have -> many capes\n",
      "coarseness and common -> not have had -> miss havisham\n",
      "coat collar -> were perplexing to reflect -> insolubility mysteries\n",
      "pea coat -> brought out -> shortness blackness pipe\n",
      "coffee house -> being entirely furnished forth -> circumjacent region\n",
      "speciousness coin -> knowingly reckon -> own make\n",
      "collins ’s ode -> particularly venerated -> mr. wopsle\n",
      "comic song -> had once bought -> half penny\n",
      "verb communication with a man in new -> had not -> south wales\n",
      "newness companions -> had taken up -> newness masters\n",
      "fitness company -> be quite -> unfitness company\n",
      "time wi’ compeyson -> was a’most -> hardness time\n",
      "compeyson ’s wife -> took it up -> bed agen\n",
      "wi’ compeyson -> so i begun -> poorness tool\n",
      "horseshoe complete -> was like striking out -> singleness blow\n",
      "pip ’s comrade -> always having -> gen teel muzzle\n",
      "guileless confectioner -> n’t be -> means soberness\n",
      "oldness confidence -> sit and talk -> oldness simplicity\n",
      "confidence in my own resources -> willingly have taken -> herbert ’s expenses\n",
      "things considered,--“well -> quite vivaciously -> mrs. joe\n",
      "greatest contempt -> comes betwixt -> own light\n",
      "desire of more conversation -> go up -> miss havisham\n",
      "conversation in the room -> divined that my coming had stopped -> otherness occupants\n",
      "strong conviction -> never like -> joe ’s trade\n",
      "cordiality goodness night -> going home -> newness matter\n",
      "extremity corner -> ultimately stood -> chimney piece\n",
      "corner my indentures -> be bound -> mr. pumblechook\n",
      "wretchedness creatures -> singling out -> specialness address\n",
      "custom house -> be brought up afterwards -> temple stairs\n",
      "sofa with my staylace cut -> have lain there -> hours insensibility\n",
      "dark night -> set out -> mr. wopsle\n",
      "days when my knuckles -> had taken -> such liberties\n",
      "marriage day -> was fixed -> wedding dresses\n",
      "days more of recovery -> go down -> oldness place\n",
      "otherness day -> let out -> mr. jaggers\n",
      "deadness silence -> sit impatiently thinking -> unusualness amount\n",
      "dearest estella -> do not let -> miss havisham\n",
      "dear fellow -> had fallen -> oldness tone\n",
      "dear fellow -> n’t be -> worse friends\n",
      "dear friend -> had recovered -> wind for speech\n",
      "dear handel -> never looked -> red book\n",
      "dear herbert -> not tell -> dependent and uncertainness\n",
      "dear joe!--no -> do n’t wipe it off -> god ’s sake\n",
      "dear oldness joe -> looking so unlike himself or so -> extraordinariness bird\n",
      "dear littleness thing -> coming back -> dear littleness thing\n",
      "dear mr. pip -> ever obliged -> affection servant\n",
      "death of her husband -> have heard -> accident consequence\n",
      "detestable in a pig -> was more -> detestable in a boy\n",
      "horrible din -> had lasted -> certain time\n",
      "direction the mist -> had shrouded -> otherness man\n",
      "such strangeness directions -> was afflicted -> such remarkable coughs\n",
      "dirt flannel -> was dressed -> oldness blackness clothes\n",
      "hopeful disposition -> gratefully admiring -> cheer ways\n",
      "dispute reader -> hardly have directed -> unfortunate boy\n",
      "donations in locations -> have not received written -> confirmation of compliance\n",
      "front door -> had believed -> mystery portal\n",
      "door in the kitchen -> looked it out -> greatest caution\n",
      "poorness dreams;’ -> know no more -> such things\n",
      "electronics works -> was derived -> publicity domain\n",
      "electronics works -> were posting -> permission of the copyright holder\n",
      "place of encounter -> has been -> singularity littleness creature\n",
      "side entrance -> necessarily be -> night time\n",
      "mere escape -> happened sometimes -> fatigued mind\n",
      "lady with whom estella -> be placed -> mrs. brandley by name\n",
      "oldness estella -> are not going to say -> miss havisham\n",
      "evening mists -> were rising now -> broadness expanse\n",
      "unlikeliness to me that evening -> had discussed -> few hours\n",
      "everybody for miles -> round had heard -> miss havisham down town\n",
      "usualness exercise -> had landed -> dressing table\n",
      "greatness expectations -> had come -> mystery patron\n",
      "greatness expectations -> have dissolved -> own marsh mist\n",
      "expend habits -> began to spend -> amount of money\n",
      "eyes on the ground -> looked up -> half resentful\n",
      "such eyes and such hands -> had seen exactly -> memorable occasion\n",
      "eyes -- a littleness -> dimmed by looking up -> frigidity light\n",
      "meeting my eye -> said plainly -> moment and silence pause\n",
      "smallness face -> had been made -> walnut shells\n",
      "softness face -> be carried out -> highest state\n",
      "watchfulness face -> countenance wrung -> cruelness smile\n",
      "faintness singleness rap -> finally he gave -> pepper -- such\n",
      "family greatness -> sometimes did -> goodness service\n",
      "family of your relations -> had been thrown -> miss havisham\n",
      "family tombstones -> had just -> enough learning\n",
      "particularity fancy -> had not -> old artful\n",
      "sheep farmer -> ’ve been -> stock breeder\n",
      "fatality step -> leading me into what you call -> miss havisham\n",
      "last his father -> not nearly so well -> miss havisham\n",
      "patronage and these favors -> did so -> faintness hope\n",
      "newness fear -> had been engendered -> mind by his narrative\n",
      "goodness feeling -> was being promoted -> usualness manners\n",
      "softer feeling -> were seized -> violence indignation\n",
      "freemasonry as fellow sufferers -> already mentioned -> goodness natured companionship\n",
      "promising fellow -- in his way -> had not -> own way\n",
      "few hours -> mention at once -> mrs. pocket\n",
      "few minutes -> being nursed -> littleness jane\n",
      "few minutes -> had ascended -> clarity field\n",
      "few moments -> surely perishing -> human knowledge\n",
      "gay fiction -> were constantly enjoying -> skeleton truth\n",
      "fierceness young -> hound indeed -> time of life\n",
      "heart than a iron file -> were as -> cold as death\n",
      "marks of finger nails -> said it was not -> marks of brambles\n",
      "kitchen fire -> started up -> terribleness idea\n",
      "guinea on the first occasion -> tried to decline taking -> better effect\n",
      "fleet street -> got there -> lateness hackney chariot\n",
      "fluey men -> sitting there -> bills about shipping\n",
      "littleness food -> was left -> breast of his greyness jacket\n",
      "fool ’s head -> n’t express -> better opinions\n",
      "foot and a half longness -> were arranged -> neat row\n",
      "tidings of my highness fortunes -> had had -> heaviness fall\n",
      "fountain head -> no longer -> mere agent\n",
      "fowls and rabbits -> knock together -> own littleness frame\n",
      "last fragments -> soaking up -> gravy round\n",
      "mere freak -> let him suppose -> secret one\n",
      "free of the wine -> even called -> otherness bottle\n",
      "friend ones -> wot come -> willingness harts\n",
      "otherness fugitive -> was evidently -> extremity horror of his companion\n",
      "fullness project gutenberg tm -> do not unlink or detach or remove -> license terms\n",
      "security and permanent future for project -> was created to provide -> gutenberg tm\n",
      "highness gallery -> went out -> sameness first day\n",
      "oared galley -> hovering about in so -> unusualness a way\n",
      "garden and a greenhouse with nothing -> fallen down -> grape vine\n",
      "silence turn in the garden -> falling back -> main position\n",
      "joseph gargery -> warn you this is -> last chance\n",
      "haven through a wicket gate -> were disgorged -> introduce passage\n",
      "muchness to the purpose whether a gate -> n’t be -> garden wall\n",
      "knuckles against the paleness young gentleman -> had cut -> ’s teeth\n",
      "oldness gentleman -> experienced so -> muchness difficulty\n",
      "paleness young gentleman -> hardly fail to discern -> appropriateness passenger\n",
      "paleness young gentleman -> was very soon -> coal dust\n",
      "paleness young gentleman -> stood contemplating -> barnard ’s inn\n",
      "paleness young gentleman -> reaching out -> hand goodness\n",
      "young gentleman -> came unexpectedly -> large property\n",
      "gerrard street -> had not then come -> suddenness glare\n",
      "own warning ghost -> had done -> sister ’s case\n",
      "gilt looking glass -> make out -> first sight\n",
      "gloom street -> stop we presently did -> certain offices\n",
      "better men -> has been -> better circumstances\n",
      "better world -> surely make -> better men\n",
      "goodness handel -> n’t be -> obviousness that with newgate\n",
      "goodness newspaper -> down afore -> goodness fires\n",
      "goodness night -> had exchanged -> farm laborer\n",
      "goodness one -> pick us out -> oldness briton\n",
      "greatest publicity importance -> had just transpired -> spider community\n",
      "greatest reassurance -> was that he was coming -> barnard ’s inn\n",
      "honestness littleness grocer -> was only brought about -> white hat\n",
      "otherness guardian -> had had -> minority abilities\n",
      "guilt knowledge -> was going to rob -> mrs. joe\n",
      "part of this project gutenberg tm -> reading or using -> electronics works\n",
      "gutenberg tm -> wide spread -> publicity support\n",
      "hair the wrongness way -> then he would rumple -> earliest remembrance\n",
      "head in her hands -> sat making -> lowness moaning\n",
      "handsomeness mince pie -> had been made -> yesterday morning\n",
      "handsomeness young woman -> had believed -> gypsy blood\n",
      "happiness man -> have so -> many littleness drawers\n",
      "miss havisham -> suddenly saying -> impatience movement\n",
      "miss havisham -> wish to speak -> miss havisham\n",
      "miss havisham -> soon be expecting -> oldness post\n",
      "miss havisham -> passionately striking -> stick upon the floor\n",
      "miss havisham -> pushing away -> greyness hair\n",
      "miss havisham -> n’t be -> own room\n",
      "miss havisham -> had not -> least objection\n",
      "miss havisham -> deferred asking -> next day\n",
      "note of miss havisham ’s -> did you send -> mr. pip\n",
      "miss havisham ’s -> set off -> mile walk\n",
      "havisham ’s -> ’s no more -> beautiful than anybody\n",
      "heaven ’s name -> out together -> dear oldness boy\n",
      "something heaviness -> had been thrown down -> considerable violence\n",
      "herbert ’s room -> had shut off -> otherness communication\n",
      "sameness for herbert -> had not -> administer genius\n",
      "herbert and startop -> was getting -> london by land\n",
      "herbert ’s way -> was clearing fast -> oldness bill barley\n",
      "herbert ’s -> was very -> differ case\n",
      "high street -> looked disconsolately -> shop window\n",
      "top of holborn hill -> was merely -> mechanics appearance\n",
      "homage to this light -> went on to say -> friend manner:--\n",
      "please home -> having seen -> oldness father\n",
      "public house in the village -> of course there was -> course joe\n",
      "several publicity houses -> had come back -> mr. wopsle\n",
      "sluice house -> went out -> town way\n",
      "sluice house -> had had -> longness time\n",
      "smallest house -> ever see -> queerest gothic windows\n",
      "particularity notice of the housekeeper -> induced to take -> own strikingness appearance\n",
      "i. the truth -> had objected -> expend companion\n",
      "interest of the imminence pursuit -> not only absorbed -> general attention\n",
      "proud impatience -> had rather endured -> fierceness affection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sameness inflame process -> always have put -> similarity circumstances\n",
      "part of our intercourse -> then thought -> longness time\n",
      "interestingness relics -> had taken -> few days\n",
      "light iron stairs -> went out -> gallery highness overhead\n",
      "mr. jaggers -> coming up -> due time\n",
      "mr. jaggers -> sent up -> miss havisham\n",
      "mr. jaggers -> showed that she had struggled -> greatness lot\n",
      "mr. jaggers -> was altogether too -> many for the jury\n",
      "mr. jaggers -> perhaps i know more -> estella ’s history\n",
      "sureness of this unconsciousness on mr. jaggers -> n’t be -> ’s part\n",
      "mrs. joe -> has been -> dozen times\n",
      "mrs. joe -> was very -> cleanness housekeeper\n",
      "mrs. joe -> was soon landed -> uncle pumblechook\n",
      "joe and orlick -> sweeping up -> otherness traces of discomposure\n",
      "tenderness of joe -> was so beautifully -> proportioned to my need\n",
      "thanklessness to joe -> had never been struck at so keenly -> brass impostor pumblechook\n",
      "thing in joe -> soon arrived -> sorrowful comprehension\n",
      "tiresomeness journey -> had had -> mr. wopsle\n",
      "lock and key -> has been -> dear boy\n",
      "whitewashed knock knee letters -> was marked -> brew house\n",
      "stalwartness perpendicular ladder -> made out that i was fastened -> few inches\n",
      "last wretchedness littleness rag -> hoarded up -> robe of hope\n",
      "last lowness point -> had headed -> last green barge\n",
      "temple last night-- -> really have been -> last night\n",
      "remembrance of our last parting -> ever had was -> mournfulness and painfulness\n",
      "u.s. laws -> alone swamp -> smallness staff\n",
      "whole length -> now gave -> dismal chamber\n",
      "surprised in my life -> let out -> first blow\n",
      "staircase lights -> took it up -> reading lamp\n",
      "littleness room -> sat down and took -> longness look\n",
      "littleness servant -> happening to be entering -> fortress with two hotness rolls\n",
      "littleness thought -> is it to be -> refreshment beneath this humbleness roof\n",
      "longness passage -> had first trodden -> thickness boots\n",
      "longness strip -> has been -> blankness horizon\n",
      "rul loo rul -> was n’t i done very -> brownness sirs\n",
      "otherness lots -> was marked -> otherness parts of the structure\n",
      "magic pen -> as yet not universally acknowledged -> townsman tooby\n",
      "malevolence young man -> fitted up -> perfect sausage shop\n",
      "otherness man -> had not -> sameness face\n",
      "man at my side -> was most -> preciousness rascal’\n",
      "strangeness man -> had come back -> bank notes\n",
      "man trap -> n’t be -> amenities of life\n",
      "young man -> get home -> goo goodness night\n",
      "obligingness manner -> merely stating -> politeness expostulatory notice\n",
      "mantel shelf -> even extended -> blackness nose\n",
      "many rope walks -> n’t be -> old green copper\n",
      "marine store shop -> did so -> back street\n",
      "sameness matthew -> were mentioning -> miss havisham\n",
      "nominal meal -> was going to make -> vigor reality\n",
      "more meaning -> doubt if they had -> election cry\n",
      "muchness meaning -> perfectly understood -> miss havisham\n",
      "mere mooncalfs -> stand talking -> uncle pumblechook\n",
      "unfortunate mike -> very humbly withdrew -> mr. jaggers and wemmick\n",
      "strangeness and strong misgiving -> had been lying there -> longness time\n",
      "moment miss -> skiffins neatly stopped -> green gloves\n",
      "silver mist -> being touched -> first rays of the moonlight\n",
      "place of mistress -> am going to try to get -> newness school\n",
      "moment of the time -> not to lose -> dear boy\n",
      "mother woman -> had not outlived -> honestness sympathy\n",
      "mr. orlick -> have been indulging -> intellect evening\n",
      "mr. pip -> not get rid -> certain air\n",
      "mr. pocket -> is also -> first bloom\n",
      "mr. pocket -> grown up -> infant with no notion\n",
      "mr. pocket -> being justly celebrated for giving most -> excel practice advice\n",
      "mr. pumblechook -> then i put -> pence table\n",
      "mr. pumblechook -> had wished -> newness clothes\n",
      "mr. pumblechook -> sighing and nodding -> head several times\n",
      "theatre where mr. wopsle -> had achieved -> questionable triumph\n",
      "mr. trabb -> took me down -> roll of cloth\n",
      "mr. trabb -> never removed -> sternness eye\n",
      "mr. trabb -> had taken -> best table\n",
      "mr. wemmick -> had put -> biscuit into the post\n",
      "mr. wopsle -> began to conceive rather -> poorness opinion\n",
      "mr. wopsle -> was divesting -> danish garments\n",
      "mr. wopsle -> had treated -> littleness appropriateness refreshment\n",
      "mrs. pocket -> was sitting -> garden chair under a tree\n",
      "mrs. pocket -> too went fairly head foremost -> mrs. pocket\n",
      "mrs. pocket -> instantly showed -> muchness amiability emotion\n",
      "mrs. pocket -> going home -> family hole\n",
      "mrs. pocket -> tripped up -> family with her footstool\n",
      "muchness need -> had as -> hushing voice\n",
      "muchness as if one nostril -> was caught up -> horse hair\n",
      "muchness for old orlick -> usually spoke -> ancient person\n",
      "muchness watching -> required as -> powder mill\n",
      "popularity murder -> had been committed -> mr. wopsle\n",
      "naturalness ties -> never coming here to see -> miss havisham\n",
      "nothing of a tenderness nature -> possibly be confided -> oldness barley\n",
      "unavoidable necessity -> had put -> immensity relief\n",
      "remedies for negligence -> has agreed -> strict liability\n",
      "next opportunity -> was when she was waiting -> mrs. blandley\n",
      "next street -> was far -> greater hazard\n",
      "prematureness night -> had been sent straight -> bed in an attic\n",
      "oddness sensation -> see his very -> familiar face\n",
      "office page -> find it was -> additional contact information\n",
      "post office -> were as -> indifference and ready\n",
      "post office -> was widened -> utmost extent\n",
      "office proceedings -> not do -> smell fire\n",
      "oldness officer -> send down -> prison ships\n",
      "old orlick -> come for to hear -> uncle provis\n",
      "old orlick -> knowed you was burnt -> old orlick\n",
      "years older -> had established -> greatness reputation\n",
      "oncommonest workman -> n’t show -> oncommon in a gridiron ,--\n",
      "sameness opportunity -> served me for noticing -> mr. pumblechook\n",
      "piece of ordnance -> was mounted -> separateness fortress\n",
      "otherness people -> was waiting -> mr. jaggers\n",
      "otherness persons -> have turned -> cruelness account\n",
      "own story -> began adoring -> first time\n",
      "ram page -> ’s been -> last spell\n",
      "state parlor -> was seated -> kitchen fire\n",
      "quietness pause -> went on -> life afresh\n",
      "unequal to the performance -> stood looking -> miss havisham\n",
      "royal phantom -> also carried -> ghost manuscript round its truncheon\n",
      "sarah pocket -> then made -> separateness effect\n",
      "sarah pocket -> supposed me to have superseded -> miss georgiana\n",
      "remains of my poorness sister -> had been brought round -> door in the kitchen\n",
      "poorness soul -> were n’t long of following -> share of peace\n",
      "pumblechook ’s premises -> got round -> high street\n",
      "undecided prince -> had asked -> question or state a doubt\n",
      "smallness proportions -> n’t be -> kind of place\n",
      "specialness providence -> had put -> ‘ prentice\n",
      "servility pumblechook -> put down -> untasted glass\n",
      "raggedness things -> do n’t know -> many footmen\n",
      "taste for reading -> read regularly so -> many hours a day\n",
      "soberness reality -> was surpassed -> miss havisham\n",
      "such reasons -> was very -> gladness when ten o’clock\n",
      "reassuring words -> stretched out -> tremulous rightness hand\n",
      "verb remark -> n’t be -> proceeding in dullness show\n",
      "something in reserve -> felt that i must have -> dread acquaintance\n",
      "wedding ring -> passing unsympathetically -> human countenance\n",
      "white sails -> somehow thought -> miss havisham\n",
      "’s sausage -> greatly discomposed -> own attention\n",
      "whole scene -> starts out again -> vividness colors of the moment\n",
      "second or third time -> tear down -> compeyson ’s parlor\n",
      "troublesomeness sense -> has been -> lowness ”\n",
      "white sheet -> loosely overlying -> phantom air\n",
      "violence shock -> be extinguished -> next thing\n",
      "shop window -> were springing up brilliantly -> street lamp lighters\n",
      "stretch of shore -> have yet been -> steamer ’s smoke\n",
      "shortness struggle -> had informed -> mr. pocket\n",
      "shortness time -> had lasted but a very -> mrs. pocket\n",
      "waxwork and skeleton -> seemed to have -> dark eyes\n",
      "smallness as that the weight -> is unfortunately made so -> blackness feathers\n",
      "wickedness spirit -> had somehow sent -> messengers to mine\n",
      "steam traffic on the thames -> was far -> present extent\n",
      "successfulness a watch and ward -> had been established -> young lady\n",
      "such things -> had taken -> industry habits\n",
      "want of toleration -> being detected -> holiness orders\n",
      "wedding tour -> was planned out -> wedding guests\n",
      "wrongness twin -> have evaporated -> evening air\n",
      "undiscussible way -> said it so finally -> mr. pumblechook\n",
      "whole world -> giving up -> whole heart\n"
     ]
    }
   ],
   "source": [
    "for t in sorted(triples, key=lambda t:t['subject']):\n",
    "    sub=t['subject']\n",
    "    prd=t['predicate']\n",
    "    obj=t['object']\n",
    "    if sub in concepts and prd in predicates and obj in concepts:\n",
    "        sbjlabel = concepts[sub][0][2]\n",
    "        prdlabel = predicates[prd][0][2]\n",
    "        objlabel = concepts[obj][0][2]\n",
    "        print(sbjlabel,'->',prdlabel,'->',objlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 'newness_regression_technique_test', 'newness technique for regression test']\n",
      "[2, 'select_test', 'select tests']\n",
      "[2, 'certain_condition', 'certain conditions']\n",
      "[2, 'algorithm_select', 'algorithms select']\n",
      "[2, 'algorithm_selection', 'selection algorithms']\n",
      "[2, 'many_otherness_regression_test', 'many otherness regression test']\n",
      "[2, 'modification_program_type', 'types of program modifications']\n",
      "[2, 'development_testing', 'development testing']\n",
      "[2, 'modified_program', 'modified program']\n",
      "[2, 'clemson_university', 'clemson university']\n",
      "[2, 'component_program', 'program components']\n",
      "[2, 'coverage_criterion', 'coverage criteria']\n",
      "[2, 'environment_programming', 'programming environment']\n",
      "[2, 'currency_practice', 'currency practice']\n",
      "[2, 'additional_test', 'additional tests']\n",
      "[2, 'many_technique', 'many techniques']\n",
      "[2, 'algorithms_otherness_safeness', 'otherness safeness algorithms']\n",
      "[2, 'few_test', 'fewer tests']\n",
      "[2, 'process_regression_testing', 'regression testing process']\n",
      "[2, 'interprocedural_intraprocedural_regression_test', 'interprocedural and intraprocedural regression test']\n",
      "[2, 'modification_program', 'program modifications']\n",
      "[2, 'language_procedure', 'procedure languages']\n",
      "[2, 'output_p', 'output of p']\n",
      "[2, 'output_specified', 'specified output']\n",
      "[2, 'cfg_p_procedure', 'cfg for procedure p']\n",
      "[2, 'node_statement', 'statement nodes']\n",
      "[2, 'edge_label', 'edge label']\n",
      "[2, 'case_statement', 'case statements']\n",
      "[2, 'instrumented_version', 'instrumented version']\n",
      "[2, 'cfg_g', 'cfg g']\n",
      "[2, 'edge_p_t_trace', 'edge trace for t on p']\n",
      "[2, 'bit_vector', 'bit vector']\n",
      "[2, 'information_test', 'test information']\n",
      "[2, 'p_t', 'p with t']\n",
      "[2, 'subset_t', 'subset t']\n",
      "[2, 'critic_phase', 'critic phase']\n",
      "[2, 'phase_preliminary_regression_testing', 'preliminary phase of regression testing']\n",
      "[2, 'cost_critic_phase', 'critic phase cost']\n",
      "[2, 'algorithm_regression_selection_test', 'regression test selection algorithms']\n",
      "[2, 'nonobsolete_test', 'nonobsolete tests']\n",
      "[2, 'differ_execution_trace', 'differ execution traces']\n",
      "[2, 'intraprocedural_selection_test', 'intraprocedural test selection']\n",
      "[2, 'increment_process', 'increment process']\n",
      "[2, 'such_trace', 'such traces']\n",
      "[2, 'p_version', 'version p']\n",
      "[2, 'n_n_node_pair', 'pairs of nodes n and n']\n",
      "[2, 'graph_traversal', 'graph traversals']\n",
      "[2, 's_statement', 'statements s']\n",
      "[2, 'character_constant', 'character constants']\n",
      "[2, 'avg_procedure', 'procedure avg']\n",
      "[2, 'avg_avg2', 'avg and avg2']\n",
      "[2, 'suite_t_test', 'test suite t']\n",
      "[2, 'equivalent_return_trueness', 'equivalent returns trueness']\n",
      "[2, 'node_successor', 'successors of these nodes']\n",
      "[2, 'change_only', 'only change']\n",
      "[2, 'case_latter', 'latter case']\n",
      "[2, 'c_function', 'c function']\n",
      "[2, 't2_test', 'test t2']\n",
      "[2, 'factor_otherness', 'otherness factors']\n",
      "[2, 'regression_selection_test', 'regression test selection']\n",
      "[2, 'controlled_regression_testing', 'controlled regression testing']\n",
      "[2, 'prematureness_section', 'prematureness section']\n",
      "[2, 'equivalent_procedure', 'equivalent procedure']\n",
      "[2, 'practice_purpose', 'practice purposes']\n",
      "[2, 'pair_procedure', 'pair of procedures']\n",
      "[2, 'several_way', 'several ways']\n",
      "[2, 'algorithm_basic', 'basic algorithm']\n",
      "[2, 'code_executability', 'executability code']\n",
      "[2, 'only_test', 'only tests']\n",
      "[2, 'executability_portion', 'executability portion']\n",
      "[2, 'edge_newness', 'newness edges']\n",
      "[2, 'procedure_singleness', 'singleness procedure']\n",
      "[2, 'functionality_specification', 'functionality and specification']\n",
      "[2, 'approach_simpleness', 'simpleness approach']\n",
      "[2, 'p_present', 'present in p']\n",
      "[2, 'program_sys', 'program sys']\n",
      "[2, 'case_need', 'need in this case']\n",
      "[2, 'call_node', 'call nodes']\n",
      "[2, 'e_p', 'p e']\n",
      "[2, 'c_call', 'c for calls']\n",
      "[2, 'safeness_selection_test', 'safeness test selection']\n",
      "[2, 'case_multiply', 'cases where the multiply']\n",
      "[2, 'otherness_safeness_technique', 'otherness safeness techniques']\n",
      "[2, 'experimental_subject_suitability', 'suitability experimental subjects']\n",
      "[2, 'task_trivia', 'trivia task']\n",
      "[2, 'free_software', 'free software']\n",
      "[2, 'cross_fairness_section', 'fairness cross section']\n",
      "[2, 'engineer_software', 'software engineers']\n",
      "[2, 'study_such', 'such studies']\n",
      "[2, 'interprocedural_selection_test', 'interprocedural test selection']\n",
      "[2, 'adequacy_criterion_test', 'test adequacy criteria']\n",
      "[2, 'program_siemens', 'siemens programs']\n",
      "[2, 'base_fault_program_version', 'fault versions of base programs']\n",
      "[2, 'pool_test', 'test pool']\n",
      "[2, 'siemens_subject', 'siemens subjects']\n",
      "[2, 'base_procedure', 'base procedure']\n",
      "[2, 'figure_result', 'results figure']\n",
      "[2, 'selection_test_tool', 'test selection tool']\n",
      "[2, 'column_dark', 'darkest column']\n",
      "[2, 'column_light', 'lightest column']\n",
      "[2, 'overall_regression_testing_time', 'overall regression testing time']\n",
      "[2, 'large_program', 'larger programs']\n",
      "[2, 'executable_player', 'player executable']\n",
      "[2, 'manager_transaction', 'transaction manager']\n",
      "[2, 'large_software_system', 'large software systems']\n",
      "[2, 'hour_minute', 'hours and 39 minutes']\n",
      "[2, 'minimization_selection_technique_test', 'minimization test selection technique']\n",
      "[2, 'effectiveness_relativity', 'relativity effectiveness']\n",
      "[2, 'case_such', 'cases such']\n",
      "[2, 'program_simpleness', 'simpleness programs']\n",
      "[2, 'artifact_manufactured', 'manufactured artifacts']\n",
      "[2, 'analysis_time', 'analysis times']\n",
      "[2, 'product_software', 'software product']\n",
      "[2, 'developer_software_user', 'developers and users of software']\n",
      "[2, 'otherness_regression_selection_test', 'otherness regression test selection']\n",
      "[2, 'newness_test', 'newness tests']\n",
      "[2, 'design_suite_test', 'test suite design']\n",
      "[2, 'london_s.', 's. london']\n",
      "[2, 'ostrand_t.', 't. ostrand']\n",
      "[2, 'languages_principle_programming', 'principles of programming languages']\n",
      "[2, 'b._beizer', 'b. beizer']\n",
      "[2, 'john_sons_wiley', 'john wiley and sons']\n",
      "[2, 'binkley_d.', 'd. binkley']\n",
      "[2, '16th_conference_international_proceeding', 'proceedings of the 16th international conference']\n",
      "[2, 'fischer_k.f.', 'k.f. fischer']\n",
      "[2, 'gupta_r.', 'r. gupta']\n",
      "[2, 'datum_increment', 'increment data']\n",
      "[2, 'd.j._robson', 'd.j. robson']\n",
      "[2, 'reps_t.', 't. reps']\n",
      "[2, 'journal_software', 'journal of systems and software']\n",
      "[2, 'h.k.n._leung', 'h.k.n. leung']\n",
      "[2, 'h.k.n._l.j._leung_white', 'h.k.n. leung and l.j. white']\n",
      "[2, 'l.j._white', 'l.j. white']\n",
      "[2, 'cost_model', 'cost model']\n",
      "[2, 'conference_proceeding', 'conference proceedings']\n",
      "[2, 'edition_second', 'second edition']\n",
      "[2, 'w._yang', 'w. yang']\n",
      "[2, 'acm_engineering_software_transaction', 'acm transactions on software engineering']\n",
      "[2, 'reality_time', 'reality time']\n",
      "[2, 'occam_razor', \"occam 's razor\"]\n",
      "[2, 'computer_modernity', 'modernity computers']\n",
      "[2, 'language_occam_programming', 'programming language occam']\n",
      "[2, 'lex_yacc', 'lex and yacc']\n",
      "[2, 'end_front', 'front end']\n",
      "[2, 'application_code', 'application code']\n",
      "[2, 'language_specification', 'specification language']\n",
      "[2, 'infinity_lookahead', 'infinity lookahead']\n",
      "[2, 'basic_construct', 'basic constructs']\n",
      "[2, 'extra_flexibility', 'extra flexibility']\n",
      "[2, 'flexibility_greatness', 'greatness flexibility']\n",
      "[2, 'c_call_stack', 'c call stack']\n",
      "[2, 'c_stack', 'c stack']\n",
      "[2, 'analyser_lexis', 'lexis analyser']\n",
      "[2, 'many_point', 'many points']\n",
      "[2, 'block_structure', 'block structure']\n",
      "[2, 'such_tool', 'such tools']\n",
      "[2, 'input_language', 'input language']\n",
      "[2, 'parse_specification', 'parse specification']\n",
      "[2, 'correctness_parser', 'correctness parsers']\n",
      "[2, 'parser_precc', 'precc parser']\n",
      "[2, 'concreteness_specification', 'concreteness specification']\n",
      "[2, 'default_lexer', 'default lexer']\n",
      "[2, 'precc_script', 'precc script']\n",
      "[2, 'declare_semantic', 'declare semantics']\n",
      "[2, 'production_rule', 'production rules']\n",
      "[2, 'emptiness_string', 'emptiness string']\n",
      "[2, 'c_macros', 'c macros']\n",
      "[2, 'expression_islower', 'islower expression']\n",
      "[2, 'muchness_work', 'muchness of the work']\n",
      "[2, 'john_wiley', 'john wiley']\n",
      "[2, 'computing_laboratory_oxford_university', 'oxford university computing laboratory']\n",
      "[2, 'l.m._wegner', 'l.m. wegner']\n",
      "[2, 'information_processing', 'information processing']\n",
      "[2, 'd._weber_wulff', 'd. weber wulff']\n",
      "[2, 'system_uga', 'uga system']\n",
      "[2, 'detail_less', 'less detail']\n",
      "[2, 'panel_side', 'side panels']\n",
      "[2, 'class_particularity', 'particularity class']\n",
      "[2, 'perspective_view', 'perspective view']\n",
      "[2, 'dimensionality_screen', 'dimensionality screens']\n",
      "[2, 'data_large_set', 'large data sets']\n",
      "[2, 'color_such', 'such as color']\n",
      "[2, 'object_tradition', 'tradition object']\n",
      "[2, 'complexity_object', 'complexity objects']\n",
      "[2, 'csg_hierarchy', 'csg hierarchy']\n",
      "[2, 'tool_visualization', 'visualization tool']\n",
      "[2, 'information_semantics', 'semantics information']\n",
      "[2, 'file_size', 'file size']\n",
      "[2, 'excel_tool', 'excel tool']\n",
      "[2, 'general_trend', 'general trends']\n",
      "[2, 'general_impression', 'general impression']\n",
      "[2, 'node_size', 'node size']\n",
      "[2, 'large_object', 'large objects']\n",
      "[2, 'complexity_visual', 'visual complexity']\n",
      "[2, 'figure_tree', 'tree figure']\n",
      "[2, 'dimensionality_object', 'dimensionality object']\n",
      "[2, 'high_level', 'higher level']\n",
      "[2, 'node_parent', 'parent nodes']\n",
      "[2, 'such_system', 'system such']\n",
      "[2, 'futurity_research', 'futurity research']\n",
      "[2, 'c._robert_zeleznik', 'robert c. zeleznik']\n",
      "[2, 'cache_coherence_scheme_software', 'software cache coherence scheme']\n",
      "[2, 'memory_virtual', 'virtual memory']\n",
      "[2, 'cache_coherence', 'cache coherence']\n",
      "[2, 'hardware_multiprocessor_specialness', 'specialness multiprocessor hardware']\n",
      "[2, 'consistency_differ_model', 'differ consistency models']\n",
      "[2, 'consistency_model_vm', 'consistency models for the vm']\n",
      "[2, 'result_simulation', 'simulation results']\n",
      "[2, 'scale_smallness', 'smallness scale']\n",
      "[2, 'cache_cohere', 'caches cohere']\n",
      "[2, 'shelf_uniprocessor', 'shelf uniprocessors']\n",
      "[2, 'arbitrariness_interconnection', 'arbitrariness interconnections']\n",
      "[2, 'bus_transaction', 'transactions on this bus']\n",
      "[2, 'action_appropriateness', 'appropriateness actions']\n",
      "[2, 'boundary_loop', 'loop boundaries']\n",
      "[2, 'invalidation_unnecessary', 'unnecessary invalidations']\n",
      "[2, 'few_instruction', 'few instructions']\n",
      "[2, 'hardware_specialness_support', 'specialness hardware support']\n",
      "[2, 'parallel_program', 'parallel programs']\n",
      "[2, 'prematureness_work', 'prematureness work']\n",
      "[2, 'consistency_memory_model', 'memory consistency models']\n",
      "[2, 'implementation_vm', 'implementation of the vm']\n",
      "[2, 'cached_line', 'cached lines']\n",
      "[2, 'back_cache_write', 'write back caches']\n",
      "[2, 'address_space', 'address space']\n",
      "[2, 'page_table', 'page table']\n",
      "[2, 'bit_protection', 'protection bits']\n",
      "[2, 'cache_consistency_model', 'cache consistency model']\n",
      "[2, 'initial_state', 'initial state']\n",
      "[2, 'entry_page_table', 'page table entry']\n",
      "[2, 'load_memory', 'memory load']\n",
      "[2, 'invalidation_laziness_method', 'method laziness invalidation']\n",
      "[2, 'invalidation_laziness', 'laziness invalidation']\n",
      "[2, 'datum_staleness', 'staleness data']\n",
      "[2, 'location_memory_physicality_sameness', 'sameness physicality memory location']\n",
      "[2, 'bit_highness_order_unused', 'unused highness order bits']\n",
      "[2, 'number_version', 'version number']\n",
      "[2, 'otherness_variable', 'otherness variables']\n",
      "[2, 'consistency_model_relaxed', 'relaxed consistency models']\n",
      "[2, 't1_time', 'time t1']\n",
      "[2, 'fault_write', 'write fault']\n",
      "[2, 'access_synchronization', 'synchronization accesses']\n",
      "[2, 'access_store', 'store access']\n",
      "[2, 'otherness_processor_respect', 'respect to any otherness processor']\n",
      "[2, 'page_shared', 'shared pages']\n",
      "[2, 'access_write', 'write access']\n",
      "[2, 'implementation_lrc', 'implementation of lrc']\n",
      "[2, 'increment_weaki', 'increment weaki']\n",
      "[2, 'cache_entry', 'cache entries']\n",
      "[2, 'application_program', 'application programs']\n",
      "[2, 'number_small', 'smallest number']\n",
      "[2, 'queue_task', 'task queue']\n",
      "[2, 'series_step_time', 'series of time steps']\n",
      "[2, 'barrier_synchronization', 'barrier synchronization']\n",
      "[2, 'molecule_set', 'set of molecules']\n",
      "[2, 'processor_several', 'several processors']\n",
      "[2, 'cell_sameness_space', 'sameness space cell']\n",
      "[2, 'sameness_step_time', 'sameness time step']\n",
      "[2, 'matrix_point', 'point matrix']\n",
      "[2, 'memory_unit', 'memory unit']\n",
      "[2, 'bus_contention', 'bus contention']\n",
      "[2, 'lock_x', 'lock x']\n",
      "[2, 'fault_handler', 'fault handler']\n",
      "[2, 'paper_purpose', 'purpose of this paper']\n",
      "[2, 'locality_lowness', 'lowness locality']\n",
      "[2, 'degree_highness', 'highness degree']\n",
      "[2, 'case_otherness', 'otherness cases']\n",
      "[2, 'bus_load', 'load in on the bus']\n",
      "[2, 'mul_water', 'water and mul']\n",
      "[2, 'contention_extremity', 'extremity contention']\n",
      "[2, 'scheme_snooping', 'snooping scheme']\n",
      "[2, 'incoherence_page', 'incoherence pages']\n",
      "[2, 'acknowledgement_research', 'acknowledgements this research']\n",
      "[2, 'draft_early', 'earlier drafts']\n",
      "[2, 'd._hill_mark', 'mark d. hill']\n",
      "[2, 'conference_international_proceeding_supercomputing', 'proceedings of the 1992 international conference on supercomputing']\n",
      "[2, '12th_international_proceeding_symposium', 'proceedings of the 12th international symposium']\n",
      "[2, 'architectural_languages_programming_support', 'architectural support for programming languages']\n",
      "[2, 'joe_truman', 'truman joe']\n",
      "[2, 'david_nakahira', 'david nakahira']\n",
      "[2, 'luis_stevens', 'luis stevens']\n",
      "[2, 'dash_prototype_stanford', 'stanford dash prototype']\n",
      "[2, 'logic_overhead_performance', 'logic overhead and performance']\n",
      "[2, '3rd_conference_international_proceeding', 'proceedings of the 3rd international conference']\n",
      "[2, 'dynamic_object', 'object dynamics']\n",
      "[2, 'change_object_state', 'object state changes']\n",
      "[2, 'mutability_state', 'mutability state']\n",
      "[2, 'aspect_stillness', 'stillness aspects']\n",
      "[2, 'react_system', 'react systems']\n",
      "[2, 'general_language_oolp', 'general oolp language']\n",
      "[2, 'language_oolp', 'oolp language']\n",
      "[2, 'logic_program', 'logic program']\n",
      "[2, 'declare_effort', 'declare effort']\n",
      "[2, 'conjunction_logicality', 'logicality conjunction']\n",
      "[2, 'object_reality_world', 'reality world objects']\n",
      "[2, 'object_prolog', 'object prolog']\n",
      "[2, 'argument_term', 'term argument']\n",
      "[2, 'completeness_history', 'completeness histories']\n",
      "[2, 'database_declare', 'declare database']\n",
      "[2, 'knowledge_newness', 'newness knowledge']\n",
      "[2, 'general_logic_theory', 'general logic theories']\n",
      "[2, 'oldness_theory', 'oldness theory']\n",
      "[2, 'database_update', 'database updates']\n",
      "[2, 'element_update', 'element updates']\n",
      "[2, 'model_particularity', 'particularity model']\n",
      "[2, 'sameness_time', 'sameness time']\n",
      "[2, 'database_transaction', 'database transactions']\n",
      "[2, 'compositional_property', 'compositional properties']\n",
      "[2, 'choice_determinism', 'determinism choice']\n",
      "[2, 'efficiency_implementation', 'efficiency implementation']\n",
      "[2, 'imperativeness_program', 'imperativeness programs']\n",
      "[2, 'formula_oe', 'formulae oe']\n",
      "[2, 'context_free_grammar', 'context free grammar']\n",
      "[2, 'abstract_data_types', 'abstract data types']\n",
      "[2, 'aspect_dynamism', 'dynamism aspects']\n",
      "[2, 'diploma_thesis', 'diploma thesis']\n",
      "[2, 'database_theory', 'theory of database']\n",
      "[2, 'prolog_purity', 'purity prolog']\n",
      "[2, 'logic_mode', 'mode logic']\n",
      "[2, 'approach_similarity', 'similarity approach']\n",
      "[2, 'proof_search', 'proof search']\n",
      "[2, 'concurrency_pseudo', 'pseudo concurrency']\n",
      "[2, 'development_simultaneity', 'simultaneity development']\n",
      "[2, 'message_term', 'message term']\n",
      "[2, 'currency_goal', 'currency goal']\n",
      "[2, 'clause_corresponding', 'corresponding clause']\n",
      "[2, 'concurrent_programming_prolog', 'programming in concurrent prolog']\n",
      "[2, 'conventionality_prolog', 'conventionality prolog']\n",
      "[2, 'level_lowness', 'lowness level']\n",
      "[2, 'coincide_language_lp', 'coincide lp language']\n",
      "[2, 'part_record', 'part records']\n",
      "[2, 'method_polymorphism', 'polymorphism method']\n",
      "[2, 'otherness_way', 'otherness ways']\n",
      "[2, 'clause_program', 'program clause']\n",
      "[2, 'literalness_procedure', 'procedure literalness']\n",
      "[2, 'newness_object', 'newness object']\n",
      "[2, 'a_object', 'object a']\n",
      "[2, 'conery_haridi', 'conery and haridi']\n",
      "[2, 'inheritance_mechanism', 'inheritance mechanism']\n",
      "[2, 'problem_similarity', 'similarity problem']\n",
      "[2, 'fineness_granularity', 'fineness granularity']\n",
      "[2, 'implication_linearity', 'linearity implication']\n",
      "[2, 'linear_object', 'linear objects']\n",
      "[2, 'andreoli_pareschi', 'andreoli and pareschi']\n",
      "[2, 'corresponding_method', 'corresponding method']\n",
      "[2, 'inference_process', 'inference process']\n",
      "[2, 'naturalness_way', 'naturalness ways']\n",
      "[2, 'inference_rule', 'inference rule']\n",
      "[2, 'clause_horn_programming', 'horn clause programming']\n",
      "[2, 'coincide_logicality_object_theory', 'logicality theory of coincide objects']\n",
      "[2, 'language_logic_programming', 'logic programming language']\n",
      "[2, 'programming_relational', 'relational programming']\n",
      "[2, 'class_object', 'object class']\n",
      "[2, 'logic_mode_multi_programming', 'multi mode logic programming']\n",
      "[2, 'object_structure', 'object structure']\n",
      "[2, 'abiteboul_s.', 's. abiteboul']\n",
      "[2, 'acm_sigact_sigart_sigmod', 'acm sigact sigmod sigart']\n",
      "[2, 'andreoli_j_m._r.', 'j m. andreoli and r.']\n",
      "[2, 'linearity_object', 'linearity objects']\n",
      "[2, 'logicality_process', 'logicality processes']\n",
      "[2, 'pareschi_r.', 'r. pareschi']\n",
      "[2, 'a._bonner_kifer_m.', 'a. bonner and m. kifer']\n",
      "[2, 'kifer_m.', 'm. kifer']\n",
      "[2, 'masunaga_y.', 'y. masunaga']\n",
      "[2, 'chikayama_t.', 't. chikayama']\n",
      "[2, 'computer_fifth_generation', 'fifth generation computers']\n",
      "[2, 'computing_generation_newness', 'newness generation computing']\n",
      "[2, 'conference_fifth_generation_international', 'international conference on fifth generation']\n",
      "[2, \"iclp'91_paper_position_workshop\", \"position paper on the iclp'91 workshop\"]\n",
      "[2, 'oregon_university', 'university of oregon']\n",
      "[2, 'enjalbert_p.', 'p. enjalbert']\n",
      "[2, 'algebraic_logic_programming', 'algebraic and logic programming']\n",
      "[2, 'knowledge_representation', 'representation of knowledge']\n",
      "[2, 'diego_san', 'san diego']\n",
      "[2, 'fagin_r.', 'r. fagin']\n",
      "[2, 'j._ullman', 'j. ullman']\n",
      "[2, 'm._vardi', 'm. vardi']\n",
      "[2, 'a._herzig', 'a. herzig']\n",
      "[2, 'd._harel', 'd. harel']\n",
      "[2, 'logic_process', 'process logic']\n",
      "[2, 'fullness_paper', 'fullness paper']\n",
      "[2, 'master_thesis', \"master 's thesis\"]\n",
      "[2, 'computer_logic_science', 'logic in computer science']\n",
      "[2, 'ishikawa_m._tokoro_y.', 'y. ishikawa and m. tokoro']\n",
      "[2, 'phd_thesis', 'phd thesis']\n",
      "[2, 'braunschweig_technical_university', 'technical university braunschweig']\n",
      "[2, 'g._saake', 'g. saake']\n",
      "[2, 'c._sernadas', 'c. sernadas']\n",
      "[2, 'abramsky_s._s._t.', 's. abramsky and t. s.']\n",
      "[2, 'e._maibaum', 'e. maibaum']\n",
      "[2, 'conference_international_joint_theory', 'international joint conference on theory']\n",
      "[2, 'coincide_logicality_object', 'logicality coincide objects']\n",
      "[2, 'd._e._tribble', 'e. d. tribble']\n",
      "[2, 'm._miller_s.', 'm. s. miller']\n",
      "[2, 'bobrow_d._g.', 'd. g. bobrow']\n",
      "[2, 'object_oriented_programming', 'object oriented programming']\n",
      "[2, 'kanovich_m.', 'm. kanovich']\n",
      "[2, 'journal_logic_programming', 'journal of logic programming']\n",
      "[2, 'ccl_pub', 'pub / ccl']\n",
      "[2, 'm._winslett', 'm. winslett']\n",
      "[2, 'chikayama_k._t._yoshida', 'k. yoshida and t. chikayama']\n",
      "[2, 'determinism_newness_parallel', 'newness determinism parallel']\n",
      "[2, 'communication_personalized', 'personalized communication']\n",
      "[2, 'cray_research_t3d.', 'cray research t3d.']\n",
      "[2, 'differ_platform', 'differ platforms']\n",
      "[2, 'algorithm_randomness_sample_sort', 'randomness sample sort algorithm']\n",
      "[2, 'algorithm_similarity', 'similarity algorithms']\n",
      "[2, 'algorithms_efficiency_prematureness', 'prematureness efficiency algorithms']\n",
      "[2, 'algorithm_randomized_sorting', 'randomized sorting algorithm']\n",
      "[2, 'memory_performance_requirement', 'performance and memory requirements']\n",
      "[2, 'communication_regularity', 'regularity communication']\n",
      "[2, 'primitiveness_transpose', 'transpose primitiveness']\n",
      "[2, 'sameness_size', 'sameness size']\n",
      "[2, 'array_singleness', 'singleness array']\n",
      "[2, 'oem_time', 'oem time']\n",
      "[2, 'block_permutation', 'block permutation']\n",
      "[2, 'element_n', 'n elements']\n",
      "[2, 'group_p', 'p groups']\n",
      "[2, 'group_ith', 'ith group']\n",
      "[2, 'processor_singleness', 'singleness processor']\n",
      "[2, 'prematureness_study', 'prematureness studies']\n",
      "[2, 'completion_sorting', 'completion of sorting']\n",
      "[2, 'binary_search', 'binary search']\n",
      "[2, 'less_value', 'value less']\n",
      "[2, 'input_pi_processor', 'input at processor pi']\n",
      "[2, 'log_o(sp_p', 'o(sp log p']\n",
      "[2, 'datum_type', 'data type']\n",
      "[2, 'double_precision', 'double precision']\n",
      "[2, 'double_version', 'double version']\n",
      "[2, 'maximum_value', 'maximum value']\n",
      "[2, 'input_randomness', 'randomness input']\n",
      "[2, 'benchmark_integer_value', 'integer benchmark values']\n",
      "[2, 'duplicate_input', 'input of duplicates']\n",
      "[2, 'number_optimum_sample', 'optimum number of samples']\n",
      "[2, 'number_optimum', 'optimum number']\n",
      "[2, 'ii_table', 'table ii']\n",
      "[2, 'good_performance', 'best performance']\n",
      "[2, 'benchmark_integer', 'integer benchmarks']\n",
      "[2, 'benchmark_double', 'double benchmarks']\n",
      "[2, 'result_tables_vii_viii', 'results in tables vii and viii']\n",
      "[2, 'machine_size', 'machine size']\n",
      "[2, 'particularity_platform', 'particularity platform']\n",
      "[2, 'operation_step_transpose', 'transpose operation in step']\n",
      "[2, 'p_subsequence', 'p subsequences']\n",
      "[2, 'regularity_sample', 'regularity sample']\n",
      "[2, 'interaction_simulation', 'interaction simulation']\n",
      "[2, 'geography_information_system', 'geography information systems']\n",
      "[2, 'approach_effect', 'effect approach']\n",
      "[2, 'highness_performance', 'highness performance']\n",
      "[2, 'operation_query_range', 'range query operation']\n",
      "[2, 'declustering_method_randomness_range', 'randomness declustering methods for range']\n",
      "[2, 'problem_query', 'query problems']\n",
      "[2, 'dlb_method_performance', 'performance of dlb methods']\n",
      "[2, 'declustering_method', 'declustering methods']\n",
      "[2, 'line_segment', 'line segments']\n",
      "[2, 'gis_operation', 'gis operations']\n",
      "[2, 'map_polygonal', 'polygonal map']\n",
      "[2, 'frequency_operation', 'frequency of this operation']\n",
      "[2, 'formulation_parallel', 'parallel formulations']\n",
      "[2, 'gis_query_range', 'gis range query']\n",
      "[2, 'search_structure', 'search structure']\n",
      "[2, 'declustering_method_stillness', 'stillness declustering methods']\n",
      "[2, 'overhead_synchronization', 'synchronization overhead']\n",
      "[2, 'additional_work', 'additional work']\n",
      "[2, 'declustering_problem', 'declustering problem']\n",
      "[2, 'heuristic_method', 'heuristic methods']\n",
      "[2, 'more_work', 'more work']\n",
      "[2, 'filtering_step', 'filtering step']\n",
      "[2, 'imbalance_load_stillness', 'stillness load imbalance']\n",
      "[2, 'cost_synchronization', 'cost of synchronization']\n",
      "[2, 'datum_object_space', 'space data objects']\n",
      "[2, 'dlb_method', 'dlb method']\n",
      "[2, 'declustering_operation', 'declustering operation']\n",
      "[2, 'edge_sequence', 'sequence of edges']\n",
      "[2, 'graph_method_similarity', 'similarity graph method']\n",
      "[2, 'experiment_result', 'results of this experiment']\n",
      "[2, 'average_speedup', 'average speedup']\n",
      "[2, 'balance_goodness_load', 'goodness load balance']\n",
      "[2, 'datum_totality', 'totality data']\n",
      "[2, 'access_locality', 'locality of access']\n",
      "[2, 'address_globe_space', 'globe address space']\n",
      "[2, 'interaction_processor', 'processor interaction']\n",
      "[2, 'time_transfer_work', 'time work transfers']\n",
      "[2, 'kumar_v.', 'v. kumar']\n",
      "[2, 'benjamin_company_cummings_publishing', 'benjamin / cummings publishing company']\n",
      "[2, 'data_ieee_knowledge_transaction', 'ieee transaction on knowledge and data']\n",
      "[2, 'architecture_software', 'software architectures']\n",
      "[2, 'domain_specificity', 'domain specificity']\n",
      "[2, 'domain_model', 'domain models']\n",
      "[2, 'database_system', 'database systems']\n",
      "[2, 'network_protocol', 'network protocols']\n",
      "[2, 'encapsulation_large_scale', 'large scale encapsulation']\n",
      "[2, 'generator_software', 'software generators']\n",
      "[2, 'component_such', 'such components']\n",
      "[2, 'component_encapsulation', 'component encapsulation']\n",
      "[2, 'domain_specific', 'domain specific']\n",
      "[2, 'atom_unit', 'atom units']\n",
      "[2, 'construction_program', 'program construction']\n",
      "[2, 'datum_member', 'data members']\n",
      "[2, 'class_cursor', 'cursor classes']\n",
      "[2, 'element_object', 'element objects']\n",
      "[2, 'component_interface', 'interface of a component']\n",
      "[2, 'interface_realm', 'realm interface']\n",
      "[2, 'interface_realm?s', 'realm?s interface']\n",
      "[2, 'component_software', 'software components']\n",
      "[2, 'class_method', 'methods of two classes']\n",
      "[2, 'class_newness', 'newness class']\n",
      "[2, 'code_directness_modification_source', 'directness source code modification']\n",
      "[2, 'component_linked_list', 'linked_list component']\n",
      "[2, 'collection_component', 'collection component']\n",
      "[2, 'interface_r', 'interface r']\n",
      "[2, 'collection_realm', 'collection realm']\n",
      "[2, 'otherness_researcher', 'otherness researchers']\n",
      "[2, 'realm_s', 'realm s']\n",
      "[2, 'inheritance_realm', 'realm inheritance']\n",
      "[2, 'parameterized_type', 'parameterized type']\n",
      "[2, 'code_generation_highness_quality', 'highness quality code generation']\n",
      "[2, 'abstract_class', 'abstract class']\n",
      "[2, 'd?az_guillermo_prieto_rub?n', 'rub?n prieto d?az and guillermo']\n",
      "[2, 'analysis_domain', 'domain analysis']\n",
      "[2, 'marty_sirkin', 'marty sirkin']\n",
      "[2, 'ernest_hemingway', 'ernest hemingway']\n",
      "[2, 'method_statistics', 'statistics methods']\n",
      "[2, 'hardy_thomas', 'thomas hardy']\n",
      "[2, 'compression_text', 'text compression']\n",
      "[2, 'author_particularity', 'particularity author']\n",
      "[2, 'form_surface', 'surface forms']\n",
      "[2, 'competition_hemingway_imitation', 'imitation hemingway competition']\n",
      "[2, 'bad_best_hemingway', 'best of bad hemingway']\n",
      "[2, 'phrase_verb', 'verb phrase']\n",
      "[2, 'generator_number_pseudo_randomness', 'pseudo randomness number generator']\n",
      "[2, 'sample_text', 'sample text']\n",
      "[2, 'grammar_inference', 'grammar inference']\n",
      "[2, 'sample_string', 'sample strings']\n",
      "[2, 'finiteness_vocabulary', 'finiteness vocabulary']\n",
      "[2, 'induction_process', 'induction process']\n",
      "[2, 'smith_witten', 'smith and witten']\n",
      "[2, 'main_predicate', 'main predicate']\n",
      "[2, 'mechanism_planning', 'planning mechanism']\n",
      "[2, 'jersey_new', 'new jersey']\n",
      "[2, 'artificiality_intelligence', 'artificiality intelligence']\n",
      "[2, 'paper_series', 'paper series']\n",
      "[2, 'new_zealand', 'new zealand']\n",
      "[2, 'communication_mode_various', 'various communication modes']\n",
      "[2, 'communication_human', 'human communication']\n",
      "[2, 'differ_type', 'differ types']\n",
      "[2, 'collaborate_group_work', 'collaborate group work']\n",
      "[2, 'group_member', 'group members']\n",
      "[2, 'problem_workspace', 'workspace problem']\n",
      "[2, 'cooperate_environment_work', 'cooperate work environment']\n",
      "[2, 'face_face_meeting', 'face to face meetings']\n",
      "[2, 'audio_link', 'audio link']\n",
      "[2, 'cooperate_task', 'cooperate tasks']\n",
      "[2, 'effect_littleness', 'littleness effect']\n",
      "[2, 'communication_group_process', 'group communication process']\n",
      "[2, 'otherness_software', 'otherness software']\n",
      "[2, 'area_such', 'such areas']\n",
      "[2, 'control_floor', 'floor control']\n",
      "[2, 'camera_video', 'video cameras']\n",
      "[2, 'computer_control_room', 'control room computer']\n",
      "[2, 'audio_conversation', 'audio conversations']\n",
      "[2, 'differ_environment', 'differ environments']\n",
      "[2, 'environment_newness', 'newness environment']\n",
      "[2, 'audio_signal_video', 'video and audio signals']\n",
      "[2, 'simultaneity_speech', 'simultaneity speech']\n",
      "[2, 'simultaneity_speech_utterance', 'simultaneity speech utterances']\n",
      "[2, 'value_variable', 'value of these variables']\n",
      "[2, 'session_tape_video', 'video tapes of the sessions']\n",
      "[2, 'first_program', 'first program']\n",
      "[2, 'longness_time', 'longness time']\n",
      "[2, 'result_summary', 'summary of the results']\n",
      "[2, 'level_significance', 'significance level']\n",
      "[2, 'differ_term', 'differ in terms']\n",
      "[2, 'differ_result', 'differ from the result']\n",
      "[2, 'experiment_prematureness', 'prematureness experiment']\n",
      "[2, 'audio_channel', 'audio channel']\n",
      "[2, 'cambridge_press_university', 'cambridge university press']\n",
      "[2, 'cscw_environments', 'cscw environments']\n",
      "[2, 'j._s.', 'j. s.']\n",
      "[2, 'communication_visual', 'visual communication']\n",
      "[2, 'computer_human_interaction', 'human computer interaction']\n",
      "[2, 'c._j.', 'j. c.']\n",
      "[2, 'machine_man', 'man machine']\n",
      "[2, 'feature_level_lowness', 'lowness level features']\n",
      "[2, 'columbia_university', 'columbia university']\n",
      "[2, 'datum_visual', 'visual data']\n",
      "[2, 'example_pictorial_query', 'query by pictorial examples']\n",
      "[2, 'database_visual', 'visual databases']\n",
      "[2, 'feature_level_lowness_visual', 'lowness level visual features']\n",
      "[2, 'database_picture_satellite', 'satellite picture databases']\n",
      "[2, 'image_indexing', 'image indexing']\n",
      "[2, 'differ_feature_visual', 'differ visual features']\n",
      "[2, 'matching_similarity', 'similarity matching']\n",
      "[2, 'accurate_object_segmentation', 'accurate object segmentation']\n",
      "[2, 'prominence_region', 'prominence regions']\n",
      "[2, 'distinctiveness_texture', 'distinctiveness textures']\n",
      "[2, 'similarity_texture', 'similarity texture']\n",
      "[2, 'feature_set', 'feature sets']\n",
      "[2, 'decomposition_wavelet', 'wavelet decomposition']\n",
      "[2, 'class_texture', 'texture classes']\n",
      "[2, 'completeness_set', 'completeness set']\n",
      "[2, 'analysis_discriminant_fisher_technique', 'fisher discriminant analysis technique']\n",
      "[2, 'distance_mahalanobis', 'mahalanobis distance']\n",
      "[2, 'block_image_neighboring', 'neighboring blocks within each image']\n",
      "[2, 'quad_structure_tree', 'quad tree structure']\n",
      "[2, 'distance_optimum_threshold', 'optimum distance threshold']\n",
      "[2, 'application_practice_such', 'practice applications such']\n",
      "[2, 'color_differ_space', 'differ color spaces']\n",
      "[2, 'color_histograms', 'color histograms']\n",
      "[2, 'color_intersection', 'color intersection']\n",
      "[2, 'color_extraction_region_singleness', 'singleness color region extraction']\n",
      "[2, 'color_histogram_indexing', 'color histogram indexing']\n",
      "[2, 'color_represent', 'represent color']\n",
      "[2, 'color_region', 'color regions']\n",
      "[2, 'color_region_singleness', 'singleness color regions']\n",
      "[2, 'datum_image_rawness', 'rawness image data']\n",
      "[2, 'application_specificity', 'specificity applications']\n",
      "[2, 'color_list_represent', 'represent color list']\n",
      "[2, 'distance_image', 'distance image']\n",
      "[2, 'color_indexing', 'color indexing']\n",
      "[2, 'differ_scale', 'differ scales']\n",
      "[2, 'detection_edge', 'edge detection']\n",
      "[2, 'domain_wavelet', 'wavelet domain']\n",
      "[2, 'edge_information', 'edge information']\n",
      "[2, 'link_split', 'split and link']\n",
      "[2, 'feature_otherness', 'otherness features']\n",
      "[2, 'color_pattern', 'color pattern']\n",
      "[2, 'differ_feature', 'differ features']\n",
      "[2, 'image_object', 'image objects']\n",
      "[2, 'extraction_feature_image', 'image feature extraction']\n",
      "[2, 'demand_testbed', 'demand testbed']\n",
      "[2, 'b_color', 'b color']\n",
      "[2, 'c_edge', 'c edge']\n",
      "[2, 'f._j.r._s_smith', 'j.r. smith and s f.']\n",
      "[2, 'pattern_recognition', 'pattern recognition']\n",
      "[2, 'ieee_pami_t', 'ieee t pami']\n",
      "[2, 'ieee_trans', 'ieee trans']\n",
      "[2, 'automatic_generation_index', 'automatic generation of such an index']\n",
      "[2, 'learning_unsupervised', 'unsupervised learning']\n",
      "[2, 'congress_dewey_library_system', 'library of congress system or dewey']\n",
      "[2, 'decimal_system', 'decimal system']\n",
      "[2, 'balance_difficultness', 'difficultness balance']\n",
      "[2, 'human_library_patron', 'human library patron']\n",
      "[2, 'foreseeable_future', 'foreseeable future']\n",
      "[2, 'datum_engineering', 'data engineering']\n",
      "[2, 'document_fullness_text', 'fullness text documents']\n",
      "[2, 'document_relatedness', 'relatedness documents']\n",
      "[2, 'richness_structure', 'richness structure']\n",
      "[2, 'web_wide_world', 'world wide web']\n",
      "[2, 'avail_information', 'information avail']\n",
      "[2, 'value_vary', 'vary values']\n",
      "[2, 'relevance_task', 'relevance to a task']\n",
      "[2, 'classical_test', 'classical tests']\n",
      "[2, 'conditionality_probability', 'conditionality probabilities']\n",
      "[2, 'hidden_variable', 'hidden variables']\n",
      "[2, 'assignment_possibility', 'possibility assignments']\n",
      "[2, 'combination_possibility', 'possibility combinations']\n",
      "[2, 'assumption_underlying', 'underlying assumptions']\n",
      "[2, 'binary_variable', 'binary variables']\n",
      "[2, 'document_many', 'many documents']\n",
      "[2, 'machine_specialized', 'specialized machine']\n",
      "[2, 'library_patron', 'library patrons']\n",
      "[2, 'inductive_learning', 'inductive learning']\n",
      "[2, 'cluster_summary', 'cluster summary']\n",
      "[2, 'keyword_particularity', 'particularity keyword']\n",
      "[2, 'common_word', 'common words']\n",
      "[2, 'directory_yahoo', 'yahoo directory']\n",
      "[2, 'artificial_intelligence_journal_research', 'journal of artificial intelligence research']\n",
      "[2, 'computer_programming', 'computer programming']\n",
      "[2, 'part_time', 'part time']\n",
      "[2, 'al_eisenstadt_et', 'eisenstadt et al']\n",
      "[2, 'key_role', 'key role']\n",
      "[2, 'program_work', 'program works']\n",
      "[2, 'client_independence_platform_software', 'platform independence software for the client']\n",
      "[2, 'approach_appropriateness_stage', 'stage appropriateness approach']\n",
      "[2, 'great_number', 'greater number']\n",
      "[2, 'algorithm_animation_system', 'algorithm animation systems']\n",
      "[2, 'brayshaw_eisenstadt', 'eisenstadt and brayshaw']\n",
      "[2, 'al_domingue_et', 'domingue et al']\n",
      "[2, 'education_experience', 'education experience']\n",
      "[2, 'learning_process', 'learning process']\n",
      "[2, 'machine_prolog_transparence', 'transparence prolog machine']\n",
      "[2, 'differ_kind', 'differ kinds']\n",
      "[2, 'display_sv', 'sv display']\n",
      "[2, 'implicitness_information', 'implicitness information']\n",
      "[2, 'notation_secondary', 'secondary notation']\n",
      "[2, 'explicitness_information', 'explicitness information']\n",
      "[2, 'expert_sv', 'expert sv']\n",
      "[2, 'open_university', 'open university']\n",
      "[2, 'overview_strategy', 'overview strategy']\n",
      "[2, 'execution_large_space', 'larger execution spaces']\n",
      "[2, 'server_structure', 'structures on the server']\n",
      "[2, 'button_control_panel', 'button in the control panel']\n",
      "[2, 'control_panel', 'control panel']\n",
      "[2, 'currency_page_student', 'currency students page']\n",
      "[2, 'low_split', 'lower split']\n",
      "[2, 'school_summer_virtual', 'virtual summer school']\n",
      "[2, 'algorithm_level', 'algorithm level']\n",
      "[2, 'own_work', 'own work']\n",
      "[2, 'h._m.', 'm. h.']\n",
      "[2, 'h._m._t.', 'm. t. h.']\n",
      "[2, 'artificial_conference_intelligence', 'conference on artificial intelligence']\n",
      "[2, 'block_concept_edit_string', 'concept of string block edit']\n",
      "[2, 'certain_phenomenon', 'certain phenomena']\n",
      "[2, 'application_importance_reality_world', 'importance reality world applications']\n",
      "[2, 'basic_problem', 'basic problem']\n",
      "[2, 'family_variation', 'family of variations']\n",
      "[2, 'biology_molecule', 'molecule biology']\n",
      "[2, 'paper_prematureness', 'prematureness paper']\n",
      "[2, 'computing_pen', 'pen computing']\n",
      "[2, 'distance_edit_simpleness', 'simpleness edit distance']\n",
      "[2, 'long_sequence', 'longer sequences']\n",
      "[2, 'avail_tool', 'avail tool']\n",
      "[2, 'high_level_structure', 'higher level structure']\n",
      "[2, 'dog_laziness', 'laziness dog']\n",
      "[2, 'block_t', 't block']\n",
      "[2, 'substring_t', 't substrings']\n",
      "[2, 'problem_sameness', 'sameness problem']\n",
      "[2, 'block_distance_edit_problem', 'block edit distance problem']\n",
      "[2, 'lateness_section', 'lateness section']\n",
      "[2, 'membership_np', 'membership in np']\n",
      "[2, 'hardness_np', 'np hardness']\n",
      "[2, 'deadline_late', 'latest deadline']\n",
      "[2, 'copy_template', 'copy of the template']\n",
      "[2, 'block_such', 'such block']\n",
      "[2, '1)th_block_character_s01', '1)th block of 2n characters in s01']\n",
      "[2, 'step_substring_time', 'time step substring']\n",
      "[2, 'definition_dist', 'definition of dist']\n",
      "[2, 'job_substring', 'job substring']\n",
      "[2, 'character_first', 'first 2n characters']\n",
      "[2, '#_string', 'string #']\n",
      "[2, 'slot_time', 'time slot']\n",
      "[2, 'cost_cover_disjoint', 'cost disjoint cover']\n",
      "[2, 'proof_theorem', 'proof of theorem']\n",
      "[2, 'reduction_sameness', 'sameness reduction']\n",
      "[2, 'distance_problem', 'distance problems']\n",
      "[2, 'job_step_time', 'time steps and jobs']\n",
      "[2, 'distance_match_measure_validity', 'distance measure so that a validity match']\n",
      "[2, 'match_such', 'such match']\n",
      "[2, 'algorithm_cd_cd_m(i', 'algorithm cd cd m(i']\n",
      "[2, 'o(m2_t', 'o(m2 + t']\n",
      "[2, 'o(m2_time', 'o(m2 time']\n",
      "[2, 'o(mn_time', 'time o(mn']\n",
      "[2, 'open_question', 'open question']\n",
      "[2, 'appropriateness_means', 'appropriateness means']\n",
      "[2, 'differ_empiricism_technique', 'differ empiricism techniques']\n",
      "[2, 'externality_validity', 'externality validity']\n",
      "[2, 'practice_unsupported', 'unsupported practice']\n",
      "[2, 'controlled_investigation', 'controlled investigation']\n",
      "[2, 'experience_object', 'experience object']\n",
      "[2, 'highness_level_system_understanding', 'highness level system understanding']\n",
      "[2, 'issue_otherness', 'otherness issues']\n",
      "[2, 'experiment_laboratory', 'laboratory experiments']\n",
      "[2, 'collateral_power', 'collateral power']\n",
      "[2, 'group_user_wide', 'wider user group']\n",
      "[2, 'externality_replication', 'externality replication']\n",
      "[2, 'productivity_software', 'software productivity']\n",
      "[2, 'defect_efficiency_removal', 'defect removal efficiency']\n",
      "[2, 'component_reuse', 'component reuse']\n",
      "[2, 'huitt_wilde', 'wilde and huitt']\n",
      "[2, 'object_problem', 'problems with object']\n",
      "[2, 'evidence_initial', 'initial evidence']\n",
      "[2, 'concept_entropy', 'concept entropy']\n",
      "[2, 'interviewing_structured', 'structured interviewing']\n",
      "[2, 'knowledge_own', 'own knowledge']\n",
      "[2, 'datum_verb', 'verb data']\n",
      "[2, 'datum_quantitative', 'quantitative data']\n",
      "[2, 'invocation_method', 'method invocations']\n",
      "[2, 'class_x', 'class x']\n",
      "[2, 'program_understanding', 'program understanding']\n",
      "[2, 'newness_problem', 'newness problems']\n",
      "[2, 'bush_ponder', 'ponder and bush']\n",
      "[2, 'few_instance', 'few instances']\n",
      "[2, 'method_smallness', 'smallness methods']\n",
      "[2, 'software_tool', 'software tools']\n",
      "[2, 'initial_interview', 'initial interview']\n",
      "[2, 'majority_subject', 'majority of subjects']\n",
      "[2, 'curve_learning', 'learning curve']\n",
      "[2, 'several_subject', 'several subjects']\n",
      "[2, 'hybrid_language', 'hybrid languages']\n",
      "[2, 'm_subject', 'subject m']\n",
      "[2, 'design_documentation', 'design documentation']\n",
      "[2, 'k_subject', 'subject k']\n",
      "[2, 'similarity_statement', 'similarity statements']\n",
      "[2, 'otherness_system', 'otherness systems']\n",
      "[2, 'class_relationship', 'class relationships']\n",
      "[2, 'member_variable', 'member variables']\n",
      "[2, 'case_common', 'common case']\n",
      "[2, 'badness_design', 'badness design']\n",
      "[2, 'fix_quickness', 'quickness fix']\n",
      "[2, 'h_k_subject', 'subjects h and k']\n",
      "[2, 'system_understanding', 'system understanding']\n",
      "[2, 'inheritance_singleness', 'singleness inheritance']\n",
      "[2, 'equivalent_program_structured', 'equivalent structured programs']\n",
      "[2, 'mindset_object', 'object mindset']\n",
      "[2, 'more_object', 'more object']\n",
      "[2, 'practice_programming', 'programming practice']\n",
      "[2, 'goodness_practice_programming', 'goodness programming practice']\n",
      "[2, 'degradation_software', 'software degradation']\n",
      "[2, 'a_brooks', 'a brooks']\n",
      "[2, 'daly_j', 'j daly']\n",
      "[2, 'j_miller', 'j miller']\n",
      "[2, 'm_roper', 'm roper']\n",
      "[2, 'm_wood', 'm wood']\n",
      "[2, 'conference_ieee_international_proceeding', 'proceedings of the ieee international conference']\n",
      "[2, 'maintenance_object_support', 'maintenance support for object']\n",
      "[2, 'accuracy_generalization_high', 'highest generalization accuracy']\n",
      "[2, 'instance_training', 'instance in the training']\n",
      "[2, 'instance_newness_reduction_technique', 'newness instance reduction techniques']\n",
      "[2, 'dataset_experiment', 'experiments on 29 datasets']\n",
      "[2, 'condensed_nearest_neighbor_rule', 'condensed nearest neighbor rule']\n",
      "[2, 'instance_s.', 'instances in s.']\n",
      "[2, 'accuracy_high', 'higher accuracy']\n",
      "[2, 'instance_s', 'instance from s']\n",
      "[2, 'instance_otherness', 'otherness instances']\n",
      "[2, 'boundary_decision_smooth', 'smoother decision boundaries']\n",
      "[2, 'internal_point', 'internal points']\n",
      "[2, 'algorithm_wilson?s', 'wilson?s algorithm']\n",
      "[2, 'k_nn', 'k nn']\n",
      "[2, 'algorithm_learning', 'learning algorithms']\n",
      "[2, 'algorithm_tibl', 'tibl algorithm']\n",
      "[2, 'encoding_heuristic_length', 'encoding length heuristic']\n",
      "[2, 'instance_near', 'nearest two instances']\n",
      "[2, 'accuracy_classification', 'classification accuracy']\n",
      "[2, 'observation_several', 'several observations']\n",
      "[2, 'algorithm_reduction', 'reduction algorithm']\n",
      "[2, 'k_value', 'value of k']\n",
      "[2, 'direction_search', 'direction of search']\n",
      "[2, 'algorithm_decremental', 'decremental algorithms']\n",
      "[2, 'cluster_entireness', 'entireness clusters']\n",
      "[2, 'class_own', 'own class']\n",
      "[2, 'instance_reduction_technique', 'instance reduction techniques']\n",
      "[2, 'border_closeness_point', 'closeness border points']\n",
      "[2, 'instance_many', 'many instances']\n",
      "[2, 'attribute_nominal', 'nominal attributes']\n",
      "[2, 'instance_p', 'instance p']\n",
      "[2, 'accuracy_generalization_highness', 'highness generalization accuracy']\n",
      "[2, 'class_p.ai_sameness', 'sameness class as p.ai']\n",
      "[2, 'class_differ_p.ai', 'differ class than p.ai']\n",
      "[2, 'level_sameness', 'sameness level']\n",
      "[2, 'potency_problem', 'potency problem']\n",
      "[2, 'input_space', 'input space']\n",
      "[2, 'order_removal', 'order of removal']\n",
      "[2, 'noise_point', 'noise point']\n",
      "[2, 'algorithm_knn', 'knn algorithm']\n",
      "[2, 'dataset_vowel', 'vowel dataset']\n",
      "[2, 'developer_software', 'developers of software']\n",
      "[2, 'culture_otherness', 'cultures otherness']\n",
      "[2, 'culture_differ', 'differ cultures']\n",
      "[2, 'such_text', 'such text']\n",
      "[2, 'culture_element', 'culture elements']\n",
      "[2, 'output_text', 'output text']\n",
      "[2, 'case_upper', 'upper case']\n",
      "[2, 'case_low', 'lower case']\n",
      "[2, 'sameness_thing', 'sameness thing']\n",
      "[2, 'locale_part_specificity', 'locale specificity part']\n",
      "[2, 'guide_open_portability', 'open portability guide']\n",
      "[2, 'nls_ultrix', 'ultrix nls']\n",
      "[2, 'goodness_knowledge', 'goodness knowledge']\n",
      "[2, 'directness_translation', 'directness translation']\n",
      "[2, 'argument_runtime', 'runtime arguments']\n",
      "[2, 'parameter_specification', 'parameter specifications']\n",
      "[2, 'achievement_methodology', 'methodology achievements']\n",
      "[2, 'expert_generation_second_system', 'second generation expert systems']\n",
      "[2, 'first_principle', 'first principles']\n",
      "[2, 'knowledge_surface', 'surface knowledge']\n",
      "[2, 'abstract_knowledge_structure', 'abstract knowledge structures']\n",
      "[2, 'surface_system', 'surface systems']\n",
      "[2, 'specification_task', 'specification of the tasks']\n",
      "[2, 'abstract_description_task', 'abstract task descriptions']\n",
      "[2, 'differ_level', 'differ levels']\n",
      "[2, 'class_meta', 'meta classes']\n",
      "[2, 'knowledge_task', 'task knowledge']\n",
      "[2, 'al_et_patil', 'patil et al']\n",
      "[2, 'domain_medical', 'medical domain']\n",
      "[2, 'approach_kads', 'kads approach']\n",
      "[2, 'interpretation_model', 'interpretation models']\n",
      "[2, 'design_model', 'design model']\n",
      "[2, 'classification_heuristic', 'heuristic classification']\n",
      "[2, 'acquisition_knowledge_process', 'knowledge acquisition process']\n",
      "[2, 'control_strategy', 'control strategy']\n",
      "[2, 'expert_first_generation_system', 'first generation expert systems']\n",
      "[2, 'differ_domain', 'differ domains']\n",
      "[2, 'most_system', 'most systems']\n",
      "[2, 'i._mozetic', 'mozetic i.']\n",
      "[2, 'breuker_j.a.', 'breuker j.a.']\n",
      "[2, 'g._schreiber', 'schreiber g.']\n",
      "[2, 'b._bredeweg', 'bredeweg b.']\n",
      "[2, 'hayward_s.a.', 'hayward s.a.']\n",
      "[2, 'bylander_t.', 'bylander t.']\n",
      "[2, '10th_conference_international_joint', '10th international joint conference']\n",
      "[2, 'cis_lair_osu_technical', 'osu cis lair technical']\n",
      "[2, 'engineering_knowledge_review', 'knowledge engineering review']\n",
      "[2, 'davis_r.', 'davis r.']\n",
      "[2, 'conference_national_third', 'third national conference']\n",
      "[2, 'kaufmann_william', 'william kaufmann']\n",
      "[2, 'artificial_intelligence_medicine', 'artificial intelligence in medicine']\n",
      "[2, 'b.j._wielinga', 'wielinga b.j.']\n",
      "[2, 'conference_european_second', 'second european conference']\n",
      "[2, 'e.t._keravnou', 'keravnou e.t.']\n",
      "[2, 'j._washbrook', 'washbrook j.']\n",
      "[2, 'j.de_kleer', 'kleer j.de']\n",
      "[2, 'r._reiter', 'reiter r.']\n",
      "[2, 'marcus_s.(ed', 'marcus s.(ed']\n",
      "[2, 'acquisition_automating_knowledge', 'automating knowledge acquisition']\n",
      "[2, 'ai_magazine', 'ai magazine']\n",
      "[2, 'p._szolovits', 'szolovits p.']\n",
      "[2, 'schwartz_w.b.', 'schwartz w.b.']\n",
      "[2, 'diagnosis_medical', 'medical diagnosis']\n",
      "[2, 'press_westview', 'westview press']\n",
      "[2, 'b._wielinga', 'wielinga b.']\n",
      "[2, 'based_model_reasoning', 'model based reasoning']\n",
      "[2, 'particularity_piece', 'particularity pieces']\n",
      "[2, 'currency_task', 'currency task']\n",
      "[2, 'declare_representation', 'declare representations']\n",
      "[2, 'drug_smuggling', 'drug smuggling']\n",
      "[2, 'agent_reason', 'agent reasons']\n",
      "[2, 'concept_memory', 'concept memory']\n",
      "[2, 'index_newness', 'newness index']\n",
      "[2, 'method_particularity_reasoning', 'particularity reasoning methods']\n",
      "[2, 'introspect_meta_xps', 'introspect meta xps']\n",
      "[2, 'assignment_blame', 'blame assignment']\n",
      "[2, 'error_reasoning', 'reasoning error']\n",
      "[2, 'cause_explanation', 'cause explanations']\n",
      "[2, 'animateness_object', 'animateness objects']\n",
      "[2, 'process_understanding', 'understanding process']\n",
      "[2, 'composite_meta_xp', 'composite meta xp']\n",
      "[2, 'indexedstructure_mis_xp', 'xp mis indexedstructure']\n",
      "[2, 'incorrectworld_model_xp', 'xp incorrectworld model']\n",
      "[2, 'coherence_concept', 'concept coherence']\n",
      "[2, 'nodes_pre_xp', 'pre xp nodes']\n",
      "[2, 'asserted_node_xp-', 'xp- asserted node']\n",
      "[2, 'currency_implementation', 'currency implementation']\n",
      "[2, 'algorithm_understanding', 'understanding algorithm']\n",
      "[2, 'generation_hypothesis_strategy', 'strategies for hypothesis generation']\n",
      "[2, 'reasoning_task', 'reasoning task']\n",
      "[2, 'asserted_nodes_xp', 'xp asserted nodes']\n",
      "[2, 'decision_model', 'decision models']\n",
      "[2, 'story_understanding', 'story understanding']\n",
      "[2, 'avail_strategy', 'avail strategies']\n",
      "[2, 'a_node', 'node a']\n",
      "[2, 'a_e', 'a and e']\n",
      "[2, 'co_domain_figure', 'co - domain figure']\n",
      "[2, 'item_memory', 'item in memory']\n",
      "[2, 'co_domain_domain_falsifie', 'falsifies domain co - domain']\n",
      "[2, 'annual_conference_sixth', 'sixth annual conference']\n",
      "[2, 'conference_international_seventh', 'seventh international conference']\n",
      "[2, 'university_yale', 'yale university']\n",
      "[2, 'haven_new', 'new haven']\n",
      "[2, 'based_case_reasoning', 'case based reasoning']\n",
      "[2, 'class_dictionary_graph_propagation', 'class dictionary graphs and propagation']\n",
      "[2, 'class_repetition', 'repetition class']\n",
      "[2, 'class_several', 'several classes']\n",
      "[2, 'department_name', 'name and departments']\n",
      "[2, 'class_department', 'department class']\n",
      "[2, 'c_v', 'v c']\n",
      "[2, 'salary_value', 'salary value']\n",
      "[2, 'message_request', 'message request']\n",
      "[2, 'request_sumsal', 'sumsal request']\n",
      "[2, 'class_responsibility', 'responsibility each class']\n",
      "[2, 'class_importance', 'importance classes']\n",
      "[2, 'message_trivia', 'trivia message']\n",
      "[2, 'change_class_structure', 'class structure changes']\n",
      "[2, 'interface_statement', 'interface statement']\n",
      "[2, 'message_sumsal', 'sumsal message']\n",
      "[2, 'name_part', 'name part']\n",
      "[2, 'class_dictionary_edge_set', 'set of edges in the class dictionary']\n",
      "[2, 'form_text', 'text form']\n",
      "[2, 'employee_part', 'employees part']\n",
      "[2, 'corresponding_graph_propagation', 'corresponding propagation graph']\n",
      "[2, 'edge_singleness', 'singleness edge']\n",
      "[2, 'target_vertex', 'target vertex']\n",
      "[2, 'otherness_relationship', 'otherness relationships']\n",
      "[2, 'class_company_dictionary_graph', 'class dictionary graph for companies']\n",
      "[2, 'class_conglomerate', 'conglomerate class']\n",
      "[2, 'vertex_w', 'vertex w']\n",
      "[2, 'graph_original_propagation', 'original propagation graph']\n",
      "[2, 'evolution_schema', 'schema evolution']\n",
      "[2, 'j._karl_lieberherr', 'karl j. lieberherr']\n",
      "[3, 'knowledge_priority', 'priority knowledge']\n",
      "[3, 'original_suite_test', 'original test suite']\n",
      "[3, 'problem_regression_selection_test', 'regression test selection problem']\n",
      "[3, 'selection_technique_test', 'test selection techniques']\n",
      "[3, 'conditionality_statement', 'conditionality statements']\n",
      "[3, 'method_otherness', 'otherness methods']\n",
      "[3, 'paper_remainder', 'remainder of this paper']\n",
      "[3, 'cost_regression_testing', 'cost of regression testing']\n",
      "[3, 'problem_several', 'several problems']\n",
      "[3, 'et_execution_trace', 'execution trace et']\n",
      "[3, 'comparison_pairwise', 'pairwise comparison']\n",
      "[3, 'first_pair', 'first pair']\n",
      "[3, 'algorithm_selection_test', 'test selection algorithms']\n",
      "[3, 'location_memory', 'memory locations']\n",
      "[3, 'algorithm_naiveness', 'naiveness algorithm']\n",
      "[3, 'entry_procedure', 'entry procedures']\n",
      "[3, 'history_information_test', 'test history information']\n",
      "[3, 'code_source', 'source code']\n",
      "[3, 'program_version', 'program version']\n",
      "[3, 'researcher_siemens', 'siemens researchers']\n",
      "[3, 'percentage_test', 'percentage of tests']\n",
      "[3, 'second_study', 'second study']\n",
      "[3, 'functionality_test', 'functionality tests']\n",
      "[3, 'player_program', 'player program']\n",
      "[3, 'replace_version', 'versions of replace']\n",
      "[3, 'goodness_reason', 'goodness reasons']\n",
      "[3, 'futurity_work', 'futurity work']\n",
      "[3, 'horwitz_s.', 's. horwitz']\n",
      "[3, 'software_testing', 'software testing']\n",
      "[3, 'd._hoffman', 'd. hoffman']\n",
      "[3, 'hartmann_j.', 'j. hartmann']\n",
      "[3, 'acm_communication', 'communications of the acm']\n",
      "[3, 'conference_proceedings', 'conference proceedings']\n",
      "[3, 'empiricism_technique', 'empiricism techniques']\n",
      "[3, 'module_object', 'object module']\n",
      "[3, 'automaton_virtual', 'virtual automaton']\n",
      "[3, 'highness_language_level', 'highness level language']\n",
      "[3, 'sameness_way', 'sameness way']\n",
      "[3, 'more_time', 'more times']\n",
      "[3, 'international_sri', 'sri international']\n",
      "[3, 'information_more', 'more information']\n",
      "[3, 'overall_structure', 'overall structure']\n",
      "[3, 'perspective_wall', 'perspective wall']\n",
      "[3, 'additional_information', 'additional information']\n",
      "[3, 'datum_hierarchy', 'hierarchy data']\n",
      "[3, 'brown_university', 'brown university']\n",
      "[3, 'memory_multiprocessor', 'memory multiprocessors']\n",
      "[3, 'consistency_laziness_release', 'laziness release consistency']\n",
      "[3, 'similarity_technique', 'similarity techniques']\n",
      "[3, 'hardware_support', 'hardware support']\n",
      "[3, 'bit_page_protection_table', 'protection bits of all page table']\n",
      "[3, 'status_word', 'status word']\n",
      "[3, 'access_release', 'release access']\n",
      "[3, 'physicality_space', 'physicality space']\n",
      "[3, 'byte_k', 'k bytes']\n",
      "[3, 'event_synchronization', 'synchronization events']\n",
      "[3, 'good_speedup', 'better speedups']\n",
      "[3, 'large_page', 'larger pages']\n",
      "[3, 'advantage_several', 'several advantages']\n",
      "[3, 'james_laudon', 'james laudon']\n",
      "[3, 'logic_variable', 'logic variables']\n",
      "[3, 'object_otherness', 'otherness object']\n",
      "[3, 'otherness_side', 'otherness side']\n",
      "[3, 'large_number', 'large number']\n",
      "[3, 'newness_state', 'newness state']\n",
      "[3, 'logicality_semantic', 'logicality semantics']\n",
      "[3, 'logic_transaction', 'transaction logic']\n",
      "[3, 'issue_monotonicity', 'monotonicity issues']\n",
      "[3, 'calculus_event', 'event calculus']\n",
      "[3, 'base_transition', 'transition base']\n",
      "[3, 'identifier_object', 'object identifiers']\n",
      "[3, 'hierarchy_inheritance', 'inheritance hierarchy']\n",
      "[3, 'process_proof', 'proof process']\n",
      "[3, 'concurrent_prolog', 'concurrent prolog']\n",
      "[3, 'clause_head', 'head of the clause']\n",
      "[3, 'method_specificity', 'specificity method']\n",
      "[3, 'awareness_resource', 'resource awareness']\n",
      "[3, 'particularity_style', 'particularity style']\n",
      "[3, 'coincide_programming', 'coincide programming']\n",
      "[3, 'rewrite_rule', 'rewrite rule']\n",
      "[3, 'aci_operation', 'aci operation']\n",
      "[3, 'importance_point', 'importance point']\n",
      "[3, 'database_principle', 'principles of database']\n",
      "[3, 'notices_sigplan', 'sigplan notices']\n",
      "[3, 'c._delobel', 'c. delobel']\n",
      "[3, 'conery_j._s.', 'j. s. conery']\n",
      "[3, 'a._davison', 'a. davison']\n",
      "[3, 'cerro_del_fari~nas_l.', 'l. fari~nas del cerro']\n",
      "[3, 'academic_press', 'academic press']\n",
      "[3, 'linearity_logic', 'linearity logic']\n",
      "[3, 'anonymity_avail_duck.dfki.uni-sb.de_ftp', 'avail by anonymity ftp from duck.dfki.uni-sb.de']\n",
      "[3, 'jungclaus_r.', 'r. jungclaus']\n",
      "[3, 'conference_european_object', 'european conference on object']\n",
      "[3, 'c_split', 'split c']\n",
      "[3, 'regularity_sampling', 'regularity sampling']\n",
      "[3, 'algorithm_parallel', 'parallel algorithms']\n",
      "[3, 'element_th', 'th element']\n",
      "[3, 'benchmark_integer_manner_value', 'integer benchmark values in the manner']\n",
      "[3, 'integer_m', 'm integers']\n",
      "[3, 'ix_table', 'table ix']\n",
      "[3, 'declustering_method_system', 'system declustering methods']\n",
      "[3, 'declustering_randomness', 'randomness declustering']\n",
      "[3, 'balancing_dynamism_load', 'dynamism load balancing']\n",
      "[3, 'information_system', 'information systems']\n",
      "[3, 'reality_terrain_time_visualization', 'reality time terrain visualization']\n",
      "[3, 'hpgis_unit', 'hpgis unit']\n",
      "[3, 'gis_problem', 'gis problems']\n",
      "[3, 'transfer_work', 'work transfer']\n",
      "[3, 'cost_preprocessing', 'preprocessing cost']\n",
      "[3, 'chunk_size', 'chunk size']\n",
      "[3, 'algorithm_pram', 'pram algorithms']\n",
      "[3, 'architecture_uma', 'uma architectures']\n",
      "[3, 'data_engineering', 'data engineering']\n",
      "[3, 'class_interconnectedness', 'interconnectedness classes']\n",
      "[3, 'family_program', 'program families']\n",
      "[3, 'corporation_digital_equipment', 'digital equipment corporation']\n",
      "[3, 'class_container', 'container class']\n",
      "[3, 'detail_implementation', 'implementation details']\n",
      "[3, 'component_p++', 'p++ components']\n",
      "[3, 'interconnection_language_module', 'module interconnection languages']\n",
      "[3, 'constancy_parameter_type', 'constancy and type parameters']\n",
      "[3, 'r_realm', 'realm r']\n",
      "[3, 'object_t', 't objects']\n",
      "[3, 'c++_template', 'c++ templates']\n",
      "[3, 'abstraction_datum', 'data abstraction']\n",
      "[3, 'ansi_c', 'ansi c']\n",
      "[3, 'singhal_vivek', 'vivek singhal']\n",
      "[3, 'final_grammar', 'final grammar']\n",
      "[3, 'hemingway_parody', 'hemingway parody']\n",
      "[3, 'category_lexis', 'lexis categories']\n",
      "[3, 'category_symbol', 'category symbols']\n",
      "[3, 'control_information', 'information control']\n",
      "[3, 'erlbaum_lawrence', 'lawrence erlbaum']\n",
      "[3, 'h._ian_witten', 'ian h. witten']\n",
      "[3, 'early_study', 'earlier study']\n",
      "[3, 'decision_making', 'decision making']\n",
      "[3, 'group_large', 'larger groups']\n",
      "[3, 'aspect_importance', 'importance aspects']\n",
      "[3, 'meeting_remoteness', 'remoteness meetings']\n",
      "[3, 'jigsaw_puzzle', 'jigsaw puzzles']\n",
      "[3, 'area_body_upper', 'upper body area']\n",
      "[3, 'singleness_tape_video', 'singleness video tape']\n",
      "[3, 'tape_video', 'video tapes']\n",
      "[3, 'analysis_result', 'results of these analyses']\n",
      "[3, 'g._m.', 'g. m.']\n",
      "[3, 'international_journal', 'international journal']\n",
      "[3, 'content_visual', 'visual content']\n",
      "[3, 'content_image', 'image contents']\n",
      "[3, 'key_texture', 'texture key']\n",
      "[3, 'query_texture', 'query by texture']\n",
      "[3, 'discrimination_texture', 'texture discrimination']\n",
      "[3, 'extraction_region_texture', 'texture region extraction']\n",
      "[3, 'bank_filter_gabor', 'gabor filter banks']\n",
      "[3, 'transform_wavelet', 'wavelet transform']\n",
      "[3, 'element_feature', 'feature elements']\n",
      "[3, 'discriminant_function', 'discriminant function']\n",
      "[3, 'database_image_medical', 'medical image databases']\n",
      "[3, 'b_figure', 'b figure']\n",
      "[3, 'node_quad_tree', 'quad tree node']\n",
      "[3, 'color_differ', 'differ colors']\n",
      "[3, 'color_pair', 'color pairs']\n",
      "[3, 'differ_way', 'differ ways']\n",
      "[3, 'importance_issue', 'importance issue']\n",
      "[3, 'edge_point', 'edge points']\n",
      "[3, 'block_image', 'image block']\n",
      "[3, 'edge_missing_segment', 'missing edge segment']\n",
      "[3, 'database_ii_systems_visual', 'visual database systems ii']\n",
      "[3, 'ieee_information_theory_transaction', 'ieee transactions on information theory']\n",
      "[3, 'document_newness', 'newness documents']\n",
      "[3, 'document_language_naturalness', 'naturalness language documents']\n",
      "[3, 'learning_method', 'learning method']\n",
      "[3, 'library_tradition', 'tradition library']\n",
      "[3, 'document_fullness_ijcai-95_text', 'fullness text documents ijcai-95']\n",
      "[3, 'factor_more', 'more factors']\n",
      "[3, 'observe_variable', 'observe variables']\n",
      "[3, 'cluster_document', 'cluster of documents']\n",
      "[3, 'assignment_probability', 'probability assignment']\n",
      "[3, 'order_randomness', 'randomness order']\n",
      "[3, 'document_similarity', 'documents similarity']\n",
      "[3, 'part_phrase', 'part phrases']\n",
      "[3, 'information_retrieval', 'information retrieval']\n",
      "[3, 'idea_key', 'key ideas']\n",
      "[3, 'list_stop', 'stop list']\n",
      "[3, 'asynchronous_communication', 'asynchronous communication']\n",
      "[3, 'environment_isvl', 'isvl environment']\n",
      "[3, 'acm_press', 'acm press']\n",
      "[3, 'distance_edit', 'edit distance']\n",
      "[3, 'matching_string', 'string matching']\n",
      "[3, 'lemma_proof', 'proof of lemma']\n",
      "[3, 'matrix_w', 'matrix w']\n",
      "[3, 'investigation_primary', 'primary investigation']\n",
      "[3, 'further_investigation', 'further investigation']\n",
      "[3, 'interview_template', 'interview template']\n",
      "[3, 'pressure_time', 'time pressures']\n",
      "[3, 'reuse_software', 'software reuse']\n",
      "[3, 'interview_transcript', 'interview transcript']\n",
      "[3, 'j_subject', 'subject j']\n",
      "[3, 'l_subject', 'subject l']\n",
      "[3, 'a_subject', 'subjects a']\n",
      "[3, 'g_subject', 'subject g']\n",
      "[3, 'd_subject', 'subject d']\n",
      "[3, 'inheritance_level', 'levels of inheritance']\n",
      "[3, 'corlett_e_j_wilson', 'j wilson and e corlett']\n",
      "[3, 'evaluation_human_work', 'evaluation of human work']\n",
      "[3, 'ergonomic_methodology_practice', 'practice ergonomics methodology']\n",
      "[3, 'francis_taylor', 'taylor and francis']\n",
      "[3, 'set_training', 'training set']\n",
      "[3, 'application_many', 'many applications']\n",
      "[3, 'algorithm_near_neighbor', 'nearest neighbor algorithm']\n",
      "[3, 'attribute_input', 'input attributes']\n",
      "[3, 'class_differ', 'differ class']\n",
      "[3, 'instance_typicality', 'typicality instance']\n",
      "[3, 'cameron_jones', 'cameron jones']\n",
      "[3, 's_subset', 'subset s']\n",
      "[3, 'instance_original', 'original instances']\n",
      "[3, 'rule_wilson?s', 'wilson?s rule']\n",
      "[3, 'low_requirement_storage', 'lower storage requirements']\n",
      "[3, 'original_training', 'original training']\n",
      "[3, 'accuracy_average_generalization', 'average generalization accuracy']\n",
      "[3, 'issue_many', 'many issues']\n",
      "[3, 'error_message', 'error messages']\n",
      "[3, 'del_galdo', 'del galdo']\n",
      "[3, 'externality_file', 'externality files']\n",
      "[3, 'string_text', 'text strings']\n",
      "[3, 'designing_interface_user', 'designing user interfaces']\n",
      "[3, 'expert_system', 'expert systems']\n",
      "[3, 'knowledge_level', 'knowledge level']\n",
      "[3, 'object_physicality', 'physicality objects']\n",
      "[3, 'inference_structure', 'inference structure']\n",
      "[3, 'domain_knowledge', 'domain knowledge']\n",
      "[3, 'method_reasoning', 'reasoning methods']\n",
      "[3, 'qualitative_simulation', 'qualitative simulation']\n",
      "[3, 'genus_task', 'genus task']\n",
      "[3, 'causal_modeling', 'causal modeling']\n",
      "[3, 'expert_systems', 'expert systems']\n",
      "[3, 'patil_r.s.', 'patil r.s.']\n",
      "[3, 'performance_task', 'performance task']\n",
      "[3, 'failure_type', 'failure types']\n",
      "[3, 'anomaly_situation', 'anomaly situation']\n",
      "[3, 'reasoning_trace', 'trace of the reasoning']\n",
      "[3, 'chain_reasoning', 'reasoning chain']\n",
      "[3, 'novelsituation_xp', 'xp novelsituation']\n",
      "[3, 'explains_node', 'explains node']\n",
      "[3, 'concept_input', 'input to the concept']\n",
      "[3, 'hayes_roth', 'hayes roth']\n",
      "[3, 'meta_xps', 'meta xps']\n",
      "[3, 'input_new_result', 'results new input']\n",
      "[3, 'chain_co_domain_domain', 'chain domain domain co']\n",
      "[3, 'actuality_outcome', 'actuality outcome']\n",
      "[3, 'class_evolution', 'class evolution']\n",
      "[3, 'cycle_life_software', 'software life cycle']\n",
      "[3, 'salary_totality_variable', 'salary totality variable']\n",
      "[3, 'v_vertex', 'vertex v']\n",
      "[3, 'interface_method', 'method interface']\n",
      "[3, 'change_class_dictionary_graph', 'change in the class dictionary graph']\n",
      "[3, 'newness_subclass', 'newness subclass']\n",
      "[4, 'such_test', 'such tests']\n",
      "[4, 'ohio_state_university', 'ohio state university']\n",
      "[4, 'next_section', 'next section']\n",
      "[4, 'node_predicate', 'predicate nodes']\n",
      "[4, 'exit_node', 'exit node']\n",
      "[4, 'cfg_node', 'cfg node']\n",
      "[4, 'variety_wideness', 'wideness variety']\n",
      "[4, 'result_test', 'test results']\n",
      "[4, 'phase_preliminary', 'preliminary phase']\n",
      "[4, 'algorithm_interprocedural_selection_test', 'interprocedural test selection algorithm']\n",
      "[4, 'execution_trace', 'execution trace']\n",
      "[4, 'prefix_trace_traversal', 'traversal trace prefixes']\n",
      "[4, 'algorithm_efficiency', 'efficiency algorithm']\n",
      "[4, 'number_test', 'number of tests']\n",
      "[4, 'name_procedure', 'procedure names']\n",
      "[4, 'bad_case', 'worst case']\n",
      "[4, 'multiple_version', 'multiple versions']\n",
      "[4, 'siemens_study', 'siemens study']\n",
      "[4, 'base_version', 'base version']\n",
      "[4, 'effort_totality', 'totality effort']\n",
      "[4, 'deviation_standard', 'standard deviation']\n",
      "[4, 'empiricism_work', 'empiricism work']\n",
      "[4, 'g._rothermel', 'g. rothermel']\n",
      "[4, 'ieee_software', 'ieee software']\n",
      "[4, 'call_function', 'function calls']\n",
      "[4, 'flesh_language', 'flesh language']\n",
      "[4, 'data_set', 'data sets']\n",
      "[4, 'behavior_object', 'object behavior']\n",
      "[4, 'question_such', 'such questions']\n",
      "[4, 'case_many', 'many cases']\n",
      "[4, 'compiler_support', 'compiler support']\n",
      "[4, 'cache_coherence_scheme', 'cache coherence schemes']\n",
      "[4, 'processor_system', 'processor system']\n",
      "[4, 'coherence_scheme', 'coherence schemes']\n",
      "[4, 'fault_page', 'page faults']\n",
      "[4, 'falsity_sharing', 'falsity sharing']\n",
      "[4, 'p1_processor', 'processor p1']\n",
      "[4, 'gain_performance', 'performance gains']\n",
      "[4, 'conference_international_parallel_proceeding', 'proceedings of the 1985 international conference on parallel']\n",
      "[4, 'object_orientation', 'object orientation']\n",
      "[4, 'logicality_object', 'logicality objects']\n",
      "[4, 'change_minimal', 'minimal change']\n",
      "[4, 'dynamic_logic', 'dynamic logic']\n",
      "[4, 'message_stream', 'message stream']\n",
      "[4, 'class_sameness', 'sameness class']\n",
      "[4, 'object_space', 'space objects']\n",
      "[4, 'many_way', 'many ways']\n",
      "[4, 'computing_generation_new', 'new generation computing']\n",
      "[4, 'report_research', 'research report']\n",
      "[4, 'j._meseguer', 'j. meseguer']\n",
      "[4, 'distribution_input', 'input distribution']\n",
      "[4, 'communication_primitive', 'communication primitives']\n",
      "[4, 'p_processor', 'p processors']\n",
      "[4, 'element_np', 'np elements']\n",
      "[4, 'pj_processor', 'processor pj']\n",
      "[4, 'pp_processor', 'processor pp']\n",
      "[4, 'randomness_value', 'randomness values']\n",
      "[4, 'complexity_computation', 'computation complexity']\n",
      "[4, 'run_time', 'run time']\n",
      "[4, 'computation_intersection', 'intersection computation']\n",
      "[4, 'idleness_processor', 'idleness processors']\n",
      "[4, 'datum_locality', 'locality data']\n",
      "[4, 'leader_processor', 'leader processor']\n",
      "[4, 'genvoca_model', 'genvoca model']\n",
      "[4, 'design_software', 'software design']\n",
      "[4, 'example_figure', 'example of figure']\n",
      "[4, 'component_realm', 'components and realms']\n",
      "[4, 'parameter_type', 'type parameters']\n",
      "[4, 'hierarchy_implementation', 'implementation hierarchies']\n",
      "[4, 'hierarchy_type', 'type hierarchies']\n",
      "[4, 'crowd_madding', 'madding crowd']\n",
      "[4, 'expression_sample', 'sample expressions']\n",
      "[4, 'communication_human_mode', 'human communication modes']\n",
      "[4, 'group_work', 'group work']\n",
      "[4, 'task_type', 'task type']\n",
      "[4, 'face_mode', 'face mode']\n",
      "[4, 'group_subject', 'subjects / between groups']\n",
      "[4, 'duration_totality', 'totality duration']\n",
      "[4, 'duration_session', 'session duration']\n",
      "[4, 'feature_visual', 'visual features']\n",
      "[4, 'database_image', 'image database']\n",
      "[4, 'image_query', 'image query']\n",
      "[4, 'image_region', 'image regions']\n",
      "[4, 'segmentation_texture', 'texture segmentation']\n",
      "[4, 'block_boundary', 'block boundaries']\n",
      "[4, 'francisco_san', 'san francisco']\n",
      "[4, 'keyword_otherness', 'otherness keywords']\n",
      "[4, 'software_visualization', 'software visualization']\n",
      "[4, 'computer_curriculum_programming', 'computer programming curriculum']\n",
      "[4, 'code_level', 'code level']\n",
      "[4, 'good_match', 'best match']\n",
      "[4, 'family_substring', 'substring family']\n",
      "[4, 'b_string', 'string b']\n",
      "[4, 'problem_scheduling', 'scheduling problem']\n",
      "[4, 'class_hierarchy', 'class hierarchies']\n",
      "[4, 'difficulty_understanding', 'understanding difficulties']\n",
      "[4, 'e_subject', 'subject e']\n",
      "[4, 'boundary_decision', 'decision boundaries']\n",
      "[4, 'enemy_near', 'nearest enemy']\n",
      "[4, 'newness_version', 'newness version']\n",
      "[4, 'file_message', 'message files']\n",
      "[4, 'interface_us', 'user interfaces']\n",
      "[4, 'domain_knowledge_principled', 'principled knowledge about the domain']\n",
      "[4, 'inference_step', 'inference steps']\n",
      "[4, 'applied_artificial_intelligence', 'applied artificial intelligence']\n",
      "[4, 'engineer_knowledge', 'knowledge engineer']\n",
      "[4, 'level_strategy', 'strategy level']\n",
      "[4, 'j._sticklen', 'sticklen j.']\n",
      "[4, 'hunter_j.', 'hunter j.']\n",
      "[4, 'l._steel', 'steels l.']\n",
      "[4, 'failure_reasoning', 'reasoning failure']\n",
      "[4, 'general_meta_xp', 'general meta xp']\n",
      "[4, 'explanation_pattern', 'explanation patterns']\n",
      "[4, 'novel_situation', 'novel situation']\n",
      "[4, 'mentally_outcome', 'outcome mentally']\n",
      "[4, 'co_domain_domain_domain', 'domain co - domain domain']\n",
      "[4, 'cognitive_science_society', 'cognitive science society']\n",
      "[4, 'class_construction', 'construction class']\n",
      "[4, 'class_v', 'class v']\n",
      "[4, 'class_newness_structure', 'newness class structure']\n",
      "[5, 'cost_overall', 'overall cost']\n",
      "[5, 'p_p', 'p and p']\n",
      "[5, 'currency_state', 'currency state']\n",
      "[5, 'language_such', 'such languages']\n",
      "[5, 'empiricism_result', 'empiricism results']\n",
      "[5, 'm.l._soffa', 'm.l. soffa']\n",
      "[5, 'relation_space', 'space relations']\n",
      "[5, 'computer_department_science', 'department of computer science']\n",
      "[5, 'consistency_sequence', 'sequence consistency']\n",
      "[5, 'differ_processor', 'differ processors']\n",
      "[5, 'i._page', 'page i.']\n",
      "[5, 'number_processor', 'number of processors']\n",
      "[5, 'synchronization_variable', 'synchronization variables']\n",
      "[5, 'buffer_write', 'write buffer']\n",
      "[5, 'hennessy_john', 'john hennessy']\n",
      "[5, 'stanford_university', 'stanford university']\n",
      "[5, 'approach_differ', 'differ approach']\n",
      "[5, 'possibility_world', 'possibility worlds']\n",
      "[5, 'literalness_object', 'object literalness']\n",
      "[5, 'literal_object', 'object literals']\n",
      "[5, 'currency_set', 'currency set']\n",
      "[5, 'report_technical', 'technical report']\n",
      "[5, 'development_software', 'software development']\n",
      "[5, 'k._kahn_m.', 'k. m. kahn']\n",
      "[5, 'input_size', 'input sizes']\n",
      "[5, 'input_value', 'input values']\n",
      "[5, 'number_point', 'point numbers']\n",
      "[5, 'cray_t3d', 'cray t3d']\n",
      "[5, 'benchmark_wr', 'wr benchmark']\n",
      "[5, 'address_architecture_space', 'address space architecture']\n",
      "[5, 'engine_graphic', 'graphics engine']\n",
      "[5, 'pool_size', 'pool size']\n",
      "[5, 'engineering_ieee_software', 'ieee transactions on software engineering']\n",
      "[5, 'distribution_probability', 'probability distribution']\n",
      "[5, 'cognitive_science', 'cognitive science']\n",
      "[5, 'communication_face_mode', 'face communication modes']\n",
      "[5, 'elsevier_science', 'elsevier science']\n",
      "[5, 'compression_image', 'image compression']\n",
      "[5, 'issue_special', 'special issue']\n",
      "[5, 'dorado_el', 'el dorado']\n",
      "[5, 'cd_cd', 'cd cd']\n",
      "[5, 'block_distance_edit', 'block edit distance']\n",
      "[5, 'h_subject', 'subject h']\n",
      "[5, 'c_subject', 'subject c']\n",
      "[5, 'input_vector', 'input vector']\n",
      "[5, 'reduction_technique', 'reduction technique']\n",
      "[5, 'domain_technique', 'technique domains']\n",
      "[5, 'process_reasoning', 'reasoning process']\n",
      "[5, 'prediction_successfulness', 'successfulness prediction']\n",
      "[5, 'c++_code', 'c++ code']\n",
      "[6, 'selection_test', 'test selection']\n",
      "[6, 'trace_traversal', 'traversal traces']\n",
      "[6, 'n_node', 'nodes n']\n",
      "[6, 'entry_node', 'entry nodes']\n",
      "[6, 'call_recursive', 'recursive calls']\n",
      "[6, 'flag_status', 'status flag']\n",
      "[6, 'experimental_result', 'experimental results']\n",
      "[6, 'addison_wesley', 'addison wesley']\n",
      "[6, 'c_compiler', 'c compiler']\n",
      "[6, 'effect_side', 'side effects']\n",
      "[6, 'interface_user', 'user interface']\n",
      "[6, 'acm_conf_sigchi', 'acm sigchi conf']\n",
      "[6, 'computing_factors_human', 'human factors in computing']\n",
      "[6, 'main_memory', 'main memory']\n",
      "[6, 'data_structure', 'data structure']\n",
      "[6, 'anoop_gupta', 'anoop gupta']\n",
      "[6, 'change_state', 'state change']\n",
      "[6, 'object_state', 'object state']\n",
      "[6, 'r_t', 't r']\n",
      "[6, 'ibm_sp-2-wn', 'ibm sp-2-wn']\n",
      "[6, 'balance_load', 'load balance']\n",
      "[6, 'datum_double_type', 'double data type']\n",
      "[6, 'datum_space', 'space data']\n",
      "[6, 'component_composition', 'component composition']\n",
      "[6, 'computer_program', 'computer programs']\n",
      "[6, 'language_naturalness', 'naturalness language']\n",
      "[6, 'feature_map', 'feature map']\n",
      "[6, 'factor_value', 'factor values']\n",
      "[6, 'a_string', 'strings a']\n",
      "[6, 'cover_disjoint', 'disjoint cover']\n",
      "[6, 'cost_function', 'cost function']\n",
      "[6, 'acquisition_knowledge', 'knowledge acquisition']\n",
      "[6, 'binding_dynamism', 'dynamism binding']\n",
      "[6, 'b_subject', 'subjects b']\n",
      "[6, 'requirement_storage', 'storage requirements']\n",
      "[6, 'center_point', 'center points']\n",
      "[6, 'international_use', 'international use']\n",
      "[6, 'concept_model', 'concept model']\n",
      "[6, 'failure_retrieval', 'retrieval failure']\n",
      "[7, 'retest_select_technique', 'select retest techniques']\n",
      "[7, 'p_procedure', 'procedure p']\n",
      "[7, 'software_system', 'software systems']\n",
      "[7, 'language_programming', 'programming languages']\n",
      "[7, 'concreteness_syntax', 'concreteness syntax']\n",
      "[7, 'datum_structure', 'data structures']\n",
      "[7, 'execution_time_totality', 'totality execution time']\n",
      "[7, 'mit_press', 'mit press']\n",
      "[7, 'computer_ieee_press_society', 'ieee computer society press']\n",
      "[7, 'hall_prentice', 'prentice hall']\n",
      "[7, 'log_p', 'log p']\n",
      "[7, 'number_randomness', 'randomness numbers']\n",
      "[7, 'computer_ieee', 'ieee computer']\n",
      "[7, 'finiteness_set', 'finiteness set']\n",
      "[7, 'communication_mode', 'communication modes']\n",
      "[7, 'similarity_situation', 'similarity situations']\n",
      "[7, 'compressed_domain', 'compressed domain']\n",
      "[7, 'quad_tree', 'quad tree']\n",
      "[7, 'color_space', 'color space']\n",
      "[7, 'distance_function', 'distance function']\n",
      "[7, 'hierarchy_index', 'hierarchy index']\n",
      "[7, 'knowledge_structure', 'knowledge structures']\n",
      "[7, 'block_cd_cd_edit', 'cd cd block edit']\n",
      "[7, 'class_output', 'output class']\n",
      "[7, 'goal_knowledge', 'knowledge goals']\n",
      "[7, 'class_company', 'company class']\n",
      "[8, 'regression_selection_technique_test', 'regression test selection techniques']\n",
      "[8, 'base_program', 'base program']\n",
      "[8, 'new_york', 'new york']\n",
      "[8, 'harrold_m.j.', 'm.j. harrold']\n",
      "[8, 'computer_science', 'computer science']\n",
      "[8, 'memory_module', 'memory modules']\n",
      "[8, 'architecture_computer', 'computer architecture']\n",
      "[8, 'report_technique', 'technique report']\n",
      "[8, 'classical_logic', 'classical logic']\n",
      "[8, 'ffl_step', 'ffl step']\n",
      "[8, 'color_histogram', 'color histogram']\n",
      "[8, 'interview_structured', 'structured interviews']\n",
      "[8, 'near_neighbor', 'nearest neighbors']\n",
      "[8, 'jakob_nielsen', 'jakob nielsen']\n",
      "[8, 'b._chandrasekaran', 'chandrasekaran b.']\n",
      "[8, 'aqua_meta', 'meta aqua']\n",
      "[9, 'step_time', 'time steps']\n",
      "[9, 'altos_los', 'los altos']\n",
      "[9, 'kaufmann_morgan', 'morgan kaufmann']\n",
      "[9, 'gis_problem_query_range', 'gis range query problem']\n",
      "[9, 'generator_software_system', 'software system generators']\n",
      "[9, 'internet_laboratory_software_visualization', 'internet software visualization laboratory']\n",
      "[9, 'match_property', 'match property']\n",
      "[10, 'set_test', 'test sets']\n",
      "[10, 'otherness_word', 'otherness words']\n",
      "[10, 'condition_node', 'node condition']\n",
      "[10, 'c_code', 'c code']\n",
      "[10, 'precc_specification', 'precc specification']\n",
      "[10, 'otherness_processor', 'otherness processors']\n",
      "[10, 'parameter_realm', 'realm parameters']\n",
      "[10, 'expectation_failure', 'expectation failure']\n",
      "[10, 'meta_xp', 'meta xp']\n",
      "[10, 'class_structure', 'class structure']\n",
      "[10, 'class_employee', 'employee class']\n",
      "[10, 'directive_propagation', 'propagation directive']\n",
      "[11, 'empiricism_study', 'empiricism studies']\n",
      "[11, 'maintenance_software', 'software maintenance']\n",
      "[11, 'access_memory', 'memory accesses']\n",
      "[11, 'completeness_np', 'np completeness']\n",
      "[11, 'pi_processor', 'processor pi']\n",
      "[11, 'group_size', 'group size']\n",
      "[11, 'accuracy_generalization', 'generalization accuracy']\n",
      "[12, 'engineering_software', 'software engineering']\n",
      "[12, 'springer_verlag', 'springer verlag']\n",
      "[12, 'cone_tree', 'cone tree']\n",
      "[12, 'query_range', 'range query']\n",
      "[12, 'inheritance_multiple', 'multiple inheritance']\n",
      "[12, 'border_point', 'border points']\n",
      "[13, 't_test', 'test t']\n",
      "[13, 'cache_line', 'cache lines']\n",
      "[13, 'logic_programming', 'logic programming']\n",
      "[14, 'modification_traversing', 'modification traversing']\n",
      "[14, 'instance_noise', 'noise instances']\n",
      "[15, 'execution_time', 'execution time']\n",
      "[16, 'linear_logic', 'linear logic']\n",
      "[17, 'comment_individuality', 'individuality comments']\n",
      "[18, 'learning_machine', 'machine learning']\n",
      "[20, 'conference_maintenance_proceeding_software', 'proceedings of the conference on software maintenance']\n",
      "[22, 'suite_test', 'test suites']\n",
      "[22, 'graph_propagation', 'propagation graph']\n",
      "[25, 'hand_otherness', 'otherness hand']\n",
      "[25, 'artificial_intelligence', 'artificial intelligence']\n",
      "[25, 'class_dictionary_graph', 'class dictionary graph']\n",
      "[29, 'pattern_propagation', 'propagation pattern']\n",
      "[31, 'regression_testing', 'regression testing']\n"
     ]
    }
   ],
   "source": [
    "cons = sortgroup(concepts)\n",
    "for c in cons:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
